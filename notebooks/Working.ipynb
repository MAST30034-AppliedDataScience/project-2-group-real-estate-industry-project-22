{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/09/11 11:24:41 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "## METHOD 1: convert dictionary to spark dataframe and append to initialized sdf\n",
    "# built-in imports\n",
    "import re\n",
    "from json import dump, load\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen, Request\n",
    "import pandas as pd  \n",
    "import os\n",
    "# Import Spark modules\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Domain Scraper\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "#### create a spark data frame\n",
    "\n",
    "# constants\n",
    "BASE_URL = \"https://www.domain.com.au\"\n",
    "N_PAGES = range(1, 2)  # Update this to your liking\n",
    "\n",
    "#Scrape suburb from the address\n",
    "def extract_suburb(address: str) -> str:\n",
    "    \"\"\"Extract the suburb name from the property address.\"\"\"\n",
    "    match = re.search(r'(?<=, )\\w+', address)\n",
    "    if match:\n",
    "        return match.group(0)\n",
    "    return \"Unknown\"\n",
    "\n",
    "\n",
    "def start_scrape() -> None:\n",
    "    \"\"\" Function that scrapes https://www.domain.com.au and outputs the data into a json file\n",
    "\n",
    "    Parameters:\n",
    "    None\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    schema = StructType([\n",
    "    StructField(\"url\", StringType(), True),\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"cost_text\", StringType(), True),\n",
    "    StructField(\"rooms\", StringType(), True),\n",
    "    StructField(\"desc\", StringType(), True),\n",
    "    StructField(\"parking\", StringType(), True),\n",
    "    StructField(\"street\", StringType(), True),\n",
    "    StructField(\"suburb\", StringType(), True),\n",
    "    StructField(\"postcode\", StringType(), True),\n",
    "    StructField(\"propertyType\", StringType(), True),\n",
    "    StructField(\"school\", StringType(), True),\n",
    "    StructField(\"features\", StringType(), True),\n",
    "    ])\n",
    "\n",
    "    # begin code\n",
    "    url_links = []\n",
    "    property_metadata = defaultdict(dict)\n",
    "    sdf = spark.createDataFrame([],schema)\n",
    "    \n",
    "\n",
    "    # generate list of urls to visit\n",
    "    for page in N_PAGES:\n",
    "        url = BASE_URL + f\"/rent/?excludedeposittaken=1&state=vic&page={page}\"\n",
    "        print(f\"Visiting {url}\")\n",
    "        bs_object = BeautifulSoup(urlopen(Request(url, headers={'User-Agent': \"PostmanRuntime/7.6.0\"})), \"lxml\")\n",
    "\n",
    "        # find the unordered list (ul) elements which are the results, then\n",
    "        # find all href (a) tags that are from the base_url website.\n",
    "        index_links = bs_object.find(\"ul\", {\"data-testid\": \"results\"}).findAll(\n",
    "            \"a\", href=re.compile(f\"{BASE_URL}/*\")  # the `*` denotes wildcard any\n",
    "        )\n",
    "\n",
    "        for link in index_links:\n",
    "            # if it's a property address, add it to the list\n",
    "            if 'address' in link.get('class', []):\n",
    "                url_links.append(link['href'])\n",
    "\n",
    "    # for each url, scrape some basic metadata\n",
    "    pbar = tqdm(url_links)\n",
    "    success_count, total_count = 0, 0\n",
    "\n",
    "    for property_url in pbar:\n",
    "        try:\n",
    "            bs_object = BeautifulSoup(urlopen(Request(property_url, headers={'User-Agent': \"PostmanRuntime/7.6.0\"})), \"lxml\")\n",
    "            total_count += 1\n",
    "\n",
    "            property_page = urlopen(Request(property_url, headers={'User-Agent': \"PostmanRuntime/7.6.0\"}))\n",
    "            property_soup = BeautifulSoup(property_page, \"lxml\")\n",
    "\n",
    "            # looks for the header class to get property name\n",
    "            property_metadata[property_url]['name'] = bs_object.find(\"h1\", {\"class\": \"css-164r41r\"}).text.strip()\n",
    "\n",
    "            # looks for the div containing a summary title for cost\n",
    "            property_metadata[property_url]['cost_text'] = bs_object.find(\n",
    "                \"div\", {\"data-testid\": \"listing-details__summary-title\"}\n",
    "            ).text.strip()\n",
    "\n",
    "\n",
    "            # get rooms and parking\n",
    "            rooms = bs_object.find(\"div\", {\"data-testid\": \"property-features\"}).findAll(\n",
    "                \"span\", {\"data-testid\": \"property-features-text-container\"}\n",
    "            )\n",
    "\n",
    "            # rooms\n",
    "            property_metadata[property_url]['rooms'] = \", \".join(\n",
    "                [re.findall(r'\\d+\\s[A-Za-z]+', feature.text)[0] for feature in rooms if 'Bed' in feature.text or 'Bath' in feature.text]\n",
    "            )\n",
    "\n",
    "            # parking\n",
    "            property_metadata[property_url]['parking'] = \", \".join(\n",
    "                [re.findall(r'\\S+\\s[A-Za-z]+', feature.text)[0] for feature in rooms if 'Parking' in feature.text]\n",
    "            )\n",
    "\n",
    "            # desc\n",
    "            property_metadata[property_url]['desc'] = \", \".join(\n",
    "                [re.findall(r'\\d+\\s[A-Za-z]+', feature.text)[0] for feature in rooms if 'desc' in feature.text]\n",
    "            )\n",
    "            \n",
    "            # listingID:\n",
    "            property_metadata[property_url]['listingid'] = \", \".join(\n",
    "                [re.findall(r'\\S+\\s[A-Za-z]+', feature.text)[0] for feature in rooms if 'listingId' in feature.text]\n",
    "            )\n",
    "\n",
    "            # street:\n",
    "            property_metadata[property_url]['street'] = \", \".join(\n",
    "                [re.findall(r'\\S+\\s[A-Za-z]+', feature.text)[0] for feature in rooms if 'street' in feature.text]\n",
    "            )\n",
    "\n",
    "            # suburb:\n",
    "            property_metadata[property_url]['suburb'] = extract_suburb(property_metadata[property_url]['name'])\n",
    "\n",
    "            \n",
    "            # postcode:\n",
    "            property_metadata[property_url]['postcode'] = \", \".join(\n",
    "                [re.findall(r'\\S+\\s[A-Za-z]+', feature.text)[0] for feature in rooms if 'postcode' in feature.text]\n",
    "            )\n",
    "\n",
    "            # property type:\n",
    "            property_metadata[property_url]['propertyType'] = \", \".join(\n",
    "                [re.findall(r'\\S+\\s[A-Za-z]+', feature.text)[0] for feature in rooms if 'apartment' in feature.text \n",
    "                 or 'unit' in feature.text or 'house' in feature.text or 'flat' in feature.text]\n",
    "            )\n",
    "\n",
    "            # schools:\n",
    "            property_metadata[property_url]['school'] = \", \".join(\n",
    "                [re.findall(r'\\S+\\s[A-Za-z]+', feature.text)[0] for feature in rooms if 'school' in feature.text]\n",
    "            )\n",
    "\n",
    "            # features:\n",
    "            property_metadata[property_url]['features'] = \", \".join(\n",
    "                [re.findall(r'\\S+\\s[A-Za-z]+', feature.text)[0] for feature in rooms if 'feature' in feature.text]\n",
    "            )\n",
    "\n",
    "            # loanfinder:\n",
    "            property_metadata[property_url]['loan'] = \", \".join(\n",
    "                [re.findall(r'\\S+\\s[A-Za-z]+', feature.text)[0] for feature in rooms if 'loan' in feature.text]\n",
    "            )\n",
    "\n",
    "            # listingSummary:\n",
    "            property_metadata[property_url]['listingsummary'] = \", \".join(\n",
    "                [re.findall(r'\\S+\\s[A-Za-z]+', feature.text)[0] for feature in rooms if 'summary' in feature.text]\n",
    "            )\n",
    "\n",
    "            # suburb insights:\n",
    "            property_metadata[property_url]['suburbInsights'] = \", \".join(\n",
    "                [re.findall(r'\\S+\\s[A-Za-z]+', feature.text)[0] for feature in rooms if 'suburbInsights' in feature.text]\n",
    "            )\n",
    "\n",
    "            # property description\n",
    "            property_metadata[property_url]['desc'] = bs_object.find(\"p\").text.strip() if bs_object.find(\"p\") else \"N/A\"\n",
    "\n",
    "\n",
    "            # Scrape property description\n",
    "            property_metadata[property_url]['desc'] = re.sub(r'<br\\/>', '\\n', str(property_soup.find(\"p\"))).strip('</p>')\n",
    "           \n",
    "            \"\"\"\n",
    "            # Write each row to the CSV\n",
    "            writer.writerow([\n",
    "                property_url,\n",
    "                property_metadata[property_url]['name'],\n",
    "                property_metadata[property_url]['cost_text'],\n",
    "                property_metadata[property_url]['rooms'],\n",
    "                property_metadata[property_url]['parking'],\n",
    "                property_metadata[property_url]['desc'],\n",
    "                property_metadata[property_url]['listingid'],\n",
    "                property_metadata[property_url]['street'],\n",
    "                property_metadata[property_url]['suburb'],\n",
    "                property_metadata[property_url]['postcode'],\n",
    "                property_metadata[property_url]['propertyType'],\n",
    "                property_metadata[property_url]['school'],\n",
    "                property_metadata[property_url]['features'],\n",
    "                property_metadata[property_url]['loan'],\n",
    "                property_metadata[property_url]['listingsummary'],\n",
    "                property_metadata[property_url]['suburbInsights']\n",
    "            ])\n",
    "            \"\"\"\n",
    "            success_count += 1\n",
    "            temp_sdf = spark.createDataFrame(property_metadata)\n",
    "            sdf.union(temp_sdf)\n",
    "\n",
    "        except AttributeError:\n",
    "            print(f\"Issue with {property_url}\")\n",
    "\n",
    "        pbar.set_description(f\"{(success_count / total_count * 100):.0f}% successful\")\n",
    "\n",
    "        # output to example json in data/raw/\n",
    "    with open('../data/raw/example.json', 'w') as f:\n",
    "        dump(property_metadata, f)\n",
    "\n",
    "def convert_to_parquet(filepath: str, output_path: str) -> None:\n",
    "    \"\"\" Function converts a json file into a parquet file\n",
    "\n",
    "    Parameters:\n",
    "    filepath (str): the filepath that locates our json data\n",
    "\n",
    "    output_path (str): the filepath that we will place our new parquet file into\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    with open(filepath) as f:\n",
    "        data = load(f)\n",
    "\n",
    "    new_data = change_json_format(data)\n",
    "\n",
    "    # conversion from json -> dataframe -> parquet\n",
    "    df = pd.DataFrame(new_data)\n",
    "    df.to_parquet(output_path, engine='pyarrow')\n",
    "\n",
    "    delete_json_file(filepath)\n",
    "\n",
    "# function that changes the formatting of the json file\n",
    "def change_json_format(data: dict) -> dict:\n",
    "    \"\"\" Function grabs the renames the json keys to the words after the last backslash in the url and adds the url as an item\n",
    "\n",
    "    Parameters:\n",
    "    data (dict): json dictionary we are changing\n",
    "\n",
    "    Returns:\n",
    "    dict: our new json dictionary\n",
    "    \n",
    "    \"\"\"\n",
    "    new_data = {}\n",
    "    for i in data.keys():\n",
    "        new_name = i.rsplit('/', 1)[-1]\n",
    "        new_data[new_name] = data[i]\n",
    "        new_data[new_name][\"href\"] = i\n",
    "    return new_data\n",
    "\n",
    "def delete_json_file(filepath: str) -> None:\n",
    "    \"\"\" Function deletes the json file we are converting from\n",
    "\n",
    "    Parameters:\n",
    "    filepath (string): filepath to the json file we are deleting\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        os.remove(filepath)\n",
    "        print(f\"File '{filepath}' deleted successfully\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File '{filepath}' not found\")\n",
    "    except PermissionError:\n",
    "        print(f\"Permission denied: '{filepath}'\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/09/11 11:24:41 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create a spark session (which will run spark jobs)\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"MAST30034 Project 2\")\n",
    "    .config(\"spark.sql.repl.eagerEval.enabled\", True) \n",
    "    .config(\"spark.sql.parquet.cacheMetadata\", \"true\")\n",
    "    .config(\"spark.sql.session.timeZone\", \"Etc/UTC\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "from pyarrow import json\n",
    "import pyarrow.parquet as pq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_parquet(filepath: str, output_path: str) -> None:\n",
    "    \"\"\" Function converts a JSON file into a parquet file \"\"\"\n",
    "    with open(filepath) as f:\n",
    "        data = load(f)\n",
    "\n",
    "    new_data = change_json_format(data)\n",
    "\n",
    "    # Conversion from JSON -> DataFrame -> Parquet\n",
    "    df = pd.DataFrame(new_data)\n",
    "    df.to_parquet(output_path, engine='pyarrow')\n",
    "\n",
    "    delete_json_file(filepath)\n",
    "\n",
    "def change_json_format(data: dict) -> dict:\n",
    "    \"\"\" Function renames JSON keys and adds the URL as an item \"\"\"\n",
    "    new_data = {}\n",
    "    for i in data.keys():\n",
    "        new_name = i.rsplit('/', 1)[-1]\n",
    "        new_data[new_name] = data[i]\n",
    "        new_data[new_name][\"href\"] = i\n",
    "    return new_data\n",
    "\n",
    "def delete_json_file(filepath: str) -> None:\n",
    "    \"\"\" Function deletes the JSON file \"\"\"\n",
    "    try:\n",
    "        os.remove(filepath)\n",
    "        print(f\"File '{filepath}' deleted successfully\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File '{filepath}' not found\")\n",
    "    except PermissionError:\n",
    "        print(f\"Permission denied: '{filepath}'\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping data for melbourne (3000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% successful: 100%|██████████| 20/20 [00:14<00:00,  1.39it/s]\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+---------+--------------------+--------------+----+-----+-------+--------------------+\n",
      "|                 url|postcode|   suburb|                name|     cost_text|beds|baths|parking|       property_type|\n",
      "+--------------------+--------+---------+--------------------+--------------+----+-----+-------+--------------------+\n",
      "|https://www.domai...|    3000|melbourne|1503/270 King Str...| $850 Per Week|   4|    1|      1|Apartment / Unit ...|\n",
      "|https://www.domai...|    3000|melbourne|26/418 St Kilda R...|       $725 pw|   2|    1|      1|Apartment / Unit ...|\n",
      "|https://www.domai...|    3000|melbourne|3712/80 ABeckett ...| $675 per week|   2|    1|      1|Apartment / Unit ...|\n",
      "|https://www.domai...|    3000|melbourne|3002B/11 Rose Lan...| $650 per week|   2|    1|      1|Apartment / Unit ...|\n",
      "|https://www.domai...|    3000|melbourne|103/300 Swanston ...|       $620 pw|   1|    1|      1|Apartment / Unit ...|\n",
      "|https://www.domai...|    3000|melbourne|201/23 Queens Roa...|          $600|   2|    1|      1|Apartment / Unit ...|\n",
      "|https://www.domai...|    3000|melbourne|804/225 Elizabeth...|       $570.00|   2|    1|      0|Apartment / Unit ...|\n",
      "|https://www.domai...|    3000|melbourne|801/115 Swanston ...|    $550.00 pw|   1|    1|      0|Apartment / Unit ...|\n",
      "|https://www.domai...|    3000|melbourne|4012/22-24 Jane B...|       $530 pw|   1|    1|      1|Apartment / Unit ...|\n",
      "|https://www.domai...|    3000|melbourne|509/318 Little Bo...| $490 per week|   1|    1|      0|Apartment / Unit ...|\n",
      "|https://www.domai...|    3000|melbourne|1403/325 Collins ...|       $450 pw|   0|    1|      0|              Studio|\n",
      "|https://www.domai...|    3000|melbourne|302/408 Lonsdale ...|          $410|   1|    1|      0|              Studio|\n",
      "|https://www.domai...|    3000|melbourne|413/500 Flinders ...|          $220|   1|    1|      0|Apartment / Unit ...|\n",
      "|https://www.domai...|    3000|melbourne|2601/82 Flinders ...|$1900 per week|   4|    2|      2|Apartment / Unit ...|\n",
      "|https://www.domai...|    3000|melbourne|1113/639 Lonsdale...|       $800 pw|   2|    2|      1|Apartment / Unit ...|\n",
      "|https://www.domai...|    3000|melbourne|1208/10 Bennetts ...|          $750|   1|    1|      0|Apartment / Unit ...|\n",
      "|https://www.domai...|    3000|melbourne|522/199 William S...|          $720|   2|    2|      0|Apartment / Unit ...|\n",
      "|https://www.domai...|    3000|melbourne|16HI/131 Lonsdale...|          $700|   2|    2|      0|Apartment / Unit ...|\n",
      "|https://www.domai...|    3000|melbourne|1708/38 Rose Lane...| $700 per week|   2|    1|      0|Apartment / Unit ...|\n",
      "|https://www.domai...|    3000|melbourne|3601/81 A'Beckett...|   $700 weekly|   2|    1|      0|Apartment / Unit ...|\n",
      "+--------------------+--------+---------+--------------------+--------------+----+-----+-------+--------------------+\n",
      "\n",
      "Scraping data for melbourne (3001)\n",
      "Error fetching https://www.domain.com.au/rent/melbourne-vic-3001/?ssubs=0&sort=suburb-asc&page=1: HTTP Error 404: Not Found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+---------+--------------------+--------------+----+-----+-------+--------------------+\n",
      "|                 url|postcode|   suburb|                name|     cost_text|beds|baths|parking|       property_type|\n",
      "+--------------------+--------+---------+--------------------+--------------+----+-----+-------+--------------------+\n",
      "|https://www.domai...|    3000|melbourne|1503/270 King Str...| $850 Per Week|   4|    1|      1|Apartment / Unit ...|\n",
      "|https://www.domai...|    3000|melbourne|26/418 St Kilda R...|       $725 pw|   2|    1|      1|Apartment / Unit ...|\n",
      "|https://www.domai...|    3000|melbourne|3712/80 ABeckett ...| $675 per week|   2|    1|      1|Apartment / Unit ...|\n",
      "|https://www.domai...|    3000|melbourne|3002B/11 Rose Lan...| $650 per week|   2|    1|      1|Apartment / Unit ...|\n",
      "|https://www.domai...|    3000|melbourne|103/300 Swanston ...|       $620 pw|   1|    1|      1|Apartment / Unit ...|\n",
      "|https://www.domai...|    3000|melbourne|201/23 Queens Roa...|          $600|   2|    1|      1|Apartment / Unit ...|\n",
      "|https://www.domai...|    3000|melbourne|804/225 Elizabeth...|       $570.00|   2|    1|      0|Apartment / Unit ...|\n",
      "|https://www.domai...|    3000|melbourne|801/115 Swanston ...|    $550.00 pw|   1|    1|      0|Apartment / Unit ...|\n",
      "|https://www.domai...|    3000|melbourne|4012/22-24 Jane B...|       $530 pw|   1|    1|      1|Apartment / Unit ...|\n",
      "|https://www.domai...|    3000|melbourne|509/318 Little Bo...| $490 per week|   1|    1|      0|Apartment / Unit ...|\n",
      "|https://www.domai...|    3000|melbourne|1403/325 Collins ...|       $450 pw|   0|    1|      0|              Studio|\n",
      "|https://www.domai...|    3000|melbourne|302/408 Lonsdale ...|          $410|   1|    1|      0|              Studio|\n",
      "|https://www.domai...|    3000|melbourne|413/500 Flinders ...|          $220|   1|    1|      0|Apartment / Unit ...|\n",
      "|https://www.domai...|    3000|melbourne|2601/82 Flinders ...|$1900 per week|   4|    2|      2|Apartment / Unit ...|\n",
      "|https://www.domai...|    3000|melbourne|1113/639 Lonsdale...|       $800 pw|   2|    2|      1|Apartment / Unit ...|\n",
      "|https://www.domai...|    3000|melbourne|1208/10 Bennetts ...|          $750|   1|    1|      0|Apartment / Unit ...|\n",
      "|https://www.domai...|    3000|melbourne|522/199 William S...|          $720|   2|    2|      0|Apartment / Unit ...|\n",
      "|https://www.domai...|    3000|melbourne|16HI/131 Lonsdale...|          $700|   2|    2|      0|Apartment / Unit ...|\n",
      "|https://www.domai...|    3000|melbourne|1708/38 Rose Lane...| $700 per week|   2|    1|      0|Apartment / Unit ...|\n",
      "|https://www.domai...|    3000|melbourne|3601/81 A'Beckett...|   $700 weekly|   2|    1|      0|Apartment / Unit ...|\n",
      "+--------------------+--------+---------+--------------------+--------------+----+-----+-------+--------------------+\n",
      "\n",
      "Scraping data for east-melbourne (3002)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% successful: 100%|██████████| 20/20 [00:13<00:00,  1.49it/s]\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+---------+--------------------+--------------+----+-----+-------+--------------------+\n",
      "|                 url|postcode|   suburb|                name|     cost_text|beds|baths|parking|       property_type|\n",
      "+--------------------+--------+---------+--------------------+--------------+----+-----+-------+--------------------+\n",
      "|https://www.domai...|    3000|melbourne|1503/270 King Str...| $850 Per Week|   4|    1|      1|Apartment / Unit ...|\n",
      "|https://www.domai...|    3000|melbourne|26/418 St Kilda R...|       $725 pw|   2|    1|      1|Apartment / Unit ...|\n",
      "|https://www.domai...|    3000|melbourne|3712/80 ABeckett ...| $675 per week|   2|    1|      1|Apartment / Unit ...|\n",
      "|https://www.domai...|    3000|melbourne|3002B/11 Rose Lan...| $650 per week|   2|    1|      1|Apartment / Unit ...|\n",
      "|https://www.domai...|    3000|melbourne|103/300 Swanston ...|       $620 pw|   1|    1|      1|Apartment / Unit ...|\n",
      "|https://www.domai...|    3000|melbourne|201/23 Queens Roa...|          $600|   2|    1|      1|Apartment / Unit ...|\n",
      "|https://www.domai...|    3000|melbourne|804/225 Elizabeth...|       $570.00|   2|    1|      0|Apartment / Unit ...|\n",
      "|https://www.domai...|    3000|melbourne|801/115 Swanston ...|    $550.00 pw|   1|    1|      0|Apartment / Unit ...|\n",
      "|https://www.domai...|    3000|melbourne|4012/22-24 Jane B...|       $530 pw|   1|    1|      1|Apartment / Unit ...|\n",
      "|https://www.domai...|    3000|melbourne|509/318 Little Bo...| $490 per week|   1|    1|      0|Apartment / Unit ...|\n",
      "|https://www.domai...|    3000|melbourne|1403/325 Collins ...|       $450 pw|   0|    1|      0|              Studio|\n",
      "|https://www.domai...|    3000|melbourne|302/408 Lonsdale ...|          $410|   1|    1|      0|              Studio|\n",
      "|https://www.domai...|    3000|melbourne|413/500 Flinders ...|          $220|   1|    1|      0|Apartment / Unit ...|\n",
      "|https://www.domai...|    3000|melbourne|2601/82 Flinders ...|$1900 per week|   4|    2|      2|Apartment / Unit ...|\n",
      "|https://www.domai...|    3000|melbourne|1113/639 Lonsdale...|       $800 pw|   2|    2|      1|Apartment / Unit ...|\n",
      "|https://www.domai...|    3000|melbourne|1208/10 Bennetts ...|          $750|   1|    1|      0|Apartment / Unit ...|\n",
      "|https://www.domai...|    3000|melbourne|522/199 William S...|          $720|   2|    2|      0|Apartment / Unit ...|\n",
      "|https://www.domai...|    3000|melbourne|16HI/131 Lonsdale...|          $700|   2|    2|      0|Apartment / Unit ...|\n",
      "|https://www.domai...|    3000|melbourne|1708/38 Rose Lane...| $700 per week|   2|    1|      0|Apartment / Unit ...|\n",
      "|https://www.domai...|    3000|melbourne|3601/81 A'Beckett...|   $700 weekly|   2|    1|      0|Apartment / Unit ...|\n",
      "+--------------------+--------+---------+--------------------+--------------+----+-----+-------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Scraping data for west-melbourne (3003)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% successful:  20%|██        | 4/20 [00:02<00:08,  1.98it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 130\u001b[0m\n\u001b[1;32m    127\u001b[0m     property_metadata\u001b[38;5;241m.\u001b[39mwrite\u001b[38;5;241m.\u001b[39mjson(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../data/raw/work.json\u001b[39m\u001b[38;5;124m'\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moverwrite\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    129\u001b[0m \u001b[38;5;66;03m# Start scraping\u001b[39;00m\n\u001b[0;32m--> 130\u001b[0m \u001b[43mstart_scrape\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[43], line 76\u001b[0m, in \u001b[0;36mstart_scrape\u001b[0;34m()\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m property_url \u001b[38;5;129;01min\u001b[39;00m pbar:\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 76\u001b[0m         bs_object \u001b[38;5;241m=\u001b[39m \u001b[43mBeautifulSoup\u001b[49m\u001b[43m(\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproperty_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mUser-Agent\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPostmanRuntime/7.6.0\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlxml\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m         total_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     79\u001b[0m         \u001b[38;5;66;03m# Get property name\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/bs4/__init__.py:314\u001b[0m, in \u001b[0;36mBeautifulSoup.__init__\u001b[0;34m(self, markup, features, builder, parse_only, from_encoding, exclude_encodings, element_classes, **kwargs)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_only \u001b[38;5;241m=\u001b[39m parse_only\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(markup, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m'\u001b[39m):        \u001b[38;5;66;03m# It's a file-type object.\u001b[39;00m\n\u001b[0;32m--> 314\u001b[0m     markup \u001b[38;5;241m=\u001b[39m \u001b[43mmarkup\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(markup) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m256\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[1;32m    316\u001b[0m         (\u001b[38;5;28misinstance\u001b[39m(markup, \u001b[38;5;28mbytes\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m markup)\n\u001b[1;32m    317\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(markup, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m markup)\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    321\u001b[0m     \u001b[38;5;66;03m# Beautiful Soup will still parse the input as markup,\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;66;03m# since that is sometimes the intended behavior.\u001b[39;00m\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_markup_is_url(markup):\n",
      "File \u001b[0;32m/usr/lib/python3.10/http/client.py:460\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    457\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunked:\n\u001b[0;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_chunked\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    462\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    463\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength:\n\u001b[1;32m    464\u001b[0m         \u001b[38;5;66;03m# clip the read to the \"end of response\"\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/http/client.py:583\u001b[0m, in \u001b[0;36mHTTPResponse._read_chunked\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    581\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    582\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 583\u001b[0m         chunk_left \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_chunk_left\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    584\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m chunk_left \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    585\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/http/client.py:566\u001b[0m, in \u001b[0;36mHTTPResponse._get_chunk_left\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    564\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_safe_read(\u001b[38;5;241m2\u001b[39m)  \u001b[38;5;66;03m# toss the CRLF at the end of the chunk\u001b[39;00m\n\u001b[1;32m    565\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 566\u001b[0m     chunk_left \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_next_chunk_size\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[1;32m    568\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m IncompleteRead(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/usr/lib/python3.10/http/client.py:526\u001b[0m, in \u001b[0;36mHTTPResponse._read_next_chunk_size\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    524\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_next_chunk_size\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    525\u001b[0m     \u001b[38;5;66;03m# Read the next chunk size from the file\u001b[39;00m\n\u001b[0;32m--> 526\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    527\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[1;32m    528\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchunk size\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/lib/python3.10/socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 705\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    707\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/ssl.py:1303\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1299\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1300\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1301\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1302\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1303\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1304\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1305\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m/usr/lib/python3.10/ssl.py:1159\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1157\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1159\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1160\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1161\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Working METHOD\n",
    "import re\n",
    "from json import dump\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen, Request\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder.appName(\"PropertyScraper\").getOrCreate()\n",
    "\n",
    "# Constants\n",
    "BASE_URL = \"https://www.domain.com.au\"\n",
    "N_PAGES = range(1, 2)  # Update this to your liking\n",
    "\n",
    "# Load suburbs CSV\n",
    "suburbs_df = pd.read_csv('postcodes.csv')  # Ensure this CSV contains 'suburb' and 'postcode' columns\n",
    "\n",
    "def start_scrape():\n",
    "    \"\"\"Function that scrapes https://www.domain.com.au and outputs the data into a JSON file\"\"\"\n",
    "\n",
    "    # Define schema for the Spark DataFrame\n",
    "    schema = StructType([\n",
    "        StructField(\"url\", StringType(), True),\n",
    "        StructField(\"postcode\", StringType(), True),\n",
    "        StructField(\"suburb\", StringType(), True),\n",
    "        StructField(\"name\", StringType(), True),\n",
    "        StructField(\"cost_text\", StringType(), True),\n",
    "        StructField(\"beds\", StringType(), True),  # Separate field for beds\n",
    "        StructField(\"baths\", StringType(), True),  # Separate field for baths\n",
    "        StructField(\"parking\", StringType(), True),  # Parking field\n",
    "        StructField(\"property_type\", StringType(), True),  # Parking field\n",
    "    ])\n",
    "\n",
    "\n",
    "    # Initialize an empty DataFrame with the schema\n",
    "    property_metadata = spark.createDataFrame([], schema)\n",
    "\n",
    "    # Loop through each suburb and its postcode\n",
    "    for index, row in suburbs_df.iterrows():\n",
    "        suburb = row['locality'].lower().replace(' ', '-')  # Convert to lowercase and hyphenate\n",
    "        postcode = row['postcode']\n",
    "\n",
    "        print(f\"Scraping data for {suburb} ({postcode})\")\n",
    "\n",
    "        url_links = []\n",
    "\n",
    "        # Generate list of URLs to visit\n",
    "        for page in N_PAGES:\n",
    "            url = BASE_URL + f\"/rent/{suburb}-vic-{postcode}/?ssubs=0&sort=suburb-asc&page={page}\"\n",
    "            try:\n",
    "                bs_object = BeautifulSoup(urlopen(Request(url, headers={'User-Agent': \"PostmanRuntime/7.6.0\"})), \"lxml\")\n",
    "\n",
    "                # Find property links\n",
    "                index_links = bs_object.find(\"ul\", {\"data-testid\": \"results\"}).findAll(\n",
    "                    \"a\", href=re.compile(f\"{BASE_URL}/*\")\n",
    "                )\n",
    "\n",
    "                for link in index_links:\n",
    "                    # If it's a property address, add it to the list\n",
    "                    if 'address' in link.get('class', []):\n",
    "                        url_links.append(link['href'])\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error fetching {url}: {e}\")\n",
    "\n",
    "        # For each URL, scrape some basic metadata\n",
    "        pbar = tqdm(url_links)\n",
    "        success_count, total_count = 0, 0\n",
    "\n",
    "        for property_url in pbar:\n",
    "            try:\n",
    "                bs_object = BeautifulSoup(urlopen(Request(property_url, headers={'User-Agent': \"PostmanRuntime/7.6.0\"})), \"lxml\")\n",
    "                total_count += 1\n",
    "\n",
    "                # Get property name\n",
    "                name = bs_object.find(\"h1\", {\"class\": \"css-164r41r\"}).text.strip()\n",
    "\n",
    "\n",
    "                # Get cost text\n",
    "                cost_text = bs_object.find(\"div\", {\"data-testid\": \"listing-details__summary-title\"}).text.strip()\n",
    "\n",
    "                # Get rooms (beds and baths)\n",
    "                rooms = bs_object.find(\"div\", {\"data-testid\": \"property-features\"}).findAll(\n",
    "                    \"span\", {\"data-testid\": \"property-features-text-container\"}\n",
    "                )\n",
    "\n",
    "                # Initialize variables\n",
    "                beds, baths, parking = None, None, '0'  # Default value for parking is '0 Car'\n",
    "\n",
    "                for feature in rooms:\n",
    "                    text = feature.text\n",
    "                    if 'Bed' in text:\n",
    "                        beds_match = re.findall(r'\\d+', text)\n",
    "                        if beds_match:\n",
    "                            beds = beds_match[0]  # Extract the number of beds\n",
    "                    elif 'Bath' in text:\n",
    "                        baths_match = re.findall(r'\\d+', text)\n",
    "                        if baths_match:\n",
    "                            baths = baths_match[0]  # Extract the number of baths\n",
    "                    elif 'Car' in text or 'Parking' in text:\n",
    "                        parking_match = re.findall(r'\\d+', text)\n",
    "                        if parking_match:\n",
    "                            parking = parking_match[0]  # Extract the number of parking spaces\n",
    "\n",
    "                property_type_container = bs_object.find(\"div\", {\"data-testid\": \"listing-summary-property-type\"})\n",
    "                property_type = property_type_container.get_text(strip=True)\n",
    "\n",
    "                # Create a row and append it to the DataFrame\n",
    "                row = [(property_url, postcode, suburb, name, cost_text, beds, baths, parking, property_type)]\n",
    "                row_df = spark.createDataFrame(row, schema)\n",
    "                property_metadata = property_metadata.union(row_df)\n",
    "                success_count += 1\n",
    "\n",
    "            except AttributeError:\n",
    "                print(f\"Error scraping {property_url}: missing data\")\n",
    "\n",
    "            pbar.set_description(f\"{(success_count / total_count * 100):.0f}% successful\")\n",
    "\n",
    "        # Show the DataFrame to ensure data is being appended\n",
    "        property_metadata.show()\n",
    "\n",
    "    # Output to JSON file\n",
    "    property_metadata.write.json('../data/raw/work.json', mode='overwrite')\n",
    "\n",
    "# Start scraping\n",
    "start_scrape()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  url  \\\n",
      "0   https://www.domain.com.au/4-45-ormond-esplanad...   \n",
      "1   https://www.domain.com.au/506-6-percy-place-pr...   \n",
      "2   https://www.domain.com.au/414-25-johnston-stre...   \n",
      "3   https://www.domain.com.au/warrnambool-vic-3280...   \n",
      "4   https://www.domain.com.au/103-300-swanston-str...   \n",
      "5   https://www.domain.com.au/89-axford-boulevard-...   \n",
      "6   https://www.domain.com.au/1403-325-collins-str...   \n",
      "7   https://www.domain.com.au/39-foundry-circuit-b...   \n",
      "8   https://www.domain.com.au/421-528-swanston-str...   \n",
      "9   https://www.domain.com.au/401-3-5-union-street...   \n",
      "10  https://www.domain.com.au/2-125-bell-street-iv...   \n",
      "11  https://www.domain.com.au/1-7-gordon-street-to...   \n",
      "\n",
      "                                            name                  cost_text  \\\n",
      "0         4/45 Ormond Esplanade, Elwood VIC 3184                $670 weekly   \n",
      "1            506/6 Percy Place, Prahran VIC 3181                    $720.00   \n",
      "2   414/25 Johnston Street, Collingwood VIC 3066                       $700   \n",
      "3                           Warrnambool VIC 3280                       $700   \n",
      "4    103/300 Swanston Street, Melbourne VIC 3000                    $620 pw   \n",
      "5          89 AXFORD BOULEVARD, Wodonga VIC 3690                       $620   \n",
      "6    1403/325 Collins Street, Melbourne VIC 3000                    $450 pw   \n",
      "7         39 Foundry Circuit, Beveridge VIC 3753  $460 per week ($1999 pcm)   \n",
      "8      421/528 Swanston Street, Carlton VIC 3053                    $430 pw   \n",
      "9       401/3-5 Union Street, Brunswick VIC 3056                    $670.00   \n",
      "10           2/125 Bell Street, Ivanhoe VIC 3079              $730 per week   \n",
      "11            1/7 Gordon Street, Toorak VIC 3142            $1,200 Per Week   \n",
      "\n",
      "              rooms  \n",
      "0    2 Beds, 1 Bath  \n",
      "1   2 Beds, 2 Baths  \n",
      "2     1 Bed, 1 Bath  \n",
      "3   4 Beds, 2 Baths  \n",
      "4     1 Bed, 1 Bath  \n",
      "5   4 Beds, 2 Baths  \n",
      "6    0 Beds, 1 Bath  \n",
      "7   4 Beds, 3 Baths  \n",
      "8     1 Bed, 1 Bath  \n",
      "9   2 Beds, 2 Baths  \n",
      "10  2 Beds, 2 Baths  \n",
      "11  2 Beds, 2 Baths  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define the folder path containing JSON files\n",
    "folder_path = '../data/raw/work.json'\n",
    "\n",
    "# List all files in the directory\n",
    "json_files = [f for f in os.listdir(folder_path) if f.endswith('.json')]\n",
    "\n",
    "# Initialize an empty list to store DataFrames\n",
    "dataframes = []\n",
    "\n",
    "# Read each JSON file into a DataFrame\n",
    "for file in json_files:\n",
    "    file_path = os.path.join(folder_path, file)\n",
    "    # Read JSON file\n",
    "    df = pd.read_json(file_path, lines=True)\n",
    "    # Append the DataFrame to the list\n",
    "    dataframes.append(df)\n",
    "\n",
    "# Concatenate all DataFrames into a single DataFrame\n",
    "combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# Display the combined DataFrame\n",
    "print(combined_df.head(12))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
