{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "your 131072x1 screen size is bogus. expect trouble\n",
      "24/09/15 12:28:10 WARN Utils: Your hostname, DESKTOP-Q5SP5SI resolves to a loopback address: 127.0.1.1; using 172.20.36.110 instead (on interface eth0)\n",
      "24/09/15 12:28:10 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/09/15 12:28:14 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "## METHOD 1: convert dictionary to spark dataframe and append to initialized sdf\n",
    "# built-in imports\n",
    "import re\n",
    "from json import dump, load\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen, Request\n",
    "import pandas as pd  \n",
    "import os\n",
    "# Import Spark modules\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Domain Scraper\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "#### create a spark data frame\n",
    "\n",
    "# constants\n",
    "BASE_URL = \"https://www.domain.com.au\"\n",
    "N_PAGES = range(1, 2)  # Update this to your liking\n",
    "\n",
    "#Scrape suburb from the address\n",
    "def extract_suburb(address: str) -> str:\n",
    "    \"\"\"Extract the suburb name from the property address.\"\"\"\n",
    "    match = re.search(r'(?<=, )\\w+', address)\n",
    "    if match:\n",
    "        return match.group(0)\n",
    "    return \"Unknown\"\n",
    "\n",
    "\n",
    "def start_scrape() -> None:\n",
    "    \"\"\" Function that scrapes https://www.domain.com.au and outputs the data into a json file\n",
    "\n",
    "    Parameters:\n",
    "    None\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    schema = StructType([\n",
    "    StructField(\"url\", StringType(), True),\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"cost_text\", StringType(), True),\n",
    "    StructField(\"rooms\", StringType(), True),\n",
    "    StructField(\"desc\", StringType(), True),\n",
    "    StructField(\"parking\", StringType(), True),\n",
    "    StructField(\"street\", StringType(), True),\n",
    "    StructField(\"suburb\", StringType(), True),\n",
    "    StructField(\"postcode\", StringType(), True),\n",
    "    StructField(\"propertyType\", StringType(), True),\n",
    "    StructField(\"school\", StringType(), True),\n",
    "    StructField(\"features\", StringType(), True),\n",
    "    ])\n",
    "\n",
    "    # begin code\n",
    "    url_links = []\n",
    "    property_metadata = defaultdict(dict)\n",
    "    sdf = spark.createDataFrame([],schema)\n",
    "    \n",
    "\n",
    "    # generate list of urls to visit\n",
    "    for page in N_PAGES:\n",
    "        url = BASE_URL + f\"/rent/?excludedeposittaken=1&state=vic&page={page}\"\n",
    "        print(f\"Visiting {url}\")\n",
    "        bs_object = BeautifulSoup(urlopen(Request(url, headers={'User-Agent': \"PostmanRuntime/7.6.0\"})), \"lxml\")\n",
    "\n",
    "        # find the unordered list (ul) elements which are the results, then\n",
    "        # find all href (a) tags that are from the base_url website.\n",
    "        index_links = bs_object.find(\"ul\", {\"data-testid\": \"results\"}).findAll(\n",
    "            \"a\", href=re.compile(f\"{BASE_URL}/*\")  # the `*` denotes wildcard any\n",
    "        )\n",
    "\n",
    "        for link in index_links:\n",
    "            # if it's a property address, add it to the list\n",
    "            if 'address' in link.get('class', []):\n",
    "                url_links.append(link['href'])\n",
    "\n",
    "    # for each url, scrape some basic metadata\n",
    "    pbar = tqdm(url_links)\n",
    "    success_count, total_count = 0, 0\n",
    "\n",
    "    for property_url in pbar:\n",
    "        try:\n",
    "            bs_object = BeautifulSoup(urlopen(Request(property_url, headers={'User-Agent': \"PostmanRuntime/7.6.0\"})), \"lxml\")\n",
    "            total_count += 1\n",
    "\n",
    "            property_page = urlopen(Request(property_url, headers={'User-Agent': \"PostmanRuntime/7.6.0\"}))\n",
    "            property_soup = BeautifulSoup(property_page, \"lxml\")\n",
    "\n",
    "            # looks for the header class to get property name\n",
    "            property_metadata[property_url]['name'] = bs_object.find(\"h1\", {\"class\": \"css-164r41r\"}).text.strip()\n",
    "\n",
    "            # looks for the div containing a summary title for cost\n",
    "            property_metadata[property_url]['cost_text'] = bs_object.find(\n",
    "                \"div\", {\"data-testid\": \"listing-details__summary-title\"}\n",
    "            ).text.strip()\n",
    "\n",
    "\n",
    "            # get rooms and parking\n",
    "            rooms = bs_object.find(\"div\", {\"data-testid\": \"property-features\"}).findAll(\n",
    "                \"span\", {\"data-testid\": \"property-features-text-container\"}\n",
    "            )\n",
    "\n",
    "            # rooms\n",
    "            property_metadata[property_url]['rooms'] = \", \".join(\n",
    "                [re.findall(r'\\d+\\s[A-Za-z]+', feature.text)[0] for feature in rooms if 'Bed' in feature.text or 'Bath' in feature.text]\n",
    "            )\n",
    "\n",
    "            # parking\n",
    "            property_metadata[property_url]['parking'] = \", \".join(\n",
    "                [re.findall(r'\\S+\\s[A-Za-z]+', feature.text)[0] for feature in rooms if 'Parking' in feature.text]\n",
    "            )\n",
    "\n",
    "            # desc\n",
    "            property_metadata[property_url]['desc'] = \", \".join(\n",
    "                [re.findall(r'\\d+\\s[A-Za-z]+', feature.text)[0] for feature in rooms if 'desc' in feature.text]\n",
    "            )\n",
    "            \n",
    "            # listingID:\n",
    "            property_metadata[property_url]['listingid'] = \", \".join(\n",
    "                [re.findall(r'\\S+\\s[A-Za-z]+', feature.text)[0] for feature in rooms if 'listingId' in feature.text]\n",
    "            )\n",
    "\n",
    "            # street:\n",
    "            property_metadata[property_url]['street'] = \", \".join(\n",
    "                [re.findall(r'\\S+\\s[A-Za-z]+', feature.text)[0] for feature in rooms if 'street' in feature.text]\n",
    "            )\n",
    "\n",
    "            # suburb:\n",
    "            property_metadata[property_url]['suburb'] = extract_suburb(property_metadata[property_url]['name'])\n",
    "\n",
    "            \n",
    "            # postcode:\n",
    "            property_metadata[property_url]['postcode'] = \", \".join(\n",
    "                [re.findall(r'\\S+\\s[A-Za-z]+', feature.text)[0] for feature in rooms if 'postcode' in feature.text]\n",
    "            )\n",
    "\n",
    "            # property type:\n",
    "            property_metadata[property_url]['propertyType'] = \", \".join(\n",
    "                [re.findall(r'\\S+\\s[A-Za-z]+', feature.text)[0] for feature in rooms if 'apartment' in feature.text \n",
    "                 or 'unit' in feature.text or 'house' in feature.text or 'flat' in feature.text]\n",
    "            )\n",
    "\n",
    "            # schools:\n",
    "            property_metadata[property_url]['school'] = \", \".join(\n",
    "                [re.findall(r'\\S+\\s[A-Za-z]+', feature.text)[0] for feature in rooms if 'school' in feature.text]\n",
    "            )\n",
    "\n",
    "            # features:\n",
    "            property_metadata[property_url]['features'] = \", \".join(\n",
    "                [re.findall(r'\\S+\\s[A-Za-z]+', feature.text)[0] for feature in rooms if 'feature' in feature.text]\n",
    "            )\n",
    "\n",
    "            # loanfinder:\n",
    "            property_metadata[property_url]['loan'] = \", \".join(\n",
    "                [re.findall(r'\\S+\\s[A-Za-z]+', feature.text)[0] for feature in rooms if 'loan' in feature.text]\n",
    "            )\n",
    "\n",
    "            # listingSummary:\n",
    "            property_metadata[property_url]['listingsummary'] = \", \".join(\n",
    "                [re.findall(r'\\S+\\s[A-Za-z]+', feature.text)[0] for feature in rooms if 'summary' in feature.text]\n",
    "            )\n",
    "\n",
    "            # suburb insights:\n",
    "            property_metadata[property_url]['suburbInsights'] = \", \".join(\n",
    "                [re.findall(r'\\S+\\s[A-Za-z]+', feature.text)[0] for feature in rooms if 'suburbInsights' in feature.text]\n",
    "            )\n",
    "\n",
    "            # property description\n",
    "            property_metadata[property_url]['desc'] = bs_object.find(\"p\").text.strip() if bs_object.find(\"p\") else \"N/A\"\n",
    "\n",
    "\n",
    "            # Scrape property description\n",
    "            property_metadata[property_url]['desc'] = re.sub(r'<br\\/>', '\\n', str(property_soup.find(\"p\"))).strip('</p>')\n",
    "           \n",
    "            \"\"\"\n",
    "            # Write each row to the CSV\n",
    "            writer.writerow([\n",
    "                property_url,\n",
    "                property_metadata[property_url]['name'],\n",
    "                property_metadata[property_url]['cost_text'],\n",
    "                property_metadata[property_url]['rooms'],\n",
    "                property_metadata[property_url]['parking'],\n",
    "                property_metadata[property_url]['desc'],\n",
    "                property_metadata[property_url]['listingid'],\n",
    "                property_metadata[property_url]['street'],\n",
    "                property_metadata[property_url]['suburb'],\n",
    "                property_metadata[property_url]['postcode'],\n",
    "                property_metadata[property_url]['propertyType'],\n",
    "                property_metadata[property_url]['school'],\n",
    "                property_metadata[property_url]['features'],\n",
    "                property_metadata[property_url]['loan'],\n",
    "                property_metadata[property_url]['listingsummary'],\n",
    "                property_metadata[property_url]['suburbInsights']\n",
    "            ])\n",
    "            \"\"\"\n",
    "            success_count += 1\n",
    "            temp_sdf = spark.createDataFrame(property_metadata)\n",
    "            sdf.union(temp_sdf)\n",
    "\n",
    "        except AttributeError:\n",
    "            print(f\"Issue with {property_url}\")\n",
    "\n",
    "        pbar.set_description(f\"{(success_count / total_count * 100):.0f}% successful\")\n",
    "\n",
    "        # output to example json in data/raw/\n",
    "    with open('../data/raw/example.json', 'w') as f:\n",
    "        dump(property_metadata, f)\n",
    "\n",
    "def convert_to_parquet(filepath: str, output_path: str) -> None:\n",
    "    \"\"\" Function converts a json file into a parquet file\n",
    "\n",
    "    Parameters:\n",
    "    filepath (str): the filepath that locates our json data\n",
    "\n",
    "    output_path (str): the filepath that we will place our new parquet file into\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    with open(filepath) as f:\n",
    "        data = load(f)\n",
    "\n",
    "    new_data = change_json_format(data)\n",
    "\n",
    "    # conversion from json -> dataframe -> parquet\n",
    "    df = pd.DataFrame(new_data)\n",
    "    df.to_parquet(output_path, engine='pyarrow')\n",
    "\n",
    "    delete_json_file(filepath)\n",
    "\n",
    "# function that changes the formatting of the json file\n",
    "def change_json_format(data: dict) -> dict:\n",
    "    \"\"\" Function grabs the renames the json keys to the words after the last backslash in the url and adds the url as an item\n",
    "\n",
    "    Parameters:\n",
    "    data (dict): json dictionary we are changing\n",
    "\n",
    "    Returns:\n",
    "    dict: our new json dictionary\n",
    "    \n",
    "    \"\"\"\n",
    "    new_data = {}\n",
    "    for i in data.keys():\n",
    "        new_name = i.rsplit('/', 1)[-1]\n",
    "        new_data[new_name] = data[i]\n",
    "        new_data[new_name][\"href\"] = i\n",
    "    return new_data\n",
    "\n",
    "def delete_json_file(filepath: str) -> None:\n",
    "    \"\"\" Function deletes the json file we are converting from\n",
    "\n",
    "    Parameters:\n",
    "    filepath (string): filepath to the json file we are deleting\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        os.remove(filepath)\n",
    "        print(f\"File '{filepath}' deleted successfully\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File '{filepath}' not found\")\n",
    "    except PermissionError:\n",
    "        print(f\"Permission denied: '{filepath}'\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/09/15 12:28:25 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create a spark session (which will run spark jobs)\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"MAST30034 Project 2\")\n",
    "    .config(\"spark.sql.repl.eagerEval.enabled\", True) \n",
    "    .config(\"spark.sql.parquet.cacheMetadata\", \"true\")\n",
    "    .config(\"spark.sql.session.timeZone\", \"Etc/UTC\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "from pyarrow import json\n",
    "import pyarrow.parquet as pq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_parquet(filepath: str, output_path: str) -> None:\n",
    "    \"\"\" Function converts a JSON file into a parquet file \"\"\"\n",
    "    with open(filepath) as f:\n",
    "        data = load(f)\n",
    "\n",
    "    new_data = change_json_format(data)\n",
    "\n",
    "    # Conversion from JSON -> DataFrame -> Parquet\n",
    "    df = pd.DataFrame(new_data)\n",
    "    df.to_parquet(output_path, engine='pyarrow')\n",
    "\n",
    "    delete_json_file(filepath)\n",
    "\n",
    "def change_json_format(data: dict) -> dict:\n",
    "    \"\"\" Function renames JSON keys and adds the URL as an item \"\"\"\n",
    "    new_data = {}\n",
    "    for i in data.keys():\n",
    "        new_name = i.rsplit('/', 1)[-1]\n",
    "        new_data[new_name] = data[i]\n",
    "        new_data[new_name][\"href\"] = i\n",
    "    return new_data\n",
    "\n",
    "def delete_json_file(filepath: str) -> None:\n",
    "    \"\"\" Function deletes the JSON file \"\"\"\n",
    "    try:\n",
    "        os.remove(filepath)\n",
    "        print(f\"File '{filepath}' deleted successfully\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File '{filepath}' not found\")\n",
    "    except PermissionError:\n",
    "        print(f\"Permission denied: '{filepath}'\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "    \n",
    "def get_chunks(suburbs_df) -> dict:\n",
    "    \"\"\"function that splits up postcodes into chunks of 50 so that if we are kicked halfway during scraping we don't lose too much progress\n",
    "    \"\"\"\n",
    "    chunk_dict = {}\n",
    "    \n",
    "    i = 3048\n",
    "    j = 3023  \n",
    "    while i < 3997:\n",
    "        temp = suburbs_df[suburbs_df['postcode'] >= j]\n",
    "        chunk_dict['chunk_{}'.format(i)] = temp[temp['postcode'] <= i]\n",
    "        j += 25\n",
    "        i += 25\n",
    "\n",
    "    return chunk_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk_3048\n",
      "chunk_3073\n",
      "chunk_3098\n",
      "chunk_3123\n",
      "chunk_3148\n",
      "chunk_3173\n",
      "chunk_3198\n",
      "chunk_3223\n",
      "chunk_3248\n",
      "chunk_3273\n",
      "chunk_3298\n",
      "chunk_3323\n",
      "chunk_3348\n",
      "chunk_3373\n",
      "chunk_3398\n",
      "chunk_3423\n",
      "chunk_3448\n",
      "chunk_3473\n",
      "chunk_3498\n",
      "chunk_3523\n",
      "chunk_3548\n",
      "chunk_3573\n",
      "chunk_3598\n",
      "chunk_3623\n",
      "chunk_3648\n",
      "chunk_3673\n",
      "chunk_3698\n",
      "chunk_3723\n",
      "chunk_3748\n",
      "chunk_3773\n",
      "chunk_3798\n",
      "chunk_3823\n",
      "chunk_3848\n",
      "chunk_3873\n",
      "chunk_3898\n",
      "chunk_3923\n",
      "chunk_3948\n",
      "chunk_3973\n"
     ]
    }
   ],
   "source": [
    "chunk_dict = get_chunks(suburbs_df)\n",
    "for i in chunk_dict:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Run cell above\n",
    "2. Run cell below \n",
    "3. Run cell below the cell below\n",
    "4. Run property_metadata.write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working METHOD\n",
    "import re\n",
    "from json import dump\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen, Request\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder.master('local[*]') \\\n",
    "    .config(\"spark.driver.memory\", \"15g\") \\\n",
    "    .config(\"spark.executor.memory\", \"16g\") \\\n",
    "    .appName(\"PropertyScraper\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Constants\n",
    "BASE_URL = \"https://www.domain.com.au\"\n",
    "N_PAGES = range(1, 50)  # Max number of pages you want to scrape  \n",
    "\n",
    "# Load suburbs CSV\n",
    "suburbs_df = pd.read_csv('postcodes.csv')  # Ensure this CSV contains 'suburb' and 'postcode' columns\n",
    "chunk_dict = get_chunks(suburbs_df)\n",
    "\n",
    "def start_scrape(chunk, file_suffix):\n",
    "    \"\"\"Function that scrapes https://www.domain.com.au and outputs the data into a JSON file\n",
    "    \n",
    "    parameters:\n",
    "    chunk: chunk of 50 postcodes we will scrape\n",
    "    file_suffix: what we want to title the end of our files when we write to json\n",
    "    \"\"\"\n",
    "\n",
    "    # Define schema for the Spark DataFrame\n",
    "    schema = StructType([\n",
    "        StructField(\"url\", StringType(), True),\n",
    "        StructField(\"postcode\", StringType(), True),\n",
    "        StructField(\"suburb\", StringType(), True),\n",
    "        StructField(\"name\", StringType(), True),\n",
    "        StructField(\"cost_text\", StringType(), True),\n",
    "        StructField(\"beds\", StringType(), True),  # Separate field for beds\n",
    "        StructField(\"baths\", StringType(), True),  # Separate field for baths\n",
    "        StructField(\"parking\", StringType(), True),  # Parking field\n",
    "        StructField(\"property_type\", StringType(), True),  # Property type field\n",
    "    ])\n",
    "\n",
    "\n",
    "    # Initialize an empty DataFrame with the schema\n",
    "    property_metadata = spark.createDataFrame([], schema)\n",
    "\n",
    "    # Loop through each suburb and its postcode\n",
    "    for index, row in chunk.iterrows():\n",
    "        suburb = row['locality'].lower().replace(' ', '-')  # Convert to lowercase and hyphenate\n",
    "        postcode = row['postcode']\n",
    "\n",
    "        print(f\"Scraping data for {suburb} ({postcode})\")\n",
    "\n",
    "        url_links = []\n",
    "        page_found = False  # This flag will help us track whether any results are found\n",
    "\n",
    "        # Generate list of URLs to visit\n",
    "        for page in N_PAGES:\n",
    "            url = BASE_URL + f\"/rent/{suburb}-vic-{postcode}/?ssubs=0&sort=suburb-asc&page={page}\"\n",
    "            try:\n",
    "                bs_object = BeautifulSoup(urlopen(Request(url, headers={'User-Agent': \"PostmanRuntime/7.6.0\"})), \"lxml\")\n",
    "\n",
    "                # Check if the page has results or shows \"No results found\"\n",
    "                no_results = bs_object.find(text=re.compile(\"No results found\", re.I))\n",
    "                if no_results:\n",
    "                    print(f\"No results found for {suburb} on page {page}. Stopping further scraping for this suburb.\")\n",
    "                    break  # Exit the pagination loop if no results are found\n",
    "\n",
    "                # Find property links\n",
    "                index_links = bs_object.find(\"ul\", {\"data-testid\": \"results\"})\n",
    "                if not index_links:\n",
    "                    print(f\"No more results for {suburb} on page {page}.\")\n",
    "                    break  # Exit pagination if no results list is found (end of pages)\n",
    "\n",
    "                index_links = index_links.findAll(\"a\", href=re.compile(f\"{BASE_URL}/*\"))\n",
    "                page_found = True  # At least one result was found on this page\n",
    "\n",
    "                for link in index_links:\n",
    "                    # If it's a property address, add it to the list\n",
    "                    if 'address' in link.get('class', []):\n",
    "                        url_links.append(link['href'])\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error fetching {url}: {e}\")\n",
    "                break  # Stop if there's an issue with fetching the page\n",
    "\n",
    "        if not page_found:\n",
    "            print(f\"No results for {suburb}. Moving to the next suburb.\")\n",
    "            continue  # Skip to the next suburb if no pages were found for this one\n",
    "\n",
    "        # For each URL, scrape some basic metadata\n",
    "        pbar = tqdm(url_links)\n",
    "        success_count, total_count = 0, 0\n",
    "\n",
    "        for property_url in pbar:\n",
    "            try:\n",
    "                bs_object = BeautifulSoup(urlopen(Request(property_url, headers={'User-Agent': \"PostmanRuntime/7.6.0\"})), \"lxml\")\n",
    "                total_count += 1\n",
    "\n",
    "                # Get property name\n",
    "                name = bs_object.find(\"h1\", {\"class\": \"css-164r41r\"}).text.strip()\n",
    "\n",
    "                # Get cost text\n",
    "                cost_text = bs_object.find(\"div\", {\"data-testid\": \"listing-details__summary-title\"}).text.strip()\n",
    "\n",
    "                # Get rooms (beds and baths)\n",
    "                rooms = bs_object.find(\"div\", {\"data-testid\": \"property-features\"}).findAll(\n",
    "                    \"span\", {\"data-testid\": \"property-features-text-container\"}\n",
    "                )\n",
    "\n",
    "                # Initialize variables\n",
    "                beds, baths, parking = None, None, '0'  # Default value for parking is '0 Car'\n",
    "\n",
    "                for feature in rooms:\n",
    "                    text = feature.text\n",
    "                    if 'Bed' in text:\n",
    "                        beds_match = re.findall(r'\\d+', text)\n",
    "                        if beds_match:\n",
    "                            beds = beds_match[0]  # Extract the number of beds\n",
    "                    elif 'Bath' in text:\n",
    "                        baths_match = re.findall(r'\\d+', text)\n",
    "                        if baths_match:\n",
    "                            baths = baths_match[0]  # Extract the number of baths\n",
    "                    elif 'Car' in text or 'Parking' in text:\n",
    "                        parking_match = re.findall(r'\\d+', text)\n",
    "                        if parking_match:\n",
    "                            parking = parking_match[0]  # Extract the number of parking spaces\n",
    "\n",
    "                property_type_container = bs_object.find(\"div\", {\"data-testid\": \"listing-summary-property-type\"})\n",
    "                property_type = property_type_container.get_text(strip=True)\n",
    "\n",
    "                # Create a row and append it to the DataFrame\n",
    "                row = [(property_url, postcode, suburb, name, cost_text, beds, baths, parking, property_type)]\n",
    "                row_df = spark.createDataFrame(row, schema)\n",
    "                property_metadata = property_metadata.union(row_df)\n",
    "                success_count += 1\n",
    "\n",
    "            except AttributeError:\n",
    "                print(f\"Error scraping {property_url}: missing data\")\n",
    "\n",
    "            pbar.set_description(f\"{(success_count / total_count * 100):.0f}% successful\")\n",
    "\n",
    "        # Show the DataFrame to ensure data is being appended\n",
    "        #property_metadata.show()\n",
    "\n",
    "    # Output to parquet file\n",
    "    try:\n",
    "        property_metadata.write.mode(\"overwrite\").parquet('../data/raw/work_{}.parquet'.format(file_suffix))\n",
    "        print(f\"Data successfully written\")\n",
    "    except Exception as e:\n",
    "       print(f\"An error occured: {e}\")\n",
    "\n",
    "    #added this print statement so that the cell output can be scrollable - it's getting annoying to click the scroll bar >:(\n",
    "    print(\"chunk finished\")\n",
    "    #return property_metadata\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'chunk_3000'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# start scraping by chunks of 50\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#for i in chunk_dict:\u001b[39;00m\n\u001b[1;32m      3\u001b[0m  \u001b[38;5;66;03m#   start_scrape(chunk_dict[i], i.split(\"_\")[1])\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m property_metadata \u001b[38;5;241m=\u001b[39m start_scrape(\u001b[43mchunk_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mchunk_3000\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m3000\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m## changed 3050 , 3050\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'chunk_3000'"
     ]
    }
   ],
   "source": [
    "# start scraping by chunks of 50\n",
    "#for i in chunk_dict:\n",
    " #   start_scrape(chunk_dict[i], i.split(\"_\")[1])\n",
    "property_metadata = start_scrape(chunk_dict['chunk_3000'], '3000')  ## changed 3050 , 3050"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/09/14 17:28:53 WARN DAGScheduler: Broadcasting large task binary with size 6.1 MiB\n",
      "24/09/14 17:28:55 WARN DAGScheduler: Broadcasting large task binary with size 6.1 MiB\n",
      "24/09/14 17:28:55 WARN DAGScheduler: Broadcasting large task binary with size 6.1 MiB\n",
      "24/09/14 17:28:57 WARN DAGScheduler: Broadcasting large task binary with size 6.1 MiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+---------+--------------------+-------------+----+-----+-------+--------------------+\n",
      "|                 url|postcode|   suburb|                name|    cost_text|beds|baths|parking|       property_type|\n",
      "+--------------------+--------+---------+--------------------+-------------+----+-----+-------+--------------------+\n",
      "|https://www.domai...|    3000|melbourne|3113/639 Lonsdale...|    $1,200.00|   3|    2|      1|Apartment / Unit ...|\n",
      "|https://www.domai...|    3000|melbourne|1503/270 King Str...|$850 Per Week|   4|    1|      1|Apartment / Unit ...|\n",
      "|https://www.domai...|    3000|melbourne|403/639 Lonsdale ...| $750per week|   2|    2|      0|Apartment / Unit ...|\n",
      "|https://www.domai...|    3000|melbourne|3409/138 Spencer ...|      $625 pw|   1|    1|      0|Apartment / Unit ...|\n",
      "|https://www.domai...|    3000|melbourne|103/300 Swanston ...|      $620 pw|   1|    1|      1|Apartment / Unit ...|\n",
      "+--------------------+--------+---------+--------------------+-------------+----+-----+-------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "property_metadata.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/09/14 17:29:53 WARN DAGScheduler: Broadcasting large task binary with size 5.5 MiB\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "property_metadata.write.mode(\"overwrite\").parquet(\"../data/raw/work_3000.parquet\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf = spark.read.parquet(\"../data/raw/work_3000.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>url</th><th>postcode</th><th>suburb</th><th>name</th><th>cost_text</th><th>beds</th><th>baths</th><th>parking</th><th>property_type</th></tr>\n",
       "<tr><td>https://www.domai...</td><td>3000</td><td>melbourne</td><td>4307/639 Little L...</td><td>$600 and Fully Fu...</td><td>1</td><td>1</td><td>0</td><td>Apartment / Unit ...</td></tr>\n",
       "<tr><td>https://www.domai...</td><td>3000</td><td>melbourne</td><td>2213/27 Little Co...</td><td>$750 a week and F...</td><td>2</td><td>2</td><td>0</td><td>Apartment / Unit ...</td></tr>\n",
       "<tr><td>https://www.domai...</td><td>3000</td><td>melbourne</td><td>4207/371 Little L...</td><td>$720 per week opp...</td><td>2</td><td>1</td><td>0</td><td>Apartment / Unit ...</td></tr>\n",
       "<tr><td>https://www.domai...</td><td>3000</td><td>melbourne</td><td>99 Franklin Stree...</td><td>Furnished, bills,...</td><td>1</td><td>1</td><td>0</td><td>Apartment / Unit ...</td></tr>\n",
       "<tr><td>https://www.domai...</td><td>3000</td><td>melbourne</td><td>1302/279-283 La T...</td><td>$650 and Fully Fu...</td><td>2</td><td>1</td><td>0</td><td>Apartment / Unit ...</td></tr>\n",
       "<tr><td>https://www.domai...</td><td>3000</td><td>melbourne</td><td>103/19 Exploratio...</td><td>$540 Per Week Inc...</td><td>1</td><td>1</td><td>0</td><td>Studio</td></tr>\n",
       "<tr><td>https://www.domai...</td><td>3000</td><td>melbourne</td><td>913/22-24 Jane Be...</td><td>$520 and Fully Fu...</td><td>1</td><td>1</td><td>1</td><td>Apartment / Unit ...</td></tr>\n",
       "<tr><td>https://www.domai...</td><td>3000</td><td>melbourne</td><td>1202/601 Little C...</td><td>$620 per week, $2...</td><td>2</td><td>1</td><td>0</td><td>Apartment / Unit ...</td></tr>\n",
       "<tr><td>https://www.domai...</td><td>3000</td><td>melbourne</td><td>4211/371 Little L...</td><td>$750 Per Week</td><td>2</td><td>1</td><td>0</td><td>Apartment / Unit ...</td></tr>\n",
       "<tr><td>https://www.domai...</td><td>3000</td><td>melbourne</td><td>1308/138 Spencer ...</td><td>$800 and Fully Fu...</td><td>2</td><td>2</td><td>0</td><td>Apartment / Unit ...</td></tr>\n",
       "<tr><td>https://www.domai...</td><td>3000</td><td>melbourne</td><td>4311/371 Little L...</td><td>$850 per week &amp; A...</td><td>2</td><td>1</td><td>0</td><td>Apartment / Unit ...</td></tr>\n",
       "<tr><td>https://www.domai...</td><td>3000</td><td>melbourne</td><td>3506/228 La Trobe...</td><td>$650 a week and F...</td><td>1</td><td>1</td><td>0</td><td>Apartment / Unit ...</td></tr>\n",
       "<tr><td>https://www.domai...</td><td>3000</td><td>melbourne</td><td>236 La Trobe Stre...</td><td>Furnished, all in...</td><td>1</td><td>1</td><td>0</td><td>Apartment / Unit ...</td></tr>\n",
       "<tr><td>https://www.domai...</td><td>3000</td><td>melbourne</td><td>Level 4, 401B/120...</td><td>$860 furnished/3 ...</td><td>2</td><td>1</td><td>0</td><td>Apartment / Unit ...</td></tr>\n",
       "<tr><td>https://www.domai...</td><td>3000</td><td>melbourne</td><td>405/151 Berkeley ...</td><td>$720 **OPPOSITE T...</td><td>2</td><td>2</td><td>0</td><td>Apartment / Unit ...</td></tr>\n",
       "<tr><td>https://www.domai...</td><td>3000</td><td>melbourne</td><td>4703/568 Collins ...</td><td>$750 a week and F...</td><td>2</td><td>2</td><td>1</td><td>Apartment / Unit ...</td></tr>\n",
       "<tr><td>https://www.domai...</td><td>3000</td><td>melbourne</td><td>1006/442 Elizabet...</td><td>$650 per week and...</td><td>1</td><td>1</td><td>0</td><td>Apartment / Unit ...</td></tr>\n",
       "<tr><td>https://www.domai...</td><td>3000</td><td>melbourne</td><td>1406/22 Jane Bell...</td><td>$795 include bill...</td><td>2</td><td>1</td><td>1</td><td>Apartment / Unit ...</td></tr>\n",
       "<tr><td>https://www.domai...</td><td>3000</td><td>melbourne</td><td>2514/23 Mackenzie...</td><td>$720 per week *Pa...</td><td>2</td><td>1</td><td>0</td><td>Apartment / Unit ...</td></tr>\n",
       "<tr><td>https://www.domai...</td><td>3000</td><td>melbourne</td><td>4302/120 A'Becket...</td><td>$1200 **INSPECTIO...</td><td>3</td><td>2</td><td>0</td><td>Apartment / Unit ...</td></tr>\n",
       "</table>\n",
       "only showing top 20 rows\n"
      ],
      "text/plain": [
       "+--------------------+--------+---------+--------------------+--------------------+----+-----+-------+--------------------+\n",
       "|                 url|postcode|   suburb|                name|           cost_text|beds|baths|parking|       property_type|\n",
       "+--------------------+--------+---------+--------------------+--------------------+----+-----+-------+--------------------+\n",
       "|https://www.domai...|    3000|melbourne|4307/639 Little L...|$600 and Fully Fu...|   1|    1|      0|Apartment / Unit ...|\n",
       "|https://www.domai...|    3000|melbourne|2213/27 Little Co...|$750 a week and F...|   2|    2|      0|Apartment / Unit ...|\n",
       "|https://www.domai...|    3000|melbourne|4207/371 Little L...|$720 per week opp...|   2|    1|      0|Apartment / Unit ...|\n",
       "|https://www.domai...|    3000|melbourne|99 Franklin Stree...|Furnished, bills,...|   1|    1|      0|Apartment / Unit ...|\n",
       "|https://www.domai...|    3000|melbourne|1302/279-283 La T...|$650 and Fully Fu...|   2|    1|      0|Apartment / Unit ...|\n",
       "|https://www.domai...|    3000|melbourne|103/19 Exploratio...|$540 Per Week Inc...|   1|    1|      0|              Studio|\n",
       "|https://www.domai...|    3000|melbourne|913/22-24 Jane Be...|$520 and Fully Fu...|   1|    1|      1|Apartment / Unit ...|\n",
       "|https://www.domai...|    3000|melbourne|1202/601 Little C...|$620 per week, $2...|   2|    1|      0|Apartment / Unit ...|\n",
       "|https://www.domai...|    3000|melbourne|4211/371 Little L...|       $750 Per Week|   2|    1|      0|Apartment / Unit ...|\n",
       "|https://www.domai...|    3000|melbourne|1308/138 Spencer ...|$800 and Fully Fu...|   2|    2|      0|Apartment / Unit ...|\n",
       "|https://www.domai...|    3000|melbourne|4311/371 Little L...|$850 per week & A...|   2|    1|      0|Apartment / Unit ...|\n",
       "|https://www.domai...|    3000|melbourne|3506/228 La Trobe...|$650 a week and F...|   1|    1|      0|Apartment / Unit ...|\n",
       "|https://www.domai...|    3000|melbourne|236 La Trobe Stre...|Furnished, all in...|   1|    1|      0|Apartment / Unit ...|\n",
       "|https://www.domai...|    3000|melbourne|Level 4, 401B/120...|$860 furnished/3 ...|   2|    1|      0|Apartment / Unit ...|\n",
       "|https://www.domai...|    3000|melbourne|405/151 Berkeley ...|$720 **OPPOSITE T...|   2|    2|      0|Apartment / Unit ...|\n",
       "|https://www.domai...|    3000|melbourne|4703/568 Collins ...|$750 a week and F...|   2|    2|      1|Apartment / Unit ...|\n",
       "|https://www.domai...|    3000|melbourne|1006/442 Elizabet...|$650 per week and...|   1|    1|      0|Apartment / Unit ...|\n",
       "|https://www.domai...|    3000|melbourne|1406/22 Jane Bell...|$795 include bill...|   2|    1|      1|Apartment / Unit ...|\n",
       "|https://www.domai...|    3000|melbourne|2514/23 Mackenzie...|$720 per week *Pa...|   2|    1|      0|Apartment / Unit ...|\n",
       "|https://www.domai...|    3000|melbourne|4302/120 A'Becket...|$1200 **INSPECTIO...|   3|    2|      0|Apartment / Unit ...|\n",
       "+--------------------+--------+---------+--------------------+--------------------+----+-----+-------+--------------------+\n",
       "only showing top 20 rows"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = suburbs_df[suburbs_df['postcode'] >= 3950]\n",
    "chunk_dict['chunk_3997'] = temp[temp['postcode'] < 3997]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "postcode = list(range(3001, 4000))  # List of postcodes\n",
    "chunk_size = 50  # Define the chunk size\n",
    "\n",
    "# Loop over the postcodes in chunks of 50\n",
    "for i in range(0, len(postcode), chunk_size):\n",
    "    # Extract a chunk of 50 postcodes\n",
    "    chunk = postcode[i:i + chunk_size]\n",
    "    \n",
    "    # Convert chunk to string or appropriate format for your function\n",
    "    chunk_name = f'chunk_{i // chunk_size + 1}'\n",
    "    \n",
    "    # Call start_scrape function with the chunk\n",
    "    property_metadata = start_scrape(chunk_dict[chunk_name], f'{chunk}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'slice'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/davynr06/Documents/MAST30034/project-2-group-real-estate-industry-project-22/notebooks/Working.ipynb Cell 13'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/davynr06/Documents/MAST30034/project-2-group-real-estate-industry-project-22/notebooks/Working.ipynb#ch0000012?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m chunk_dict[\u001b[39m1\u001b[39;49m:]:\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/davynr06/Documents/MAST30034/project-2-group-real-estate-industry-project-22/notebooks/Working.ipynb#ch0000012?line=1'>2</a>\u001b[0m     start_scrape(chunk_dict[i])\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'slice'"
     ]
    }
   ],
   "source": [
    "for i in chunk_dict[1:]:\n",
    "    start_scrape(chunk_dict[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "[PATH_NOT_FOUND] Path does not exist: file:/home/priscillapei/project-2-group-real-estate-industry-project-22/data/raw/work_3050.json.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 12\u001b[0m\n\u001b[1;32m      1\u001b[0m schema \u001b[38;5;241m=\u001b[39m StructType([\n\u001b[1;32m      2\u001b[0m         StructField(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124murl\u001b[39m\u001b[38;5;124m\"\u001b[39m, StringType(), \u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[1;32m      3\u001b[0m         StructField(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpostcode\u001b[39m\u001b[38;5;124m\"\u001b[39m, StringType(), \u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m         StructField(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproperty_type\u001b[39m\u001b[38;5;124m\"\u001b[39m, StringType(), \u001b[38;5;28;01mTrue\u001b[39;00m),  \u001b[38;5;66;03m# Property type field\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     ])\n\u001b[0;32m---> 12\u001b[0m work \u001b[38;5;241m=\u001b[39m \u001b[43mspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m(\u001b[49m\u001b[43mschema\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../data/raw/work_3050.json\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyspark/sql/readwriter.py:425\u001b[0m, in \u001b[0;36mDataFrameReader.json\u001b[0;34m(self, path, schema, primitivesAsString, prefersDecimal, allowComments, allowUnquotedFieldNames, allowSingleQuotes, allowNumericLeadingZero, allowBackslashEscapingAnyCharacter, mode, columnNameOfCorruptRecord, dateFormat, timestampFormat, multiLine, allowUnquotedControlChars, lineSep, samplingRatio, dropFieldIfAllNull, encoding, locale, pathGlobFilter, recursiveFileLookup, modifiedBefore, modifiedAfter, allowNonNumericNumbers)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(path) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlist\u001b[39m:\n\u001b[1;32m    424\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_spark\u001b[38;5;241m.\u001b[39m_sc\u001b[38;5;241m.\u001b[39m_jvm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 425\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_df(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jreader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_spark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jvm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPythonUtils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoSeq\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    426\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, RDD):\n\u001b[1;32m    428\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfunc\u001b[39m(iterator: Iterable) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterable:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyspark/errors/exceptions/captured.py:185\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    181\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: [PATH_NOT_FOUND] Path does not exist: file:/home/priscillapei/project-2-group-real-estate-industry-project-22/data/raw/work_3050.json."
     ]
    }
   ],
   "source": [
    "\n",
    "schema = StructType([\n",
    "        StructField(\"url\", StringType(), True),\n",
    "        StructField(\"postcode\", StringType(), True),\n",
    "        StructField(\"suburb\", StringType(), True),\n",
    "        StructField(\"name\", StringType(), True),\n",
    "        StructField(\"cost_text\", StringType(), True),\n",
    "        StructField(\"beds\", StringType(), True),  # Separate field for beds\n",
    "        StructField(\"baths\", StringType(), True),  # Separate field for baths\n",
    "        StructField(\"parking\", StringType(), True),  # Parking field\n",
    "        StructField(\"property_type\", StringType(), True),  # Property type field\n",
    "    ])\n",
    "work = spark.read.schema(schema).json('../data/raw/work_3050.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+------+----+---------+----+-----+-------+-------------+\n",
      "|url|postcode|suburb|name|cost_text|beds|baths|parking|property_type|\n",
      "+---+--------+------+----+---------+----+-----+-------+-------------+\n",
      "+---+--------+------+----+---------+----+-----+-------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "work.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  url  postcode   suburb  \\\n",
      "0   https://www.domain.com.au/34-evadene-drive-tar...      3029  tarneit   \n",
      "1   https://www.domain.com.au/434-bethany-road-tar...      3029  tarneit   \n",
      "2   https://www.domain.com.au/58-antonio-road-tarn...      3029  tarneit   \n",
      "3   https://www.domain.com.au/12-lindeman-street-t...      3029  tarneit   \n",
      "4   https://www.domain.com.au/3-imatra-loop-tarnei...      3029  tarneit   \n",
      "5   https://www.domain.com.au/84-lucania-crescent-...      3029  tarneit   \n",
      "6   https://www.domain.com.au/8-keeping-terrace-ta...      3029  tarneit   \n",
      "7   https://www.domain.com.au/40-kamala-drive-tarn...      3029  tarneit   \n",
      "8   https://www.domain.com.au/48-riland-boulevard-...      3029  tarneit   \n",
      "9   https://www.domain.com.au/9-ceremony-drive-tar...      3029  tarneit   \n",
      "10  https://www.domain.com.au/11-ogawa-walk-tarnei...      3029  tarneit   \n",
      "11  https://www.domain.com.au/tarneit-vic-3029-151...      3029  tarneit   \n",
      "\n",
      "                                     name                 cost_text  beds  \\\n",
      "0      34 Evadene Drive, Tarneit VIC 3029             $620 per week     4   \n",
      "1      434 Bethany Road, Tarneit VIC 3029                      $520     3   \n",
      "2       58 Antonio Road, Tarneit VIC 3029             $580 Per Week     4   \n",
      "3    12 Lindeman Street, Tarneit VIC 3029                   $650 pw     4   \n",
      "4         3 Imatra Loop, Tarneit VIC 3029                      $570     4   \n",
      "5   84 Lucania Crescent, Tarneit VIC 3029             Contact Agent     4   \n",
      "6     8 Keeping Terrace, Tarneit VIC 3029            $ 500 PER WEEK     3   \n",
      "7       40 Kamala Drive, Tarneit VIC 3029                      $520     3   \n",
      "8   48 Riland Boulevard, Tarneit VIC 3029                      $520     3   \n",
      "9      9 Ceremony Drive, Tarneit VIC 3029                       610     4   \n",
      "10        11 Ogawa Walk, Tarneit VIC 3029                       530     3   \n",
      "11                       Tarneit VIC 3029  Rent2own with No Deposit     4   \n",
      "\n",
      "    baths  parking property_type  \n",
      "0       3        2         House  \n",
      "1       2        2         House  \n",
      "2       2        2         House  \n",
      "3       2        2         House  \n",
      "4       2        2         House  \n",
      "5       2        2         House  \n",
      "6       2        1         House  \n",
      "7       2        1         House  \n",
      "8       2        1         House  \n",
      "9       2        2         House  \n",
      "10      2        2         House  \n",
      "11      2        2         House  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define the folder path containing JSON files\n",
    "folder_path = '../data/raw/work.json'\n",
    "\n",
    "# List all files in the directory\n",
    "json_files = [f for f in os.listdir(folder_path) if f.endswith('.json')]\n",
    "\n",
    "# Initialize an empty list to store DataFrames\n",
    "dataframes = []\n",
    "\n",
    "# Read each JSON file into a DataFrame\n",
    "for file in json_files:\n",
    "    file_path = os.path.join(folder_path, file)\n",
    "    # Read JSON file\n",
    "    df = pd.read_json(file_path, lines=True)\n",
    "    # Append the DataFrame to the list\n",
    "    dataframes.append(df)\n",
    "\n",
    "# Concatenate all DataFrames into a single DataFrame\n",
    "combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# Display the combined DataFrame\n",
    "print(combined_df.head(12))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please run these code chunks after first running create_chunk(), start_scrape() and run_chunk() methods: \\\n",
    "1st Cell: Davyn \\\n",
    "2nd Cell: Arpan \\\n",
    "3rd Cell: Priscilla \\\n",
    "4th Cell: Rachel \\\n",
    "5th Cell: Nathan \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_chunk(starting_chunk):\n",
    "    i = starting_chunk\n",
    "    # we are running chunks of 25 postcodes 7 times each\n",
    "    while i < starting_chunk + 175:\n",
    "        start_scrape(chunk_dict[\"chunk_{}\".format(i)], i) #i.split(\"_\")[1])\n",
    "        i += 25\n",
    "    if i == 3923:\n",
    "        temp = suburbs_df[suburbs_df['postcode'] >= i + 1]\n",
    "        chunk_dict['chunk_3996'] = temp[temp['postcode'] < 3997]\n",
    "        start_scrape(chunk_dict['chunk_3996'], 3996)\n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Davyn\n",
    "starting_chunk = 3048\n",
    "run_chunk(starting_chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Arpan\n",
    "starting_chunk = 3048 + 175\n",
    "run_chunk(starting_chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping data for beaufort (3373)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_44579/2477479290.py:69: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  no_results = bs_object.find(text=re.compile(\"No results found\", re.I))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No more results for beaufort on page 2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% successful: 100%|██████████| 2/2 [00:03<00:00,  1.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping data for chute (3373)\n",
      "No more results for chute on page 1.\n",
      "No results for chute. Moving to the next suburb.\n",
      "Scraping data for cross-roads (3373)\n",
      "No more results for cross-roads on page 1.\n",
      "No results for cross-roads. Moving to the next suburb.\n",
      "Scraping data for lake-goldsmith (3373)\n",
      "No more results for lake-goldsmith on page 1.\n",
      "No results for lake-goldsmith. Moving to the next suburb.\n",
      "Scraping data for lake-wongan (3373)\n",
      "No more results for lake-wongan on page 1.\n",
      "No results for lake-wongan. Moving to the next suburb.\n",
      "Scraping data for main-lead (3373)\n",
      "No more results for main-lead on page 1.\n",
      "No results for main-lead. Moving to the next suburb.\n",
      "Scraping data for mena-park (3373)\n",
      "No more results for mena-park on page 1.\n",
      "No results for mena-park. Moving to the next suburb.\n",
      "Scraping data for nerring (3373)\n",
      "No more results for nerring on page 1.\n",
      "No results for nerring. Moving to the next suburb.\n",
      "Scraping data for raglan (3373)\n",
      "No more results for raglan on page 1.\n",
      "No results for raglan. Moving to the next suburb.\n",
      "Scraping data for shirley (3373)\n",
      "Error fetching https://www.domain.com.au/rent/shirley-vic-3373/?ssubs=0&sort=suburb-asc&page=1: HTTP Error 404: Not Found\n",
      "No results for shirley. Moving to the next suburb.\n",
      "Scraping data for stockyard-hill (3373)\n",
      "No more results for stockyard-hill on page 1.\n",
      "No results for stockyard-hill. Moving to the next suburb.\n",
      "Scraping data for stoneleigh (3373)\n",
      "No more results for stoneleigh on page 1.\n",
      "No results for stoneleigh. Moving to the next suburb.\n",
      "Scraping data for trawalla (3373)\n",
      "No more results for trawalla on page 1.\n",
      "No results for trawalla. Moving to the next suburb.\n",
      "Scraping data for waterloo (3373)\n",
      "No more results for waterloo on page 1.\n",
      "No results for waterloo. Moving to the next suburb.\n",
      "Scraping data for great-western (3374)\n",
      "No more results for great-western on page 1.\n",
      "No results for great-western. Moving to the next suburb.\n",
      "Scraping data for ballyrogan (3375)\n",
      "No more results for ballyrogan on page 1.\n",
      "No results for ballyrogan. Moving to the next suburb.\n",
      "Scraping data for bayindeen (3375)\n",
      "No more results for bayindeen on page 1.\n",
      "No results for bayindeen. Moving to the next suburb.\n",
      "Scraping data for buangor (3375)\n",
      "No more results for buangor on page 1.\n",
      "No results for buangor. Moving to the next suburb.\n",
      "Scraping data for middle-creek (3375)\n",
      "No more results for middle-creek on page 1.\n",
      "No results for middle-creek. Moving to the next suburb.\n",
      "Scraping data for amphitheatre (3377)\n",
      "Error fetching https://www.domain.com.au/rent/amphitheatre-vic-3377/?ssubs=0&sort=suburb-asc&page=1: HTTP Error 404: Not Found\n",
      "No results for amphitheatre. Moving to the next suburb.\n",
      "Scraping data for ararat (3377)\n",
      "No more results for ararat on page 2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% successful: 100%|██████████| 9/9 [00:10<00:00,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping data for ararat-east (3377)\n",
      "Error fetching https://www.domain.com.au/rent/ararat-east-vic-3377/?ssubs=0&sort=suburb-asc&page=1: HTTP Error 404: Not Found\n",
      "No results for ararat-east. Moving to the next suburb.\n",
      "Scraping data for armstrong (3377)\n",
      "No more results for armstrong on page 2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% successful: 100%|██████████| 1/1 [00:01<00:00,  1.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping data for ben-nevis (3377)\n",
      "Error fetching https://www.domain.com.au/rent/ben-nevis-vic-3377/?ssubs=0&sort=suburb-asc&page=1: HTTP Error 404: Not Found\n",
      "No results for ben-nevis. Moving to the next suburb.\n",
      "Scraping data for bulgana (3377)\n",
      "No more results for bulgana on page 1.\n",
      "No results for bulgana. Moving to the next suburb.\n",
      "Scraping data for cathcart (3377)\n",
      "No more results for cathcart on page 1.\n",
      "No results for cathcart. Moving to the next suburb.\n",
      "Scraping data for crowlands (3377)\n",
      "No more results for crowlands on page 1.\n",
      "No results for crowlands. Moving to the next suburb.\n",
      "Scraping data for denicull-creek (3377)\n",
      "No more results for denicull-creek on page 1.\n",
      "No results for denicull-creek. Moving to the next suburb.\n",
      "Scraping data for dobie (3377)\n",
      "No more results for dobie on page 1.\n",
      "No results for dobie. Moving to the next suburb.\n",
      "Scraping data for dunneworthy (3377)\n",
      "No more results for dunneworthy on page 1.\n",
      "No results for dunneworthy. Moving to the next suburb.\n",
      "Scraping data for eversley (3377)\n",
      "No more results for eversley on page 1.\n",
      "No results for eversley. Moving to the next suburb.\n",
      "Scraping data for great-western (3377)\n",
      "No more results for great-western on page 1.\n",
      "No results for great-western. Moving to the next suburb.\n",
      "Scraping data for jallukur (3377)\n",
      "Error fetching https://www.domain.com.au/rent/jallukur-vic-3377/?ssubs=0&sort=suburb-asc&page=1: HTTP Error 404: Not Found\n",
      "No results for jallukur. Moving to the next suburb.\n",
      "Scraping data for langi-logan (3377)\n",
      "No more results for langi-logan on page 1.\n",
      "No results for langi-logan. Moving to the next suburb.\n",
      "Scraping data for maroona (3377)\n",
      "No more results for maroona on page 1.\n",
      "No results for maroona. Moving to the next suburb.\n",
      "Scraping data for mount-cole (3377)\n",
      "No more results for mount-cole on page 1.\n",
      "No results for mount-cole. Moving to the next suburb.\n",
      "Scraping data for mount-cole-creek (3377)\n",
      "No more results for mount-cole-creek on page 1.\n",
      "No results for mount-cole-creek. Moving to the next suburb.\n",
      "Scraping data for mount-lonarch (3377)\n",
      "Error fetching https://www.domain.com.au/rent/mount-lonarch-vic-3377/?ssubs=0&sort=suburb-asc&page=1: HTTP Error 404: Not Found\n",
      "No results for mount-lonarch. Moving to the next suburb.\n",
      "Scraping data for moyston (3377)\n",
      "No more results for moyston on page 1.\n",
      "No results for moyston. Moving to the next suburb.\n",
      "Scraping data for norval (3377)\n",
      "No more results for norval on page 1.\n",
      "No results for norval. Moving to the next suburb.\n",
      "Scraping data for rhymney (3377)\n",
      "No more results for rhymney on page 1.\n",
      "No results for rhymney. Moving to the next suburb.\n",
      "Scraping data for rocky-point (3377)\n",
      "No more results for rocky-point on page 1.\n",
      "No results for rocky-point. Moving to the next suburb.\n",
      "Scraping data for rossbridge (3377)\n",
      "No more results for rossbridge on page 1.\n",
      "No results for rossbridge. Moving to the next suburb.\n",
      "Scraping data for shays-flat (3377)\n",
      "No more results for shays-flat on page 1.\n",
      "No results for shays-flat. Moving to the next suburb.\n",
      "Scraping data for warrak (3377)\n",
      "No more results for warrak on page 1.\n",
      "No results for warrak. Moving to the next suburb.\n",
      "Scraping data for tatyoon (3378)\n",
      "No more results for tatyoon on page 1.\n",
      "No results for tatyoon. Moving to the next suburb.\n",
      "Scraping data for yalla-y-poora (3378)\n",
      "No more results for yalla-y-poora on page 1.\n",
      "No results for yalla-y-poora. Moving to the next suburb.\n",
      "Scraping data for berrambool (3379)\n",
      "Error fetching https://www.domain.com.au/rent/berrambool-vic-3379/?ssubs=0&sort=suburb-asc&page=1: HTTP Error 404: Not Found\n",
      "No results for berrambool. Moving to the next suburb.\n",
      "Scraping data for bornes-hill (3379)\n",
      "No more results for bornes-hill on page 1.\n",
      "No results for bornes-hill. Moving to the next suburb.\n",
      "Scraping data for chatsworth (3379)\n",
      "No more results for chatsworth on page 1.\n",
      "No results for chatsworth. Moving to the next suburb.\n",
      "Scraping data for mafeking (3379)\n",
      "No more results for mafeking on page 1.\n",
      "No results for mafeking. Moving to the next suburb.\n",
      "Scraping data for stavely (3379)\n",
      "No more results for stavely on page 1.\n",
      "No results for stavely. Moving to the next suburb.\n",
      "Scraping data for watgania (3379)\n",
      "Error fetching https://www.domain.com.au/rent/watgania-vic-3379/?ssubs=0&sort=suburb-asc&page=1: HTTP Error 404: Not Found\n",
      "No results for watgania. Moving to the next suburb.\n",
      "Scraping data for wickliffe (3379)\n",
      "No more results for wickliffe on page 1.\n",
      "No results for wickliffe. Moving to the next suburb.\n",
      "Scraping data for willaura (3379)\n",
      "No more results for willaura on page 1.\n",
      "No results for willaura. Moving to the next suburb.\n",
      "Scraping data for willaura-north (3379)\n",
      "No more results for willaura-north on page 1.\n",
      "No results for willaura-north. Moving to the next suburb.\n",
      "Scraping data for bellellen (3380)\n",
      "No more results for bellellen on page 1.\n",
      "No results for bellellen. Moving to the next suburb.\n",
      "Scraping data for bridge-inn (3380)\n",
      "Error fetching https://www.domain.com.au/rent/bridge-inn-vic-3380/?ssubs=0&sort=suburb-asc&page=1: HTTP Error 404: Not Found\n",
      "No results for bridge-inn. Moving to the next suburb.\n",
      "Scraping data for mokepilly (3380)\n",
      "No more results for mokepilly on page 1.\n",
      "No results for mokepilly. Moving to the next suburb.\n",
      "Scraping data for stawell (3380)\n",
      "No more results for stawell on page 2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% successful: 100%|██████████| 6/6 [00:06<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping data for stawell-west (3380)\n",
      "Error fetching https://www.domain.com.au/rent/stawell-west-vic-3380/?ssubs=0&sort=suburb-asc&page=1: HTTP Error 404: Not Found\n",
      "No results for stawell-west. Moving to the next suburb.\n",
      "Scraping data for winjallok (3380)\n",
      "No more results for winjallok on page 1.\n",
      "No results for winjallok. Moving to the next suburb.\n",
      "Scraping data for barkly (3381)\n",
      "Error fetching https://www.domain.com.au/rent/barkly-vic-3381/?ssubs=0&sort=suburb-asc&page=1: HTTP Error 404: Not Found\n",
      "No results for barkly. Moving to the next suburb.\n",
      "Scraping data for bellellen (3381)\n",
      "No more results for bellellen on page 1.\n",
      "No results for bellellen. Moving to the next suburb.\n",
      "Scraping data for bellfield (3381)\n",
      "No more results for bellfield on page 1.\n",
      "No results for bellfield. Moving to the next suburb.\n",
      "Scraping data for black-range (3381)\n",
      "No more results for black-range on page 1.\n",
      "No results for black-range. Moving to the next suburb.\n",
      "Scraping data for bolangum (3381)\n",
      "No more results for bolangum on page 1.\n",
      "No results for bolangum. Moving to the next suburb.\n",
      "Scraping data for callawadda (3381)\n",
      "No more results for callawadda on page 1.\n",
      "No results for callawadda. Moving to the next suburb.\n",
      "Scraping data for campbells-bridge (3381)\n",
      "No more results for campbells-bridge on page 1.\n",
      "No results for campbells-bridge. Moving to the next suburb.\n",
      "Scraping data for concongella (3381)\n",
      "No more results for concongella on page 1.\n",
      "No results for concongella. Moving to the next suburb.\n",
      "Scraping data for deep-lead (3381)\n",
      "No more results for deep-lead on page 1.\n",
      "No results for deep-lead. Moving to the next suburb.\n",
      "Scraping data for fyans-creek (3381)\n",
      "No more results for fyans-creek on page 1.\n",
      "No results for fyans-creek. Moving to the next suburb.\n",
      "Scraping data for germania (3381)\n",
      "No more results for germania on page 1.\n",
      "No results for germania. Moving to the next suburb.\n",
      "Scraping data for greens-creek (3381)\n",
      "No more results for greens-creek on page 1.\n",
      "No results for greens-creek. Moving to the next suburb.\n",
      "Scraping data for halls-gap (3381)\n",
      "No more results for halls-gap on page 1.\n",
      "No results for halls-gap. Moving to the next suburb.\n",
      "Scraping data for illawarra (3381)\n",
      "No more results for illawarra on page 1.\n",
      "No results for illawarra. Moving to the next suburb.\n",
      "Scraping data for joel-joel (3381)\n",
      "No more results for joel-joel on page 1.\n",
      "No results for joel-joel. Moving to the next suburb.\n",
      "Scraping data for joel-south (3381)\n",
      "No more results for joel-south on page 1.\n",
      "No results for joel-south. Moving to the next suburb.\n",
      "Scraping data for kanya (3381)\n",
      "No more results for kanya on page 1.\n",
      "No results for kanya. Moving to the next suburb.\n",
      "Scraping data for lake-fyans (3381)\n",
      "No more results for lake-fyans on page 1.\n",
      "No results for lake-fyans. Moving to the next suburb.\n",
      "Scraping data for lake-lonsdale (3381)\n",
      "No more results for lake-lonsdale on page 1.\n",
      "No results for lake-lonsdale. Moving to the next suburb.\n",
      "Scraping data for lubeck (3381)\n",
      "No more results for lubeck on page 1.\n",
      "No results for lubeck. Moving to the next suburb.\n",
      "Scraping data for mokepilly (3381)\n",
      "No more results for mokepilly on page 1.\n",
      "No results for mokepilly. Moving to the next suburb.\n",
      "Scraping data for morrl-morrl (3381)\n",
      "No more results for morrl-morrl on page 1.\n",
      "No results for morrl-morrl. Moving to the next suburb.\n",
      "Scraping data for mount-dryden (3381)\n",
      "No more results for mount-dryden on page 1.\n",
      "No results for mount-dryden. Moving to the next suburb.\n",
      "Scraping data for paradise (3381)\n",
      "No more results for paradise on page 1.\n",
      "No results for paradise. Moving to the next suburb.\n",
      "Scraping data for pomonal (3381)\n",
      "No more results for pomonal on page 1.\n",
      "No results for pomonal. Moving to the next suburb.\n",
      "Scraping data for rostron (3381)\n",
      "No more results for rostron on page 1.\n",
      "No results for rostron. Moving to the next suburb.\n",
      "Scraping data for wal-wal (3381)\n",
      "No more results for wal-wal on page 1.\n",
      "No results for wal-wal. Moving to the next suburb.\n",
      "Scraping data for wallaloo (3381)\n",
      "No more results for wallaloo on page 1.\n",
      "No results for wallaloo. Moving to the next suburb.\n",
      "Scraping data for wallaloo-east (3381)\n",
      "No more results for wallaloo-east on page 1.\n",
      "No results for wallaloo-east. Moving to the next suburb.\n",
      "Scraping data for barkly (3384)\n",
      "No more results for barkly on page 1.\n",
      "No results for barkly. Moving to the next suburb.\n",
      "Scraping data for concongella (3384)\n",
      "No more results for concongella on page 1.\n",
      "No results for concongella. Moving to the next suburb.\n",
      "Scraping data for frenchmans (3384)\n",
      "No more results for frenchmans on page 1.\n",
      "No results for frenchmans. Moving to the next suburb.\n",
      "Scraping data for joel-joel (3384)\n",
      "No more results for joel-joel on page 1.\n",
      "No results for joel-joel. Moving to the next suburb.\n",
      "Scraping data for joel-south (3384)\n",
      "No more results for joel-south on page 1.\n",
      "No results for joel-south. Moving to the next suburb.\n",
      "Scraping data for landsborough (3384)\n",
      "No more results for landsborough on page 1.\n",
      "No results for landsborough. Moving to the next suburb.\n",
      "Scraping data for landsborough-west (3384)\n",
      "No more results for landsborough-west on page 1.\n",
      "No results for landsborough-west. Moving to the next suburb.\n",
      "Scraping data for navarre (3384)\n",
      "No more results for navarre on page 1.\n",
      "No results for navarre. Moving to the next suburb.\n",
      "Scraping data for shays-flat (3384)\n",
      "No more results for shays-flat on page 1.\n",
      "No results for shays-flat. Moving to the next suburb.\n",
      "Scraping data for tulkara (3384)\n",
      "No more results for tulkara on page 1.\n",
      "No results for tulkara. Moving to the next suburb.\n",
      "Scraping data for wattle-creek (3384)\n",
      "No more results for wattle-creek on page 1.\n",
      "No results for wattle-creek. Moving to the next suburb.\n",
      "Scraping data for dadswells-bridge (3385)\n",
      "No more results for dadswells-bridge on page 1.\n",
      "No results for dadswells-bridge. Moving to the next suburb.\n",
      "Scraping data for deep-lead (3385)\n",
      "No more results for deep-lead on page 1.\n",
      "No results for deep-lead. Moving to the next suburb.\n",
      "Scraping data for glenorchy (3385)\n",
      "No more results for glenorchy on page 1.\n",
      "No results for glenorchy. Moving to the next suburb.\n",
      "Scraping data for ledcourt (3385)\n",
      "No more results for ledcourt on page 1.\n",
      "No results for ledcourt. Moving to the next suburb.\n",
      "Scraping data for lubeck (3385)\n",
      "No more results for lubeck on page 1.\n",
      "No results for lubeck. Moving to the next suburb.\n",
      "Scraping data for riachella (3385)\n",
      "No more results for riachella on page 1.\n",
      "No results for riachella. Moving to the next suburb.\n",
      "Scraping data for roses-gap (3385)\n",
      "No more results for roses-gap on page 1.\n",
      "No results for roses-gap. Moving to the next suburb.\n",
      "Scraping data for wal-wal (3385)\n",
      "No more results for wal-wal on page 1.\n",
      "No results for wal-wal. Moving to the next suburb.\n",
      "Scraping data for bolangum (3387)\n",
      "No more results for bolangum on page 1.\n",
      "No results for bolangum. Moving to the next suburb.\n",
      "Scraping data for callawadda (3387)\n",
      "No more results for callawadda on page 1.\n",
      "No results for callawadda. Moving to the next suburb.\n",
      "Scraping data for campbells-bridge (3387)\n",
      "No more results for campbells-bridge on page 1.\n",
      "No results for campbells-bridge. Moving to the next suburb.\n",
      "Scraping data for germania (3387)\n",
      "No more results for germania on page 1.\n",
      "No results for germania. Moving to the next suburb.\n",
      "Scraping data for greens-creek (3387)\n",
      "No more results for greens-creek on page 1.\n",
      "No results for greens-creek. Moving to the next suburb.\n",
      "Scraping data for kanya (3387)\n",
      "No more results for kanya on page 1.\n",
      "No results for kanya. Moving to the next suburb.\n",
      "Scraping data for marnoo (3387)\n",
      "No more results for marnoo on page 1.\n",
      "No results for marnoo. Moving to the next suburb.\n",
      "Scraping data for marnoo-west (3387)\n",
      "No more results for marnoo-west on page 1.\n",
      "No results for marnoo-west. Moving to the next suburb.\n",
      "Scraping data for morrl-morrl (3387)\n",
      "No more results for morrl-morrl on page 1.\n",
      "No results for morrl-morrl. Moving to the next suburb.\n",
      "Scraping data for wallaloo (3387)\n",
      "No more results for wallaloo on page 1.\n",
      "No results for wallaloo. Moving to the next suburb.\n",
      "Scraping data for wallaloo-east (3387)\n",
      "No more results for wallaloo-east on page 1.\n",
      "No results for wallaloo-east. Moving to the next suburb.\n",
      "Scraping data for banyena (3388)\n",
      "No more results for banyena on page 1.\n",
      "No results for banyena. Moving to the next suburb.\n",
      "Scraping data for rupanyup (3388)\n",
      "No more results for rupanyup on page 1.\n",
      "No results for rupanyup. Moving to the next suburb.\n",
      "Scraping data for kewell (3390)\n",
      "No more results for kewell on page 1.\n",
      "No results for kewell. Moving to the next suburb.\n",
      "Scraping data for murtoa (3390)\n",
      "No more results for murtoa on page 1.\n",
      "No results for murtoa. Moving to the next suburb.\n",
      "Scraping data for brim (3391)\n",
      "No more results for brim on page 1.\n",
      "No results for brim. Moving to the next suburb.\n",
      "Scraping data for boolite (3392)\n",
      "No more results for boolite on page 1.\n",
      "No results for boolite. Moving to the next suburb.\n",
      "Scraping data for minyip (3392)\n",
      "No more results for minyip on page 1.\n",
      "No results for minyip. Moving to the next suburb.\n",
      "Scraping data for sheep-hills (3392)\n",
      "No more results for sheep-hills on page 1.\n",
      "No results for sheep-hills. Moving to the next suburb.\n",
      "Scraping data for ailsa (3393)\n",
      "No more results for ailsa on page 1.\n",
      "No results for ailsa. Moving to the next suburb.\n",
      "Scraping data for angip (3393)\n",
      "Error fetching https://www.domain.com.au/rent/angip-vic-3393/?ssubs=0&sort=suburb-asc&page=1: HTTP Error 404: Not Found\n",
      "No results for angip. Moving to the next suburb.\n",
      "Scraping data for aubrey (3393)\n",
      "No more results for aubrey on page 1.\n",
      "No results for aubrey. Moving to the next suburb.\n",
      "Scraping data for bangerang (3393)\n",
      "No more results for bangerang on page 1.\n",
      "No results for bangerang. Moving to the next suburb.\n",
      "Scraping data for cannum (3393)\n",
      "No more results for cannum on page 1.\n",
      "No results for cannum. Moving to the next suburb.\n",
      "Scraping data for crymelon (3393)\n",
      "No more results for crymelon on page 1.\n",
      "No results for crymelon. Moving to the next suburb.\n",
      "Scraping data for kellalac (3393)\n",
      "No more results for kellalac on page 1.\n",
      "No results for kellalac. Moving to the next suburb.\n",
      "Scraping data for lah (3393)\n",
      "No more results for lah on page 1.\n",
      "No results for lah. Moving to the next suburb.\n",
      "Scraping data for warracknabeal (3393)\n",
      "No more results for warracknabeal on page 2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% successful: 100%|██████████| 2/2 [00:03<00:00,  1.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping data for wilkur (3393)\n",
      "No more results for wilkur on page 1.\n",
      "No results for wilkur. Moving to the next suburb.\n",
      "Scraping data for willenabrina (3393)\n",
      "No more results for willenabrina on page 1.\n",
      "No results for willenabrina. Moving to the next suburb.\n",
      "Scraping data for beulah (3395)\n",
      "No more results for beulah on page 1.\n",
      "No results for beulah. Moving to the next suburb.\n",
      "Scraping data for kenmare (3395)\n",
      "No more results for kenmare on page 1.\n",
      "No results for kenmare. Moving to the next suburb.\n",
      "Scraping data for reedy-dam (3395)\n",
      "No more results for reedy-dam on page 1.\n",
      "No results for reedy-dam. Moving to the next suburb.\n",
      "Scraping data for rosebery (3395)\n",
      "No more results for rosebery on page 1.\n",
      "No results for rosebery. Moving to the next suburb.\n",
      "Scraping data for hopetoun (3396)\n",
      "No more results for hopetoun on page 2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% successful: 100%|██████████| 2/2 [00:02<00:00,  1.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping data for hopevale (3396)\n",
      "Error fetching https://www.domain.com.au/rent/hopevale-vic-3396/?ssubs=0&sort=suburb-asc&page=1: HTTP Error 404: Not Found\n",
      "No results for hopevale. Moving to the next suburb.\n",
      "Scraping data for yarto (3396)\n",
      "Error fetching https://www.domain.com.au/rent/yarto-vic-3396/?ssubs=0&sort=suburb-asc&page=1: HTTP Error 404: Not Found\n",
      "No results for yarto. Moving to the next suburb.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully written\n",
      "chunk finished\n",
      "Scraping data for jung (3399)\n",
      "Error fetching https://www.domain.com.au/rent/jung-vic-3399/?ssubs=0&sort=suburb-asc&page=1: HTTP Error 404: Not Found\n",
      "No results for jung. Moving to the next suburb.\n",
      "Scraping data for longerenong (3399)\n",
      "Error fetching https://www.domain.com.au/rent/longerenong-vic-3399/?ssubs=0&sort=suburb-asc&page=1: HTTP Error 404: Not Found\n",
      "No results for longerenong. Moving to the next suburb.\n",
      "Scraping data for brimpaen (3400)\n",
      "Error fetching https://www.domain.com.au/rent/brimpaen-vic-3400/?ssubs=0&sort=suburb-asc&page=1: HTTP Error 404: Not Found\n",
      "No results for brimpaen. Moving to the next suburb.\n",
      "Scraping data for horsham (3400)\n",
      "No more results for horsham on page 3.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% successful: 100%|██████████| 24/24 [00:35<00:00,  1.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping data for horsham-west (3400)\n",
      "Error fetching https://www.domain.com.au/rent/horsham-west-vic-3400/?ssubs=0&sort=suburb-asc&page=1: HTTP Error 404: Not Found\n",
      "No results for horsham-west. Moving to the next suburb.\n",
      "Scraping data for st-helens-plains (3400)\n",
      "Error fetching https://www.domain.com.au/rent/st-helens-plains-vic-3400/?ssubs=0&sort=suburb-asc&page=1: HTTP Error 404: Not Found\n",
      "No results for st-helens-plains. Moving to the next suburb.\n",
      "Scraping data for wartook (3400)\n",
      "Error fetching https://www.domain.com.au/rent/wartook-vic-3400/?ssubs=0&sort=suburb-asc&page=1: HTTP Error 404: Not Found\n",
      "No results for wartook. Moving to the next suburb.\n",
      "Scraping data for wonwondah-east (3400)\n",
      "Error fetching https://www.domain.com.au/rent/wonwondah-east-vic-3400/?ssubs=0&sort=suburb-asc&page=1: HTTP Error 404: Not Found\n",
      "No results for wonwondah-east. Moving to the next suburb.\n",
      "Scraping data for wonwondah-south (3400)\n",
      "Error fetching https://www.domain.com.au/rent/wonwondah-south-vic-3400/?ssubs=0&sort=suburb-asc&page=1: HTTP Error 404: Not Found\n",
      "No results for wonwondah-south. Moving to the next suburb.\n",
      "Scraping data for blackheath (3401)\n",
      "No more results for blackheath on page 1.\n",
      "No results for blackheath. Moving to the next suburb.\n",
      "Scraping data for brimpaen (3401)\n",
      "No more results for brimpaen on page 1.\n",
      "No results for brimpaen. Moving to the next suburb.\n",
      "Scraping data for bungalally (3401)\n",
      "No more results for bungalally on page 1.\n",
      "No results for bungalally. Moving to the next suburb.\n",
      "Scraping data for cherrypool (3401)\n",
      "No more results for cherrypool on page 1.\n",
      "No results for cherrypool. Moving to the next suburb.\n",
      "Scraping data for clear-lake (3401)\n",
      "Error fetching https://www.domain.com.au/rent/clear-lake-vic-3401/?ssubs=0&sort=suburb-asc&page=1: HTTP Error 404: Not Found\n",
      "No results for clear-lake. Moving to the next suburb.\n",
      "Scraping data for connangorach (3401)\n",
      "Error fetching https://www.domain.com.au/rent/connangorach-vic-3401/?ssubs=0&sort=suburb-asc&page=1: HTTP Error 404: Not Found\n",
      "No results for connangorach. Moving to the next suburb.\n",
      "Scraping data for dahlen (3401)\n",
      "Error fetching https://www.domain.com.au/rent/dahlen-vic-3401/?ssubs=0&sort=suburb-asc&page=1: HTTP Error 404: Not Found\n",
      "No results for dahlen. Moving to the next suburb.\n",
      "Scraping data for dooen (3401)\n",
      "No more results for dooen on page 1.\n",
      "No results for dooen. Moving to the next suburb.\n",
      "Scraping data for douglas (3401)\n",
      "Error fetching https://www.domain.com.au/rent/douglas-vic-3401/?ssubs=0&sort=suburb-asc&page=1: HTTP Error 404: Not Found\n",
      "No results for douglas. Moving to the next suburb.\n",
      "Scraping data for drung (3401)\n",
      "No more results for drung on page 1.\n",
      "No results for drung. Moving to the next suburb.\n",
      "Scraping data for green-lake (3401)\n",
      "Error fetching https://www.domain.com.au/rent/green-lake-vic-3401/?ssubs=0&sort=suburb-asc&page=1: HTTP Error 404: Not Found\n",
      "No results for green-lake. Moving to the next suburb.\n",
      "Scraping data for gymbowen (3401)\n",
      "No more results for gymbowen on page 1.\n",
      "No results for gymbowen. Moving to the next suburb.\n",
      "Scraping data for haven (3401)\n",
      "No more results for haven on page 1.\n",
      "No results for haven. Moving to the next suburb.\n",
      "Scraping data for horsham (3401)\n",
      "Error fetching https://www.domain.com.au/rent/horsham-vic-3401/?ssubs=0&sort=suburb-asc&page=1: HTTP Error 404: Not Found\n",
      "No results for horsham. Moving to the next suburb.\n",
      "Scraping data for jallumba (3401)\n",
      "Error fetching https://www.domain.com.au/rent/jallumba-vic-3401/?ssubs=0&sort=suburb-asc&page=1: HTTP Error 404: Not Found\n",
      "No results for jallumba. Moving to the next suburb.\n",
      "Scraping data for jilpanger (3401)\n",
      "Error fetching https://www.domain.com.au/rent/jilpanger-vic-3401/?ssubs=0&sort=suburb-asc&page=1: HTTP Error 404: Not Found\n",
      "No results for jilpanger. Moving to the next suburb.\n",
      "Scraping data for jung (3401)\n",
      "No more results for jung on page 1.\n",
      "No results for jung. Moving to the next suburb.\n",
      "Scraping data for kalkee (3401)\n",
      "No more results for kalkee on page 1.\n",
      "No results for kalkee. Moving to the next suburb.\n",
      "Scraping data for kanagulk (3401)\n",
      "No more results for kanagulk on page 1.\n",
      "No results for kanagulk. Moving to the next suburb.\n",
      "Scraping data for karnak (3401)\n",
      "No more results for karnak on page 1.\n",
      "No results for karnak. Moving to the next suburb.\n",
      "Scraping data for laharum (3401)\n",
      "No more results for laharum on page 1.\n",
      "No results for laharum. Moving to the next suburb.\n",
      "Scraping data for longerenong (3401)\n",
      "No more results for longerenong on page 1.\n",
      "No results for longerenong. Moving to the next suburb.\n",
      "Scraping data for lower-norton (3401)\n",
      "No more results for lower-norton on page 1.\n",
      "No results for lower-norton. Moving to the next suburb.\n",
      "Scraping data for mckenzie-creek (3401)\n",
      "No more results for mckenzie-creek on page 1.\n",
      "No results for mckenzie-creek. Moving to the next suburb.\n",
      "Scraping data for miga-lake (3401)\n",
      "Error fetching https://www.domain.com.au/rent/miga-lake-vic-3401/?ssubs=0&sort=suburb-asc&page=1: HTTP Error 404: Not Found\n",
      "No results for miga-lake. Moving to the next suburb.\n",
      "Scraping data for mitre (3401)\n",
      "Error fetching https://www.domain.com.au/rent/mitre-vic-3401/?ssubs=0&sort=suburb-asc&page=1: HTTP Error 404: Not Found\n",
      "No results for mitre. Moving to the next suburb.\n",
      "Scraping data for mockinya (3401)\n",
      "No more results for mockinya on page 1.\n",
      "No results for mockinya. Moving to the next suburb.\n",
      "Scraping data for murra-warra (3401)\n",
      "No more results for murra-warra on page 1.\n",
      "No results for murra-warra. Moving to the next suburb.\n",
      "Scraping data for noradjuha (3401)\n",
      "Error fetching https://www.domain.com.au/rent/noradjuha-vic-3401/?ssubs=0&sort=suburb-asc&page=1: HTTP Error 404: Not Found\n",
      "No results for noradjuha. Moving to the next suburb.\n",
      "Scraping data for nurcoung (3401)\n",
      "No more results for nurcoung on page 1.\n",
      "No results for nurcoung. Moving to the next suburb.\n",
      "Scraping data for nurrabiel (3401)\n",
      "No more results for nurrabiel on page 1.\n",
      "No results for nurrabiel. Moving to the next suburb.\n",
      "Scraping data for pimpinio (3401)\n",
      "No more results for pimpinio on page 1.\n",
      "No results for pimpinio. Moving to the next suburb.\n",
      "Scraping data for quantong (3401)\n",
      "No more results for quantong on page 1.\n",
      "No results for quantong. Moving to the next suburb.\n",
      "Scraping data for remlaw (3401)\n",
      "Error fetching https://www.domain.com.au/rent/remlaw-vic-3401/?ssubs=0&sort=suburb-asc&page=1: HTTP Error 404: Not Found\n",
      "No results for remlaw. Moving to the next suburb.\n",
      "Scraping data for riverside (3401)\n",
      "No more results for riverside on page 1.\n",
      "No results for riverside. Moving to the next suburb.\n",
      "Scraping data for rocklands (3401)\n",
      "No more results for rocklands on page 1.\n",
      "No results for rocklands. Moving to the next suburb.\n",
      "Scraping data for rocklands (3401)\n",
      "No more results for rocklands on page 1.\n",
      "No results for rocklands. Moving to the next suburb.\n",
      "Scraping data for st-helens-plains (3401)\n",
      "No more results for st-helens-plains on page 1.\n",
      "No results for st-helens-plains. Moving to the next suburb.\n",
      "Scraping data for telangatuk-east (3401)\n",
      "No more results for telangatuk-east on page 1.\n",
      "No results for telangatuk-east. Moving to the next suburb.\n",
      "Scraping data for tooan (3401)\n",
      "Error fetching https://www.domain.com.au/rent/tooan-vic-3401/?ssubs=0&sort=suburb-asc&page=1: HTTP Error 404: Not Found\n",
      "No results for tooan. Moving to the next suburb.\n",
      "Scraping data for toolondo (3401)\n",
      "No more results for toolondo on page 1.\n",
      "No results for toolondo. Moving to the next suburb.\n",
      "Scraping data for vectis (3401)\n",
      "No more results for vectis on page 1.\n",
      "No results for vectis. Moving to the next suburb.\n",
      "Scraping data for wail (3401)\n",
      "No more results for wail on page 1.\n",
      "No results for wail. Moving to the next suburb.\n",
      "Scraping data for wallup (3401)\n",
      "No more results for wallup on page 1.\n",
      "No results for wallup. Moving to the next suburb.\n",
      "Scraping data for wartook (3401)\n",
      "No more results for wartook on page 1.\n",
      "No results for wartook. Moving to the next suburb.\n",
      "Scraping data for wombelano (3401)\n",
      "Error fetching https://www.domain.com.au/rent/wombelano-vic-3401/?ssubs=0&sort=suburb-asc&page=1: HTTP Error 404: Not Found\n",
      "No results for wombelano. Moving to the next suburb.\n",
      "Scraping data for wonwondah (3401)\n",
      "No more results for wonwondah on page 2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% successful: 100%|██████████| 1/1 [00:01<00:00,  1.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping data for zumsteins (3401)\n",
      "No more results for zumsteins on page 1.\n",
      "No results for zumsteins. Moving to the next suburb.\n",
      "Scraping data for horsham (3402)\n",
      "Error fetching https://www.domain.com.au/rent/horsham-vic-3402/?ssubs=0&sort=suburb-asc&page=1: HTTP Error 404: Not Found\n",
      "No results for horsham. Moving to the next suburb.\n",
      "Scraping data for balmoral (3407)\n",
      "No more results for balmoral on page 1.\n",
      "No results for balmoral. Moving to the next suburb.\n",
      "Scraping data for englefield (3407)\n",
      "No more results for englefield on page 1.\n",
      "No results for englefield. Moving to the next suburb.\n",
      "Scraping data for gatum (3407)\n",
      "No more results for gatum on page 1.\n",
      "No results for gatum. Moving to the next suburb.\n",
      "Scraping data for pigeon-ponds (3407)\n",
      "No more results for pigeon-ponds on page 1.\n",
      "No results for pigeon-ponds. Moving to the next suburb.\n",
      "Scraping data for vasey (3407)\n",
      "No more results for vasey on page 1.\n",
      "No results for vasey. Moving to the next suburb.\n",
      "Scraping data for arapiles (3409)\n",
      "No more results for arapiles on page 1.\n",
      "No results for arapiles. Moving to the next suburb.\n",
      "Scraping data for clear-lake (3409)\n",
      "No more results for clear-lake on page 1.\n",
      "No results for clear-lake. Moving to the next suburb.\n",
      "Scraping data for douglas (3409)\n",
      "No more results for douglas on page 1.\n",
      "No results for douglas. Moving to the next suburb.\n",
      "Scraping data for duchembegarra (3409)\n",
      "No more results for duchembegarra on page 1.\n",
      "No results for duchembegarra. Moving to the next suburb.\n",
      "Scraping data for grass-flat (3409)\n",
      "No more results for grass-flat on page 1.\n",
      "No results for grass-flat. Moving to the next suburb.\n",
      "Scraping data for jilpanger (3409)\n",
      "No more results for jilpanger on page 1.\n",
      "No results for jilpanger. Moving to the next suburb.\n",
      "Scraping data for miga-lake (3409)\n",
      "No more results for miga-lake on page 1.\n",
      "No results for miga-lake. Moving to the next suburb.\n",
      "Scraping data for mitre (3409)\n",
      "No more results for mitre on page 1.\n",
      "No results for mitre. Moving to the next suburb.\n",
      "Scraping data for natimuk (3409)\n",
      "No more results for natimuk on page 2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% successful: 100%|██████████| 1/1 [00:00<00:00,  1.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping data for noradjuha (3409)\n",
      "No more results for noradjuha on page 1.\n",
      "No results for noradjuha. Moving to the next suburb.\n",
      "Scraping data for tooan (3409)\n",
      "No more results for tooan on page 1.\n",
      "No results for tooan. Moving to the next suburb.\n",
      "Scraping data for wombelano (3409)\n",
      "No more results for wombelano on page 1.\n",
      "No results for wombelano. Moving to the next suburb.\n",
      "Scraping data for goroke (3412)\n",
      "No more results for goroke on page 1.\n",
      "No results for goroke. Moving to the next suburb.\n",
      "Scraping data for minimay (3413)\n",
      "No more results for minimay on page 1.\n",
      "No results for minimay. Moving to the next suburb.\n",
      "Scraping data for neuarpurr (3413)\n",
      "No more results for neuarpurr on page 1.\n",
      "No results for neuarpurr. Moving to the next suburb.\n",
      "Scraping data for ozenkadnook (3413)\n",
      "No more results for ozenkadnook on page 1.\n",
      "No results for ozenkadnook. Moving to the next suburb.\n",
      "Scraping data for peronne (3413)\n",
      "No more results for peronne on page 1.\n",
      "No results for peronne. Moving to the next suburb.\n",
      "Scraping data for antwerp (3414)\n",
      "No more results for antwerp on page 1.\n",
      "No results for antwerp. Moving to the next suburb.\n",
      "Scraping data for dimboola (3414)\n",
      "No more results for dimboola on page 2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% successful: 100%|██████████| 1/1 [00:01<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping data for tarranyurk (3414)\n",
      "No more results for tarranyurk on page 1.\n",
      "No results for tarranyurk. Moving to the next suburb.\n",
      "Scraping data for miram (3415)\n",
      "No more results for miram on page 1.\n",
      "No results for miram. Moving to the next suburb.\n",
      "Scraping data for yarrunga (3415)\n",
      "Error fetching https://www.domain.com.au/rent/yarrunga-vic-3415/?ssubs=0&sort=suburb-asc&page=1: HTTP Error 404: Not Found\n",
      "No results for yarrunga. Moving to the next suburb.\n",
      "Scraping data for broughton (3418)\n",
      "No more results for broughton on page 1.\n",
      "No results for broughton. Moving to the next suburb.\n",
      "Scraping data for gerang-gerung (3418)\n",
      "No more results for gerang-gerung on page 1.\n",
      "No results for gerang-gerung. Moving to the next suburb.\n",
      "Scraping data for glenlee (3418)\n",
      "No more results for glenlee on page 1.\n",
      "No results for glenlee. Moving to the next suburb.\n",
      "Scraping data for kiata (3418)\n",
      "No more results for kiata on page 1.\n",
      "No results for kiata. Moving to the next suburb.\n",
      "Scraping data for lawloit (3418)\n",
      "No more results for lawloit on page 1.\n",
      "No results for lawloit. Moving to the next suburb.\n",
      "Scraping data for little-desert (3418)\n",
      "No more results for little-desert on page 1.\n",
      "No results for little-desert. Moving to the next suburb.\n",
      "Scraping data for lorquon (3418)\n",
      "No more results for lorquon on page 1.\n",
      "No results for lorquon. Moving to the next suburb.\n",
      "Scraping data for netherby (3418)\n",
      "No more results for netherby on page 1.\n",
      "No results for netherby. Moving to the next suburb.\n",
      "Scraping data for nhill (3418)\n",
      "No more results for nhill on page 2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% successful: 100%|██████████| 1/1 [00:01<00:00,  1.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping data for yanac (3418)\n",
      "No more results for yanac on page 1.\n",
      "No results for yanac. Moving to the next suburb.\n",
      "Scraping data for kaniva (3419)\n",
      "No more results for kaniva on page 2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% successful: 100%|██████████| 3/3 [00:05<00:00,  1.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping data for lillimur (3420)\n",
      "No more results for lillimur on page 1.\n",
      "No results for lillimur. Moving to the next suburb.\n",
      "Scraping data for serviceton (3420)\n",
      "No more results for serviceton on page 1.\n",
      "No results for serviceton. Moving to the next suburb.\n",
      "Scraping data for telopea-downs (3420)\n",
      "No more results for telopea-downs on page 1.\n",
      "No results for telopea-downs. Moving to the next suburb.\n",
      "Scraping data for jeparit (3423)\n",
      "No more results for jeparit on page 1.\n",
      "No results for jeparit. Moving to the next suburb.\n",
      "Scraping data for lake-hindmarsh (3423)\n",
      "Error fetching https://www.domain.com.au/rent/lake-hindmarsh-vic-3423/?ssubs=0&sort=suburb-asc&page=1: HTTP Error 404: Not Found\n",
      "No results for lake-hindmarsh. Moving to the next suburb.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully written\n",
      "chunk finished\n",
      "Scraping data for jeparit (3423)\n",
      "No more results for jeparit on page 1.\n",
      "No results for jeparit. Moving to the next suburb.\n",
      "Scraping data for lake-hindmarsh (3423)\n",
      "Error fetching https://www.domain.com.au/rent/lake-hindmarsh-vic-3423/?ssubs=0&sort=suburb-asc&page=1: HTTP Error 404: Not Found\n",
      "No results for lake-hindmarsh. Moving to the next suburb.\n",
      "Scraping data for albacutya (3424)\n",
      "No more results for albacutya on page 1.\n",
      "No results for albacutya. Moving to the next suburb.\n",
      "Scraping data for rainbow (3424)\n",
      "No more results for rainbow on page 1.\n",
      "No results for rainbow. Moving to the next suburb.\n",
      "Scraping data for yaapeet (3424)\n",
      "No more results for yaapeet on page 1.\n",
      "No results for yaapeet. Moving to the next suburb.\n",
      "Scraping data for diggers-rest (3427)\n",
      "No more results for diggers-rest on page 2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% successful: 100%|██████████| 16/16 [00:19<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping data for plumpton (3427)\n",
      "Error fetching https://www.domain.com.au/rent/plumpton-vic-3427/?ssubs=0&sort=suburb-asc&page=1: HTTP Error 404: Not Found\n",
      "No results for plumpton. Moving to the next suburb.\n",
      "Scraping data for bulla (3428)\n",
      "No more results for bulla on page 2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% successful: 100%|██████████| 1/1 [00:01<00:00,  1.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping data for sunbury (3429)\n",
      "No more results for sunbury on page 3.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% successful: 100%|██████████| 37/37 [00:51<00:00,  1.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping data for wildwood (3429)\n",
      "No more results for wildwood on page 1.\n",
      "No results for wildwood. Moving to the next suburb.\n",
      "Scraping data for clarkefield (3430)\n",
      "No more results for clarkefield on page 2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% successful: 100%|██████████| 1/1 [00:01<00:00,  1.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping data for riddells-creek (3431)\n",
      "No more results for riddells-creek on page 2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% successful: 100%|██████████| 3/3 [00:04<00:00,  1.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping data for bolinda (3432)\n",
      "No more results for bolinda on page 1.\n",
      "No results for bolinda. Moving to the next suburb.\n",
      "Scraping data for monegeetta (3433)\n",
      "No more results for monegeetta on page 1.\n",
      "No results for monegeetta. Moving to the next suburb.\n",
      "Scraping data for cherokee (3434)\n",
      "No more results for cherokee on page 1.\n",
      "No results for cherokee. Moving to the next suburb.\n",
      "Scraping data for kerrie (3434)\n",
      "No more results for kerrie on page 1.\n",
      "No results for kerrie. Moving to the next suburb.\n",
      "Scraping data for romsey (3434)\n",
      "No more results for romsey on page 2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% successful: 100%|██████████| 3/3 [00:03<00:00,  1.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping data for springfield (3434)\n",
      "No more results for springfield on page 1.\n",
      "No results for springfield. Moving to the next suburb.\n",
      "Scraping data for benloch (3435)\n",
      "No more results for benloch on page 1.\n",
      "No results for benloch. Moving to the next suburb.\n",
      "Scraping data for goldie (3435)\n",
      "No more results for goldie on page 1.\n",
      "No results for goldie. Moving to the next suburb.\n",
      "Scraping data for lancefield (3435)\n",
      "No more results for lancefield on page 2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% successful: 100%|██████████| 2/2 [00:02<00:00,  1.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping data for nulla-vale (3435)\n",
      "No more results for nulla-vale on page 1.\n",
      "No results for nulla-vale. Moving to the next suburb.\n",
      "Scraping data for bullengarook (3437)\n",
      "No more results for bullengarook on page 1.\n",
      "No results for bullengarook. Moving to the next suburb.\n",
      "Scraping data for gisborne (3437)\n",
      "No more results for gisborne on page 2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% successful: 100%|██████████| 18/18 [00:20<00:00,  1.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping data for gisborne-south (3437)\n",
      "No more results for gisborne-south on page 2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% successful: 100%|██████████| 1/1 [00:01<00:00,  1.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping data for new-gisborne (3438)\n",
      "No more results for new-gisborne on page 2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% successful: 100%|██████████| 2/2 [00:02<00:00,  1.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping data for macedon (3440)\n",
      "No more results for macedon on page 2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% successful: 100%|██████████| 3/3 [00:06<00:00,  2.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping data for mount-macedon (3441)\n",
      "No more results for mount-macedon on page 1.\n",
      "No results for mount-macedon. Moving to the next suburb.\n",
      "Scraping data for ashbourne (3442)\n",
      "No more results for ashbourne on page 2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% successful: 100%|██████████| 1/1 [00:01<00:00,  1.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping data for cadello (3442)\n",
      "No more results for cadello on page 1.\n",
      "No results for cadello. Moving to the next suburb.\n",
      "Scraping data for carlsruhe (3442)\n",
      "No more results for carlsruhe on page 1.\n",
      "No results for carlsruhe. Moving to the next suburb.\n",
      "Scraping data for cobaw (3442)\n",
      "No more results for cobaw on page 1.\n",
      "No results for cobaw. Moving to the next suburb.\n",
      "Scraping data for hanging-rock (3442)\n",
      "Error fetching https://www.domain.com.au/rent/hanging-rock-vic-3442/?ssubs=0&sort=suburb-asc&page=1: HTTP Error 404: Not Found\n",
      "No results for hanging-rock. Moving to the next suburb.\n",
      "Scraping data for hesket (3442)\n",
      "No more results for hesket on page 2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% successful: 100%|██████████| 1/1 [00:01<00:00,  1.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping data for newham (3442)\n",
      "No more results for newham on page 1.\n",
      "No results for newham. Moving to the next suburb.\n",
      "Scraping data for rochford (3442)\n",
      "No more results for rochford on page 2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% successful: 100%|██████████| 1/1 [00:01<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping data for woodend (3442)\n",
      "No more results for woodend on page 2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% successful: 100%|██████████| 6/6 [00:11<00:00,  1.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping data for woodend-north (3442)\n",
      "No more results for woodend-north on page 1.\n",
      "No results for woodend-north. Moving to the next suburb.\n",
      "Scraping data for barfold (3444)\n",
      "No more results for barfold on page 1.\n",
      "No results for barfold. Moving to the next suburb.\n",
      "Scraping data for baynton (3444)\n",
      "No more results for baynton on page 1.\n",
      "No results for baynton. Moving to the next suburb.\n",
      "Scraping data for baynton-east (3444)\n",
      "No more results for baynton-east on page 1.\n",
      "No results for baynton-east. Moving to the next suburb.\n",
      "Scraping data for edgecombe (3444)\n",
      "No more results for edgecombe on page 1.\n",
      "No results for edgecombe. Moving to the next suburb.\n",
      "Scraping data for glenhope (3444)\n",
      "No more results for glenhope on page 1.\n",
      "No results for glenhope. Moving to the next suburb.\n",
      "Scraping data for greenhill (3444)\n",
      "No more results for greenhill on page 1.\n",
      "No results for greenhill. Moving to the next suburb.\n",
      "Scraping data for kyneton (3444)\n",
      "No more results for kyneton on page 2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% successful: 100%|██████████| 7/7 [00:08<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping data for kyneton-south (3444)\n",
      "No more results for kyneton-south on page 1.\n",
      "No results for kyneton-south. Moving to the next suburb.\n",
      "Scraping data for langley (3444)\n",
      "No more results for langley on page 1.\n",
      "No results for langley. Moving to the next suburb.\n",
      "Scraping data for lauriston (3444)\n",
      "No more results for lauriston on page 1.\n",
      "No results for lauriston. Moving to the next suburb.\n",
      "Scraping data for lyal (3444)\n",
      "No more results for lyal on page 1.\n",
      "No results for lyal. Moving to the next suburb.\n",
      "Scraping data for metcalfe-east (3444)\n",
      "No more results for metcalfe-east on page 1.\n",
      "No results for metcalfe-east. Moving to the next suburb.\n",
      "Scraping data for mia-mia (3444)\n",
      "No more results for mia-mia on page 1.\n",
      "No results for mia-mia. Moving to the next suburb.\n",
      "Scraping data for myrtle-creek (3444)\n",
      "No more results for myrtle-creek on page 1.\n",
      "No results for myrtle-creek. Moving to the next suburb.\n",
      "Scraping data for pastoria (3444)\n",
      "No more results for pastoria on page 1.\n",
      "No results for pastoria. Moving to the next suburb.\n",
      "Scraping data for pastoria-east (3444)\n",
      "No more results for pastoria-east on page 1.\n",
      "No results for pastoria-east. Moving to the next suburb.\n",
      "Scraping data for pipers-creek (3444)\n",
      "No more results for pipers-creek on page 1.\n",
      "No results for pipers-creek. Moving to the next suburb.\n",
      "Scraping data for redesdale (3444)\n",
      "No more results for redesdale on page 1.\n",
      "No results for redesdale. Moving to the next suburb.\n",
      "Scraping data for sidonia (3444)\n",
      "No more results for sidonia on page 1.\n",
      "No results for sidonia. Moving to the next suburb.\n",
      "Scraping data for spring-hill (3444)\n",
      "No more results for spring-hill on page 1.\n",
      "No results for spring-hill. Moving to the next suburb.\n",
      "Scraping data for tylden (3444)\n",
      "No more results for tylden on page 2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% successful: 100%|██████████| 1/1 [00:01<00:00,  1.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping data for tylden-south (3444)\n",
      "No more results for tylden-south on page 1.\n",
      "No results for tylden-south. Moving to the next suburb.\n",
      "Scraping data for drummond-north (3446)\n",
      "No more results for drummond-north on page 1.\n",
      "No results for drummond-north. Moving to the next suburb.\n",
      "Scraping data for malmsbury (3446)\n",
      "No more results for malmsbury on page 2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% successful: 100%|██████████| 2/2 [00:02<00:00,  1.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping data for taradale (3447)\n",
      "No more results for taradale on page 1.\n",
      "No results for taradale. Moving to the next suburb.\n",
      "Scraping data for elphinstone (3448)\n",
      "No more results for elphinstone on page 1.\n",
      "No results for elphinstone. Moving to the next suburb.\n",
      "Scraping data for metcalfe (3448)\n",
      "No more results for metcalfe on page 1.\n",
      "No results for metcalfe. Moving to the next suburb.\n",
      "Scraping data for sutton-grange (3448)\n",
      "No more results for sutton-grange on page 1.\n",
      "No results for sutton-grange. Moving to the next suburb.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully written\n",
      "chunk finished\n",
      "Scraping data for elphinstone (3448)\n",
      "No more results for elphinstone on page 1.\n",
      "No results for elphinstone. Moving to the next suburb.\n",
      "Scraping data for metcalfe (3448)\n",
      "No more results for metcalfe on page 1.\n",
      "No results for metcalfe. Moving to the next suburb.\n",
      "Scraping data for sutton-grange (3448)\n",
      "No more results for sutton-grange on page 1.\n",
      "No results for sutton-grange. Moving to the next suburb.\n",
      "Scraping data for castlemaine (3450)\n",
      "No more results for castlemaine on page 2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% successful: 100%|██████████| 11/11 [00:13<00:00,  1.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping data for moonlight-flat (3450)\n",
      "No more results for moonlight-flat on page 1.\n",
      "No results for moonlight-flat. Moving to the next suburb.\n",
      "Scraping data for barkers-creek (3451)\n",
      "No more results for barkers-creek on page 1.\n",
      "No results for barkers-creek. Moving to the next suburb.\n",
      "Scraping data for campbells-creek (3451)\n",
      "No more results for campbells-creek on page 2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% successful: 100%|██████████| 2/2 [00:03<00:00,  1.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping data for chewton (3451)\n",
      "No more results for chewton on page 2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% successful: 100%|██████████| 1/1 [00:00<00:00,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping data for chewton-bushlands (3451)\n",
      "No more results for chewton-bushlands on page 1.\n",
      "No results for chewton-bushlands. Moving to the next suburb.\n",
      "Scraping data for faraday (3451)\n",
      "No more results for faraday on page 1.\n",
      "No results for faraday. Moving to the next suburb.\n",
      "Scraping data for fryerstown (3451)\n",
      "No more results for fryerstown on page 2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% successful: 100%|██████████| 1/1 [00:01<00:00,  1.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping data for glenluce (3451)\n",
      "No more results for glenluce on page 1.\n",
      "No results for glenluce. Moving to the next suburb.\n",
      "Scraping data for golden-point (3451)\n",
      "No more results for golden-point on page 2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% successful: 100%|██████████| 1/1 [00:01<00:00,  1.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping data for gower (3451)\n",
      "No more results for gower on page 1.\n",
      "No results for gower. Moving to the next suburb.\n",
      "Scraping data for guildford (3451)\n",
      "No more results for guildford on page 1.\n",
      "No results for guildford. Moving to the next suburb.\n",
      "Scraping data for irishtown (3451)\n",
      "No more results for irishtown on page 1.\n",
      "No results for irishtown. Moving to the next suburb.\n",
      "Scraping data for mckenzie-hill (3451)\n",
      "No more results for mckenzie-hill on page 2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% successful: 100%|██████████| 2/2 [00:02<00:00,  1.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping data for muckleford (3451)\n",
      "No more results for muckleford on page 2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% successful: 100%|██████████| 1/1 [00:01<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping data for tarilta (3451)\n",
      "No more results for tarilta on page 1.\n",
      "No results for tarilta. Moving to the next suburb.\n",
      "Scraping data for vaughan (3451)\n",
      "No more results for vaughan on page 1.\n",
      "No results for vaughan. Moving to the next suburb.\n",
      "Scraping data for woodbrook (3451)\n",
      "Error fetching https://www.domain.com.au/rent/woodbrook-vic-3451/?ssubs=0&sort=suburb-asc&page=1: HTTP Error 404: Not Found\n",
      "No results for woodbrook. Moving to the next suburb.\n",
      "Scraping data for yapeen (3451)\n",
      "No more results for yapeen on page 1.\n",
      "No results for yapeen. Moving to the next suburb.\n",
      "Scraping data for harcourt (3453)\n",
      "No more results for harcourt on page 2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% successful: 100%|██████████| 2/2 [00:02<00:00,  1.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping data for harcourt-north (3453)\n",
      "No more results for harcourt-north on page 1.\n",
      "No results for harcourt-north. Moving to the next suburb.\n",
      "Scraping data for ravenswood (3453)\n",
      "No more results for ravenswood on page 1.\n",
      "No results for ravenswood. Moving to the next suburb.\n",
      "Scraping data for ravenswood-south (3453)\n",
      "No more results for ravenswood-south on page 1.\n",
      "No results for ravenswood-south. Moving to the next suburb.\n",
      "Scraping data for barrys-reef (3458)\n",
      "No more results for barrys-reef on page 1.\n",
      "No results for barrys-reef. Moving to the next suburb.\n",
      "Scraping data for blackwood (3458)\n",
      "No more results for blackwood on page 1.\n",
      "No results for blackwood. Moving to the next suburb.\n",
      "Scraping data for fern-hill (3458)\n",
      "No more results for fern-hill on page 1.\n",
      "No results for fern-hill. Moving to the next suburb.\n",
      "Scraping data for lerderderg (3458)\n",
      "No more results for lerderderg on page 1.\n",
      "No results for lerderderg. Moving to the next suburb.\n",
      "Scraping data for little-hampton (3458)\n",
      "No more results for little-hampton on page 1.\n",
      "No results for little-hampton. Moving to the next suburb.\n",
      "Scraping data for newbury (3458)\n",
      "No more results for newbury on page 1.\n",
      "No results for newbury. Moving to the next suburb.\n",
      "Scraping data for north-blackwood (3458)\n",
      "No more results for north-blackwood on page 1.\n",
      "No results for north-blackwood. Moving to the next suburb.\n",
      "Scraping data for trentham (3458)\n",
      "No more results for trentham on page 2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% successful: 100%|██████████| 1/1 [00:01<00:00,  1.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping data for trentham-east (3458)\n",
      "No more results for trentham-east on page 1.\n",
      "No results for trentham-east. Moving to the next suburb.\n",
      "Scraping data for basalt (3460)\n",
      "No more results for basalt on page 1.\n",
      "No results for basalt. Moving to the next suburb.\n",
      "Scraping data for daylesford (3460)\n",
      "No more results for daylesford on page 2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% successful: 100%|██████████| 11/11 [00:14<00:00,  1.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping data for bullarto (3461)\n",
      "No more results for bullarto on page 1.\n",
      "No results for bullarto. Moving to the next suburb.\n",
      "Scraping data for bullarto-south (3461)\n",
      "No more results for bullarto-south on page 1.\n",
      "No results for bullarto-south. Moving to the next suburb.\n",
      "Scraping data for clydesdale (3461)\n",
      "No more results for clydesdale on page 1.\n",
      "No results for clydesdale. Moving to the next suburb.\n",
      "Scraping data for coomoora (3461)\n",
      "No more results for coomoora on page 1.\n",
      "No results for coomoora. Moving to the next suburb.\n",
      "Scraping data for denver (3461)\n",
      "No more results for denver on page 1.\n",
      "No results for denver. Moving to the next suburb.\n",
      "Scraping data for drummond (3461)\n",
      "No more results for drummond on page 1.\n",
      "No results for drummond. Moving to the next suburb.\n",
      "Scraping data for dry-diggings (3461)\n",
      "No more results for dry-diggings on page 1.\n",
      "No results for dry-diggings. Moving to the next suburb.\n",
      "Scraping data for eganstown (3461)\n",
      "No more results for eganstown on page 2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% successful: 100%|██████████| 1/1 [00:01<00:00,  1.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping data for elevated-plains (3461)\n",
      "No more results for elevated-plains on page 1.\n",
      "No results for elevated-plains. Moving to the next suburb.\n",
      "Scraping data for franklinford (3461)\n",
      "No more results for franklinford on page 1.\n",
      "No results for franklinford. Moving to the next suburb.\n",
      "Scraping data for glenlyon (3461)\n",
      "No more results for glenlyon on page 1.\n",
      "No results for glenlyon. Moving to the next suburb.\n",
      "Scraping data for hepburn (3461)\n",
      "No more results for hepburn on page 1.\n",
      "No results for hepburn. Moving to the next suburb.\n",
      "Scraping data for hepburn-springs (3461)\n",
      "No more results for hepburn-springs on page 2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% successful: 100%|██████████| 1/1 [00:01<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping data for korweinguboora (3461)\n",
      "No more results for korweinguboora on page 1.\n",
      "No results for korweinguboora. Moving to the next suburb.\n",
      "Scraping data for leonards-hill (3461)\n",
      "No more results for leonards-hill on page 1.\n",
      "No results for leonards-hill. Moving to the next suburb.\n",
      "Scraping data for lyonville (3461)\n",
      "No more results for lyonville on page 1.\n",
      "No results for lyonville. Moving to the next suburb.\n",
      "Scraping data for mount-franklin (3461)\n",
      "No more results for mount-franklin on page 1.\n",
      "No results for mount-franklin. Moving to the next suburb.\n",
      "Scraping data for musk (3461)\n",
      "No more results for musk on page 2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% successful: 100%|██████████| 1/1 [00:01<00:00,  1.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping data for musk-vale (3461)\n",
      "No more results for musk-vale on page 1.\n",
      "No results for musk-vale. Moving to the next suburb.\n",
      "Scraping data for porcupine-ridge (3461)\n",
      "No more results for porcupine-ridge on page 1.\n",
      "No results for porcupine-ridge. Moving to the next suburb.\n",
      "Scraping data for sailors-falls (3461)\n",
      "No more results for sailors-falls on page 2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% successful: 100%|██████████| 1/1 [00:00<00:00,  1.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping data for sailors-hill (3461)\n",
      "No more results for sailors-hill on page 1.\n",
      "No results for sailors-hill. Moving to the next suburb.\n",
      "Scraping data for shepherds-flat (3461)\n",
      "No more results for shepherds-flat on page 1.\n",
      "No results for shepherds-flat. Moving to the next suburb.\n",
      "Scraping data for spargo-creek (3461)\n",
      "No more results for spargo-creek on page 1.\n",
      "No results for spargo-creek. Moving to the next suburb.\n",
      "Scraping data for strangways (3461)\n",
      "No more results for strangways on page 1.\n",
      "No results for strangways. Moving to the next suburb.\n",
      "Scraping data for wheatsheaf (3461)\n",
      "No more results for wheatsheaf on page 2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% successful: 100%|██████████| 1/1 [00:01<00:00,  1.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping data for yandoit (3461)\n",
      "No more results for yandoit on page 1.\n",
      "No results for yandoit. Moving to the next suburb.\n",
      "Scraping data for yandoit-hills (3461)\n",
      "No more results for yandoit-hills on page 1.\n",
      "No results for yandoit-hills. Moving to the next suburb.\n",
      "Scraping data for green-gully (3462)\n",
      "No more results for green-gully on page 1.\n",
      "No results for green-gully. Moving to the next suburb.\n",
      "Scraping data for joyces-creek (3462)\n",
      "No more results for joyces-creek on page 1.\n",
      "No results for joyces-creek. Moving to the next suburb.\n",
      "Scraping data for muckleford-south (3462)\n",
      "No more results for muckleford-south on page 1.\n",
      "No results for muckleford-south. Moving to the next suburb.\n",
      "Scraping data for newstead (3462)\n",
      "No more results for newstead on page 1.\n",
      "No results for newstead. Moving to the next suburb.\n",
      "Scraping data for sandon (3462)\n",
      "No more results for sandon on page 1.\n",
      "No results for sandon. Moving to the next suburb.\n",
      "Scraping data for welshmans-reef (3462)\n",
      "No more results for welshmans-reef on page 1.\n",
      "No results for welshmans-reef. Moving to the next suburb.\n",
      "Scraping data for baringhup (3463)\n",
      "No more results for baringhup on page 1.\n",
      "No results for baringhup. Moving to the next suburb.\n",
      "Scraping data for baringhup-west (3463)\n",
      "No more results for baringhup-west on page 1.\n",
      "No results for baringhup-west. Moving to the next suburb.\n",
      "Scraping data for bradford (3463)\n",
      "No more results for bradford on page 1.\n",
      "No results for bradford. Moving to the next suburb.\n",
      "Scraping data for eastville (3463)\n",
      "No more results for eastville on page 1.\n",
      "No results for eastville. Moving to the next suburb.\n",
      "Scraping data for gower (3463)\n",
      "No more results for gower on page 1.\n",
      "No results for gower. Moving to the next suburb.\n",
      "Scraping data for laanecoorie (3463)\n",
      "No more results for laanecoorie on page 1.\n",
      "No results for laanecoorie. Moving to the next suburb.\n",
      "Scraping data for maldon (3463)\n",
      "No more results for maldon on page 2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% successful: 100%|██████████| 3/3 [00:04<00:00,  1.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping data for neereman (3463)\n",
      "No more results for neereman on page 1.\n",
      "No results for neereman. Moving to the next suburb.\n",
      "Scraping data for nuggetty (3463)\n",
      "No more results for nuggetty on page 1.\n",
      "No results for nuggetty. Moving to the next suburb.\n",
      "Scraping data for perkins-reef (3463)\n",
      "Error fetching https://www.domain.com.au/rent/perkins-reef-vic-3463/?ssubs=0&sort=suburb-asc&page=1: HTTP Error 404: Not Found\n",
      "No results for perkins-reef. Moving to the next suburb.\n",
      "Scraping data for porcupine-flat (3463)\n",
      "Error fetching https://www.domain.com.au/rent/porcupine-flat-vic-3463/?ssubs=0&sort=suburb-asc&page=1: HTTP Error 404: Not Found\n",
      "No results for porcupine-flat. Moving to the next suburb.\n",
      "Scraping data for shelbourne (3463)\n",
      "Error fetching https://www.domain.com.au/rent/shelbourne-vic-3463/?ssubs=0&sort=suburb-asc&page=1: HTTP Error 404: Not Found\n",
      "No results for shelbourne. Moving to the next suburb.\n",
      "Scraping data for tarrengower (3463)\n",
      "No more results for tarrengower on page 1.\n",
      "No results for tarrengower. Moving to the next suburb.\n",
      "Scraping data for walmer (3463)\n",
      "No more results for walmer on page 2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% successful: 100%|██████████| 2/2 [00:03<00:00,  1.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping data for woodstock-west (3463)\n",
      "No more results for woodstock-west on page 1.\n",
      "No results for woodstock-west. Moving to the next suburb.\n",
      "Scraping data for carisbrook (3464)\n",
      "No more results for carisbrook on page 2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% successful: 100%|██████████| 1/1 [00:01<00:00,  1.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping data for adelaide-lead (3465)\n",
      "No more results for adelaide-lead on page 1.\n",
      "No results for adelaide-lead. Moving to the next suburb.\n",
      "Scraping data for alma (3465)\n",
      "No more results for alma on page 1.\n",
      "No results for alma. Moving to the next suburb.\n",
      "Scraping data for bowenvale (3465)\n",
      "No more results for bowenvale on page 1.\n",
      "No results for bowenvale. Moving to the next suburb.\n",
      "Scraping data for bung-bong (3465)\n",
      "No more results for bung-bong on page 1.\n",
      "No results for bung-bong. Moving to the next suburb.\n",
      "Scraping data for cotswold (3465)\n",
      "No more results for cotswold on page 1.\n",
      "No results for cotswold. Moving to the next suburb.\n",
      "Scraping data for craigie (3465)\n",
      "No more results for craigie on page 1.\n",
      "No results for craigie. Moving to the next suburb.\n",
      "Scraping data for daisy-hill (3465)\n",
      "No more results for daisy-hill on page 1.\n",
      "No results for daisy-hill. Moving to the next suburb.\n",
      "Scraping data for flagstaff (3465)\n",
      "No more results for flagstaff on page 1.\n",
      "No results for flagstaff. Moving to the next suburb.\n",
      "Scraping data for golden-point (3465)\n",
      "No more results for golden-point on page 2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% successful: 100%|██████████| 1/1 [00:01<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping data for havelock (3465)\n",
      "No more results for havelock on page 1.\n",
      "No results for havelock. Moving to the next suburb.\n",
      "Scraping data for homebush (3465)\n",
      "No more results for homebush on page 1.\n",
      "No results for homebush. Moving to the next suburb.\n",
      "Scraping data for majorca (3465)\n",
      "No more results for majorca on page 1.\n",
      "No results for majorca. Moving to the next suburb.\n",
      "Scraping data for maryborough (3465)\n",
      "No more results for maryborough on page 2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% successful: 100%|██████████| 11/11 [00:12<00:00,  1.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping data for moolort (3465)\n",
      "No more results for moolort on page 1.\n",
      "No results for moolort. Moving to the next suburb.\n",
      "Scraping data for moonlight-flat (3465)\n",
      "No more results for moonlight-flat on page 1.\n",
      "No results for moonlight-flat. Moving to the next suburb.\n",
      "Scraping data for natte-yallock (3465)\n",
      "No more results for natte-yallock on page 1.\n",
      "No results for natte-yallock. Moving to the next suburb.\n",
      "Scraping data for rathscar (3465)\n",
      "No more results for rathscar on page 1.\n",
      "No results for rathscar. Moving to the next suburb.\n",
      "Scraping data for rathscar-west (3465)\n",
      "No more results for rathscar-west on page 1.\n",
      "No results for rathscar-west. Moving to the next suburb.\n",
      "Scraping data for rodborough (3465)\n",
      "Error fetching https://www.domain.com.au/rent/rodborough-vic-3465/?ssubs=0&sort=suburb-asc&page=1: HTTP Error 404: Not Found\n",
      "No results for rodborough. Moving to the next suburb.\n",
      "Scraping data for simson (3465)\n",
      "No more results for simson on page 1.\n",
      "No results for simson. Moving to the next suburb.\n",
      "Scraping data for timor (3465)\n",
      "No more results for timor on page 1.\n",
      "No results for timor. Moving to the next suburb.\n",
      "Scraping data for timor-west (3465)\n",
      "No more results for timor-west on page 1.\n",
      "No results for timor-west. Moving to the next suburb.\n",
      "Scraping data for wareek (3465)\n",
      "No more results for wareek on page 1.\n",
      "No results for wareek. Moving to the next suburb.\n",
      "Scraping data for avoca (3467)\n",
      "No more results for avoca on page 1.\n",
      "No results for avoca. Moving to the next suburb.\n",
      "Scraping data for moyreisk (3467)\n",
      "No more results for moyreisk on page 1.\n",
      "No results for moyreisk. Moving to the next suburb.\n",
      "Scraping data for amphitheatre (3468)\n",
      "No more results for amphitheatre on page 1.\n",
      "No results for amphitheatre. Moving to the next suburb.\n",
      "Scraping data for mount-lonarch (3468)\n",
      "No more results for mount-lonarch on page 1.\n",
      "No results for mount-lonarch. Moving to the next suburb.\n",
      "Scraping data for elmhurst (3469)\n",
      "No more results for elmhurst on page 1.\n",
      "No results for elmhurst. Moving to the next suburb.\n",
      "Scraping data for glenlofty (3469)\n",
      "No more results for glenlofty on page 1.\n",
      "No results for glenlofty. Moving to the next suburb.\n",
      "Scraping data for glenlogie (3469)\n",
      "No more results for glenlogie on page 1.\n",
      "No results for glenlogie. Moving to the next suburb.\n",
      "Scraping data for glenpatrick (3469)\n",
      "No more results for glenpatrick on page 1.\n",
      "No results for glenpatrick. Moving to the next suburb.\n",
      "Scraping data for nowhere-creek (3469)\n",
      "No more results for nowhere-creek on page 1.\n",
      "No results for nowhere-creek. Moving to the next suburb.\n",
      "Scraping data for bet-bet (3472)\n",
      "No more results for bet-bet on page 1.\n",
      "No results for bet-bet. Moving to the next suburb.\n",
      "Scraping data for betley (3472)\n",
      "No more results for betley on page 1.\n",
      "No results for betley. Moving to the next suburb.\n",
      "Scraping data for bromley (3472)\n",
      "No more results for bromley on page 1.\n",
      "No results for bromley. Moving to the next suburb.\n",
      "Scraping data for dunluce (3472)\n",
      "No more results for dunluce on page 1.\n",
      "No results for dunluce. Moving to the next suburb.\n",
      "Scraping data for dunolly (3472)\n",
      "No more results for dunolly on page 1.\n",
      "No results for dunolly. Moving to the next suburb.\n",
      "Scraping data for eddington (3472)\n",
      "No more results for eddington on page 1.\n",
      "No results for eddington. Moving to the next suburb.\n",
      "Scraping data for goldsborough (3472)\n",
      "No more results for goldsborough on page 1.\n",
      "No results for goldsborough. Moving to the next suburb.\n",
      "Scraping data for inkerman (3472)\n",
      "No more results for inkerman on page 1.\n",
      "No results for inkerman. Moving to the next suburb.\n",
      "Scraping data for mcintyre (3472)\n",
      "No more results for mcintyre on page 1.\n",
      "No results for mcintyre. Moving to the next suburb.\n",
      "Scraping data for moliagul (3472)\n",
      "No more results for moliagul on page 1.\n",
      "No results for moliagul. Moving to the next suburb.\n",
      "Scraping data for mount-hooghly (3472)\n",
      "No more results for mount-hooghly on page 1.\n",
      "No results for mount-hooghly. Moving to the next suburb.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully written\n",
      "chunk finished\n",
      "Scraping data for archdale (3475)\n",
      "No more results for archdale on page 1.\n",
      "No results for archdale. Moving to the next suburb.\n",
      "Scraping data for archdale-junction (3475)\n",
      "No more results for archdale-junction on page 1.\n",
      "No results for archdale-junction. Moving to the next suburb.\n",
      "Scraping data for bealiba (3475)\n",
      "No more results for bealiba on page 1.\n",
      "No results for bealiba. Moving to the next suburb.\n",
      "Scraping data for burkes-flat (3475)\n",
      "No more results for burkes-flat on page 1.\n",
      "No results for burkes-flat. Moving to the next suburb.\n",
      "Scraping data for cochranes-creek (3475)\n",
      "No more results for cochranes-creek on page 1.\n",
      "No results for cochranes-creek. Moving to the next suburb.\n",
      "Scraping data for emu (3475)\n",
      "No more results for emu on page 1.\n",
      "No results for emu. Moving to the next suburb.\n",
      "Scraping data for logan (3475)\n",
      "No more results for logan on page 1.\n",
      "No results for logan. Moving to the next suburb.\n",
      "Scraping data for avon-plains (3477)\n",
      "No more results for avon-plains on page 1.\n",
      "No results for avon-plains. Moving to the next suburb.\n",
      "Scraping data for beazleys-bridge (3477)\n",
      "No more results for beazleys-bridge on page 1.\n",
      "No results for beazleys-bridge. Moving to the next suburb.\n",
      "Scraping data for carapooee (3477)\n",
      "No more results for carapooee on page 1.\n",
      "No results for carapooee. Moving to the next suburb.\n",
      "Scraping data for carapooee-west (3477)\n",
      "No more results for carapooee-west on page 1.\n",
      "No results for carapooee-west. Moving to the next suburb.\n",
      "Scraping data for coonooer-bridge (3477)\n",
      "No more results for coonooer-bridge on page 1.\n",
      "No results for coonooer-bridge. Moving to the next suburb.\n",
      "Scraping data for coonooer-west (3477)\n",
      "No more results for coonooer-west on page 1.\n",
      "No results for coonooer-west. Moving to the next suburb.\n",
      "Scraping data for dalyenong (3477)\n",
      "No more results for dalyenong on page 1.\n",
      "No results for dalyenong. Moving to the next suburb.\n",
      "Scraping data for gooroc (3477)\n",
      "No more results for gooroc on page 1.\n",
      "No results for gooroc. Moving to the next suburb.\n",
      "Scraping data for gowar-east (3477)\n",
      "No more results for gowar-east on page 1.\n",
      "No results for gowar-east. Moving to the next suburb.\n",
      "Scraping data for grays-bridge (3477)\n",
      "No more results for grays-bridge on page 1.\n",
      "No results for grays-bridge. Moving to the next suburb.\n",
      "Scraping data for gre-gre (3477)\n",
      "No more results for gre-gre on page 1.\n",
      "No results for gre-gre. Moving to the next suburb.\n",
      "Scraping data for gre-gre-north (3477)\n",
      "No more results for gre-gre-north on page 1.\n",
      "No results for gre-gre-north. Moving to the next suburb.\n",
      "Scraping data for gre-gre-south (3477)\n",
      "No more results for gre-gre-south on page 1.\n",
      "No results for gre-gre-south. Moving to the next suburb.\n",
      "Scraping data for kooreh (3477)\n",
      "No more results for kooreh on page 1.\n",
      "No results for kooreh. Moving to the next suburb.\n",
      "Scraping data for marnoo-east (3477)\n",
      "No more results for marnoo-east on page 1.\n",
      "No results for marnoo-east. Moving to the next suburb.\n",
      "Scraping data for moolerr (3477)\n",
      "No more results for moolerr on page 1.\n",
      "No results for moolerr. Moving to the next suburb.\n",
      "Scraping data for moyreisk (3477)\n",
      "No more results for moyreisk on page 1.\n",
      "No results for moyreisk. Moving to the next suburb.\n",
      "Scraping data for paradise (3477)\n",
      "No more results for paradise on page 1.\n",
      "No results for paradise. Moving to the next suburb.\n",
      "Scraping data for redbank (3477)\n",
      "No more results for redbank on page 1.\n",
      "No results for redbank. Moving to the next suburb.\n",
      "Scraping data for rostron (3477)\n",
      "No more results for rostron on page 1.\n",
      "No results for rostron. Moving to the next suburb.\n",
      "Scraping data for slaty-creek (3477)\n",
      "No more results for slaty-creek on page 1.\n",
      "No results for slaty-creek. Moving to the next suburb.\n",
      "Scraping data for st-arnaud-east (3477)\n",
      "No more results for st-arnaud-east on page 1.\n",
      "No results for st-arnaud-east. Moving to the next suburb.\n",
      "Scraping data for st-arnaud-north (3477)\n",
      "No more results for st-arnaud-north on page 1.\n",
      "No results for st-arnaud-north. Moving to the next suburb.\n",
      "Scraping data for stuart-mill (3477)\n",
      "No more results for stuart-mill on page 1.\n",
      "No results for stuart-mill. Moving to the next suburb.\n",
      "Scraping data for sutherland (3477)\n",
      "No more results for sutherland on page 1.\n",
      "No results for sutherland. Moving to the next suburb.\n",
      "Scraping data for swanwater (3477)\n",
      "No more results for swanwater on page 1.\n",
      "No results for swanwater. Moving to the next suburb.\n",
      "Scraping data for tottington (3477)\n",
      "No more results for tottington on page 1.\n",
      "No results for tottington. Moving to the next suburb.\n",
      "Scraping data for traynors-lagoon (3477)\n",
      "No more results for traynors-lagoon on page 1.\n",
      "No results for traynors-lagoon. Moving to the next suburb.\n",
      "Scraping data for winjallok (3477)\n",
      "No more results for winjallok on page 1.\n",
      "No results for winjallok. Moving to the next suburb.\n",
      "Scraping data for york-plains (3477)\n",
      "No more results for york-plains on page 1.\n",
      "No results for york-plains. Moving to the next suburb.\n",
      "Scraping data for avon-plains (3478)\n",
      "No more results for avon-plains on page 1.\n",
      "No results for avon-plains. Moving to the next suburb.\n",
      "Scraping data for beazleys-bridge (3478)\n",
      "No more results for beazleys-bridge on page 1.\n",
      "No results for beazleys-bridge. Moving to the next suburb.\n",
      "Scraping data for berrimal-west (3478)\n",
      "Error fetching https://www.domain.com.au/rent/berrimal-west-vic-3478/?ssubs=0&sort=suburb-asc&page=1: HTTP Error 404: Not Found\n",
      "No results for berrimal-west. Moving to the next suburb.\n",
      "Scraping data for carapooee (3478)\n",
      "No more results for carapooee on page 1.\n",
      "No results for carapooee. Moving to the next suburb.\n",
      "Scraping data for carapooee-west (3478)\n",
      "No more results for carapooee-west on page 1.\n",
      "No results for carapooee-west. Moving to the next suburb.\n",
      "Scraping data for coonooer-bridge (3478)\n",
      "No more results for coonooer-bridge on page 1.\n",
      "No results for coonooer-bridge. Moving to the next suburb.\n",
      "Scraping data for coonooer-west (3478)\n",
      "No more results for coonooer-west on page 1.\n",
      "No results for coonooer-west. Moving to the next suburb.\n",
      "Scraping data for darkbonee (3478)\n",
      "Error fetching https://www.domain.com.au/rent/darkbonee-vic-3478/?ssubs=0&sort=suburb-asc&page=1: HTTP Error 404: Not Found\n",
      "No results for darkbonee. Moving to the next suburb.\n",
      "Scraping data for dooboobetic (3478)\n",
      "No more results for dooboobetic on page 1.\n",
      "No results for dooboobetic. Moving to the next suburb.\n",
      "Scraping data for elberton (3478)\n",
      "Error fetching https://www.domain.com.au/rent/elberton-vic-3478/?ssubs=0&sort=suburb-asc&page=1: HTTP Error 404: Not Found\n",
      "No results for elberton. Moving to the next suburb.\n",
      "Scraping data for gooroc (3478)\n",
      "No more results for gooroc on page 1.\n",
      "No results for gooroc. Moving to the next suburb.\n",
      "Scraping data for gowar-east (3478)\n",
      "No more results for gowar-east on page 1.\n",
      "No results for gowar-east. Moving to the next suburb.\n",
      "Scraping data for gre-gre (3478)\n",
      "No more results for gre-gre on page 1.\n",
      "No results for gre-gre. Moving to the next suburb.\n",
      "Scraping data for gre-gre-north (3478)\n",
      "No more results for gre-gre-north on page 1.\n",
      "No results for gre-gre-north. Moving to the next suburb.\n",
      "Scraping data for gre-gre-south (3478)\n",
      "No more results for gre-gre-south on page 1.\n",
      "No results for gre-gre-south. Moving to the next suburb.\n",
      "Scraping data for kooreh (3478)\n",
      "No more results for kooreh on page 1.\n",
      "No results for kooreh. Moving to the next suburb.\n",
      "Scraping data for medlyn (3478)\n",
      "Error fetching https://www.domain.com.au/rent/medlyn-vic-3478/?ssubs=0&sort=suburb-asc&page=1: HTTP Error 404: Not Found\n",
      "No results for medlyn. Moving to the next suburb.\n",
      "Scraping data for mitchells-hill (3478)\n",
      "Error fetching https://www.domain.com.au/rent/mitchells-hill-vic-3478/?ssubs=0&sort=suburb-asc&page=1: HTTP Error 404: Not Found\n",
      "No results for mitchells-hill. Moving to the next suburb.\n",
      "Scraping data for moolerr (3478)\n",
      "No more results for moolerr on page 1.\n",
      "No results for moolerr. Moving to the next suburb.\n",
      "Scraping data for moonambel (3478)\n",
      "No more results for moonambel on page 1.\n",
      "No results for moonambel. Moving to the next suburb.\n",
      "Scraping data for percydale (3478)\n",
      "No more results for percydale on page 1.\n",
      "No results for percydale. Moving to the next suburb.\n",
      "Scraping data for slaty-creek (3478)\n",
      "No more results for slaty-creek on page 1.\n",
      "No results for slaty-creek. Moving to the next suburb.\n",
      "Scraping data for st-arnaud (3478)\n",
      "No more results for st-arnaud on page 1.\n",
      "No results for st-arnaud. Moving to the next suburb.\n",
      "Scraping data for st-arnaud-east (3478)\n",
      "No more results for st-arnaud-east on page 1.\n",
      "No results for st-arnaud-east. Moving to the next suburb.\n",
      "Scraping data for st-arnaud-north (3478)\n",
      "No more results for st-arnaud-north on page 1.\n",
      "No results for st-arnaud-north. Moving to the next suburb.\n",
      "Scraping data for stuart-mill (3478)\n",
      "No more results for stuart-mill on page 1.\n",
      "No results for stuart-mill. Moving to the next suburb.\n",
      "Scraping data for sutherland (3478)\n",
      "No more results for sutherland on page 1.\n",
      "No results for sutherland. Moving to the next suburb.\n",
      "Scraping data for swanwater (3478)\n",
      "No more results for swanwater on page 1.\n",
      "No results for swanwater. Moving to the next suburb.\n",
      "Scraping data for tanwood (3478)\n",
      "No more results for tanwood on page 1.\n",
      "No results for tanwood. Moving to the next suburb.\n",
      "Scraping data for tottington (3478)\n",
      "No more results for tottington on page 1.\n",
      "No results for tottington. Moving to the next suburb.\n",
      "Scraping data for traynors-lagoon (3478)\n",
      "No more results for traynors-lagoon on page 1.\n",
      "No results for traynors-lagoon. Moving to the next suburb.\n",
      "Scraping data for tulkara (3478)\n",
      "No more results for tulkara on page 1.\n",
      "No results for tulkara. Moving to the next suburb.\n",
      "Scraping data for warrenmang (3478)\n",
      "No more results for warrenmang on page 1.\n",
      "No results for warrenmang. Moving to the next suburb.\n",
      "Scraping data for yawong-hills (3478)\n",
      "No more results for yawong-hills on page 1.\n",
      "No results for yawong-hills. Moving to the next suburb.\n",
      "Scraping data for areegra (3480)\n",
      "No more results for areegra on page 1.\n",
      "No results for areegra. Moving to the next suburb.\n",
      "Scraping data for banyenong (3480)\n",
      "Error fetching https://www.domain.com.au/rent/banyenong-vic-3480/?ssubs=0&sort=suburb-asc&page=1: HTTP Error 404: Not Found\n",
      "No results for banyenong. Moving to the next suburb.\n",
      "Scraping data for boolite (3480)\n",
      "No more results for boolite on page 1.\n",
      "No results for boolite. Moving to the next suburb.\n",
      "Scraping data for carron (3480)\n",
      "No more results for carron on page 1.\n",
      "No results for carron. Moving to the next suburb.\n",
      "Scraping data for cope-cope (3480)\n",
      "No more results for cope-cope on page 1.\n",
      "No results for cope-cope. Moving to the next suburb.\n",
      "Scraping data for corack (3480)\n",
      "No more results for corack on page 1.\n",
      "No results for corack. Moving to the next suburb.\n",
      "Scraping data for corack-east (3480)\n",
      "No more results for corack-east on page 1.\n",
      "No results for corack-east. Moving to the next suburb.\n",
      "Scraping data for donald (3480)\n",
      "No more results for donald on page 1.\n",
      "No results for donald. Moving to the next suburb.\n",
      "Scraping data for gil-gil (3480)\n",
      "No more results for gil-gil on page 1.\n",
      "No results for gil-gil. Moving to the next suburb.\n",
      "Scraping data for jeffcott (3480)\n",
      "No more results for jeffcott on page 1.\n",
      "No results for jeffcott. Moving to the next suburb.\n",
      "Scraping data for jeffcott-north (3480)\n",
      "No more results for jeffcott-north on page 1.\n",
      "No results for jeffcott-north. Moving to the next suburb.\n",
      "Scraping data for laen (3480)\n",
      "No more results for laen on page 1.\n",
      "No results for laen. Moving to the next suburb.\n",
      "Scraping data for laen-east (3480)\n",
      "No more results for laen-east on page 1.\n",
      "No results for laen-east. Moving to the next suburb.\n",
      "Scraping data for laen-north (3480)\n",
      "No more results for laen-north on page 1.\n",
      "No results for laen-north. Moving to the next suburb.\n",
      "Scraping data for lake-buloke (3480)\n",
      "Error fetching https://www.domain.com.au/rent/lake-buloke-vic-3480/?ssubs=0&sort=suburb-asc&page=1: HTTP Error 404: Not Found\n",
      "No results for lake-buloke. Moving to the next suburb.\n",
      "Scraping data for lawler (3480)\n",
      "No more results for lawler on page 1.\n",
      "No results for lawler. Moving to the next suburb.\n",
      "Scraping data for litchfield (3480)\n",
      "No more results for litchfield on page 1.\n",
      "No results for litchfield. Moving to the next suburb.\n",
      "Scraping data for rich-avon (3480)\n",
      "No more results for rich-avon on page 1.\n",
      "No results for rich-avon. Moving to the next suburb.\n",
      "Scraping data for rich-avon-east (3480)\n",
      "No more results for rich-avon-east on page 1.\n",
      "No results for rich-avon-east. Moving to the next suburb.\n",
      "Scraping data for rich-avon-west (3480)\n",
      "No more results for rich-avon-west on page 1.\n",
      "No results for rich-avon-west. Moving to the next suburb.\n",
      "Scraping data for swanwater-west (3480)\n",
      "No more results for swanwater-west on page 1.\n",
      "No results for swanwater-west. Moving to the next suburb.\n",
      "Scraping data for massey (3482)\n",
      "No more results for massey on page 1.\n",
      "No results for massey. Moving to the next suburb.\n",
      "Scraping data for morton-plains (3482)\n",
      "No more results for morton-plains on page 1.\n",
      "No results for morton-plains. Moving to the next suburb.\n",
      "Scraping data for warmur (3482)\n",
      "No more results for warmur on page 1.\n",
      "No results for warmur. Moving to the next suburb.\n",
      "Scraping data for watchem (3482)\n",
      "No more results for watchem on page 1.\n",
      "No results for watchem. Moving to the next suburb.\n",
      "Scraping data for watchem-west (3482)\n",
      "No more results for watchem-west on page 1.\n",
      "No results for watchem-west. Moving to the next suburb.\n",
      "Scraping data for ballapur (3483)\n",
      "No more results for ballapur on page 1.\n",
      "No results for ballapur. Moving to the next suburb.\n",
      "Scraping data for birchip (3483)\n",
      "No more results for birchip on page 1.\n",
      "No results for birchip. Moving to the next suburb.\n",
      "Scraping data for birchip-west (3483)\n",
      "No more results for birchip-west on page 1.\n",
      "No results for birchip-west. Moving to the next suburb.\n",
      "Scraping data for curyo (3483)\n",
      "No more results for curyo on page 1.\n",
      "No results for curyo. Moving to the next suburb.\n",
      "Scraping data for jil-jil (3483)\n",
      "No more results for jil-jil on page 1.\n",
      "No results for jil-jil. Moving to the next suburb.\n",
      "Scraping data for karyrie (3483)\n",
      "No more results for karyrie on page 1.\n",
      "No results for karyrie. Moving to the next suburb.\n",
      "Scraping data for kinnabulla (3483)\n",
      "No more results for kinnabulla on page 1.\n",
      "No results for kinnabulla. Moving to the next suburb.\n",
      "Scraping data for marlbed (3483)\n",
      "No more results for marlbed on page 1.\n",
      "No results for marlbed. Moving to the next suburb.\n",
      "Scraping data for narraport (3483)\n",
      "No more results for narraport on page 1.\n",
      "No results for narraport. Moving to the next suburb.\n",
      "Scraping data for reedy-dam (3483)\n",
      "Error fetching https://www.domain.com.au/rent/reedy-dam-vic-3483/?ssubs=0&sort=suburb-asc&page=1: HTTP Error 404: Not Found\n",
      "No results for reedy-dam. Moving to the next suburb.\n",
      "Scraping data for whirily (3483)\n",
      "No more results for whirily on page 1.\n",
      "No results for whirily. Moving to the next suburb.\n",
      "Scraping data for banyan (3485)\n",
      "No more results for banyan on page 1.\n",
      "No results for banyan. Moving to the next suburb.\n",
      "Scraping data for watchupga (3485)\n",
      "No more results for watchupga on page 1.\n",
      "No results for watchupga. Moving to the next suburb.\n",
      "Scraping data for willangie (3485)\n",
      "No more results for willangie on page 1.\n",
      "No results for willangie. Moving to the next suburb.\n",
      "Scraping data for woomelang (3485)\n",
      "No more results for woomelang on page 1.\n",
      "No results for woomelang. Moving to the next suburb.\n",
      "Scraping data for lascelles (3487)\n",
      "No more results for lascelles on page 1.\n",
      "No results for lascelles. Moving to the next suburb.\n",
      "Scraping data for speed (3488)\n",
      "No more results for speed on page 1.\n",
      "No results for speed. Moving to the next suburb.\n",
      "Scraping data for turriff (3488)\n",
      "No more results for turriff on page 1.\n",
      "No results for turriff. Moving to the next suburb.\n",
      "Scraping data for turriff-east (3488)\n",
      "No more results for turriff-east on page 1.\n",
      "No results for turriff-east. Moving to the next suburb.\n",
      "Scraping data for tempy (3489)\n",
      "No more results for tempy on page 1.\n",
      "No results for tempy. Moving to the next suburb.\n",
      "Scraping data for big-desert (3490)\n",
      "No more results for big-desert on page 1.\n",
      "No results for big-desert. Moving to the next suburb.\n",
      "Scraping data for boinka (3490)\n",
      "No more results for boinka on page 1.\n",
      "No results for boinka. Moving to the next suburb.\n",
      "Scraping data for kulwin (3490)\n",
      "No more results for kulwin on page 1.\n",
      "No results for kulwin. Moving to the next suburb.\n",
      "Scraping data for mittyack (3490)\n",
      "No more results for mittyack on page 1.\n",
      "No results for mittyack. Moving to the next suburb.\n",
      "Scraping data for murray-sunset (3490)\n",
      "No more results for murray-sunset on page 1.\n",
      "No results for murray-sunset. Moving to the next suburb.\n",
      "Scraping data for ouyen (3490)\n",
      "No more results for ouyen on page 2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% successful: 100%|██████████| 1/1 [00:01<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping data for torrita (3490)\n",
      "No more results for torrita on page 1.\n",
      "No results for torrita. Moving to the next suburb.\n",
      "Scraping data for tutye (3490)\n",
      "No more results for tutye on page 1.\n",
      "No results for tutye. Moving to the next suburb.\n",
      "Scraping data for patchewollock (3491)\n",
      "No more results for patchewollock on page 1.\n",
      "No results for patchewollock. Moving to the next suburb.\n",
      "Scraping data for carwarp (3494)\n",
      "No more results for carwarp on page 1.\n",
      "No results for carwarp. Moving to the next suburb.\n",
      "Scraping data for colignan (3494)\n",
      "No more results for colignan on page 1.\n",
      "No results for colignan. Moving to the next suburb.\n",
      "Scraping data for iraak (3494)\n",
      "No more results for iraak on page 1.\n",
      "No results for iraak. Moving to the next suburb.\n",
      "Scraping data for nangiloc (3494)\n",
      "No more results for nangiloc on page 1.\n",
      "No results for nangiloc. Moving to the next suburb.\n",
      "Scraping data for cardross (3496)\n",
      "No more results for cardross on page 2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% successful: 100%|██████████| 1/1 [00:01<00:00,  1.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping data for cullulleraine (3496)\n",
      "No more results for cullulleraine on page 1.\n",
      "No results for cullulleraine. Moving to the next suburb.\n",
      "Scraping data for lindsay-point (3496)\n",
      "No more results for lindsay-point on page 1.\n",
      "No results for lindsay-point. Moving to the next suburb.\n",
      "Scraping data for meringur (3496)\n",
      "No more results for meringur on page 1.\n",
      "No results for meringur. Moving to the next suburb.\n",
      "Scraping data for merrinee (3496)\n",
      "No more results for merrinee on page 1.\n",
      "No results for merrinee. Moving to the next suburb.\n",
      "Scraping data for murray-lock-no-9 (3496)\n",
      "Error fetching https://www.domain.com.au/rent/murray-lock-no-9-vic-3496/?ssubs=0&sort=suburb-asc&page=1: HTTP Error 404: Not Found\n",
      "No results for murray-lock-no-9. Moving to the next suburb.\n",
      "Scraping data for neds-corner (3496)\n",
      "No more results for neds-corner on page 1.\n",
      "No results for neds-corner. Moving to the next suburb.\n",
      "Scraping data for red-cliffs (3496)\n",
      "No more results for red-cliffs on page 2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% successful: 100%|██████████| 4/4 [00:04<00:00,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping data for sunnycliffs (3496)\n",
      "No more results for sunnycliffs on page 1.\n",
      "No results for sunnycliffs. Moving to the next suburb.\n",
      "Scraping data for werrimull (3496)\n",
      "No more results for werrimull on page 1.\n",
      "No results for werrimull. Moving to the next suburb.\n",
      "Scraping data for irymple (3498)\n",
      "No more results for irymple on page 2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% successful: 100%|██████████| 4/4 [00:05<00:00,  1.48s/it]\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully written\n",
      "chunk finished\n",
      "Scraping data for irymple (3498)\n",
      "No more results for irymple on page 2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% successful: 100%|██████████| 4/4 [00:08<00:00,  2.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping data for mildura (3500)\n",
      "No more results for mildura on page 4.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% successful: 100%|██████████| 58/58 [01:20<00:00,  1.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping data for mildura-east (3500)\n",
      "Error fetching https://www.domain.com.au/rent/mildura-east-vic-3500/?ssubs=0&sort=suburb-asc&page=1: HTTP Error 404: Not Found\n",
      "No results for mildura-east. Moving to the next suburb.\n",
      "Scraping data for mildura-west (3500)\n",
      "No more results for mildura-west on page 1.\n",
      "No results for mildura-west. Moving to the next suburb.\n",
      "Scraping data for hattah (3501)\n",
      "No more results for hattah on page 1.\n",
      "No results for hattah. Moving to the next suburb.\n",
      "Scraping data for koorlong (3501)\n",
      "No more results for koorlong on page 1.\n",
      "No results for koorlong. Moving to the next suburb.\n",
      "Scraping data for mildura-centre-plaza (3501)\n",
      "Error fetching https://www.domain.com.au/rent/mildura-centre-plaza-vic-3501/?ssubs=0&sort=suburb-asc&page=1: HTTP Error 404: Not Found\n",
      "No results for mildura-centre-plaza. Moving to the next suburb.\n",
      "Scraping data for mildura-south (3501)\n",
      "Error fetching https://www.domain.com.au/rent/mildura-south-vic-3501/?ssubs=0&sort=suburb-asc&page=1: HTTP Error 404: Not Found\n",
      "No results for mildura-south. Moving to the next suburb.\n",
      "Scraping data for nichols-point (3501)\n",
      "No more results for nichols-point on page 2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% successful: 100%|██████████| 1/1 [00:00<00:00,  1.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping data for mildura (3502)\n",
      "Error fetching https://www.domain.com.au/rent/mildura-vic-3502/?ssubs=0&sort=suburb-asc&page=1: HTTP Error 404: Not Found\n",
      "No results for mildura. Moving to the next suburb.\n",
      "Scraping data for birdwoodton (3505)\n",
      "No more results for birdwoodton on page 1.\n",
      "No results for birdwoodton. Moving to the next suburb.\n",
      "Scraping data for cabarita (3505)\n",
      "No more results for cabarita on page 1.\n",
      "No results for cabarita. Moving to the next suburb.\n",
      "Scraping data for merbein (3505)\n",
      "No more results for merbein on page 2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% successful: 100%|██████████| 1/1 [00:00<00:00,  1.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping data for merbein-south (3505)\n",
      "No more results for merbein-south on page 1.\n",
      "No results for merbein-south. Moving to the next suburb.\n",
      "Scraping data for merbein-west (3505)\n",
      "No more results for merbein-west on page 1.\n",
      "No results for merbein-west. Moving to the next suburb.\n",
      "Scraping data for wargan (3505)\n",
      "No more results for wargan on page 1.\n",
      "No results for wargan. Moving to the next suburb.\n",
      "Scraping data for yelta (3505)\n",
      "No more results for yelta on page 1.\n",
      "No results for yelta. Moving to the next suburb.\n",
      "Scraping data for cowangie (3506)\n",
      "No more results for cowangie on page 1.\n",
      "No results for cowangie. Moving to the next suburb.\n",
      "Scraping data for walpeup (3507)\n",
      "No more results for walpeup on page 1.\n",
      "No results for walpeup. Moving to the next suburb.\n",
      "Scraping data for linga (3509)\n",
      "No more results for linga on page 1.\n",
      "No results for linga. Moving to the next suburb.\n",
      "Scraping data for underbool (3509)\n",
      "No more results for underbool on page 2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% successful: 100%|██████████| 1/1 [00:00<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping data for carina (3512)\n",
      "No more results for carina on page 1.\n",
      "No results for carina. Moving to the next suburb.\n",
      "Scraping data for murrayville (3512)\n",
      "No more results for murrayville on page 1.\n",
      "No results for murrayville. Moving to the next suburb.\n",
      "Scraping data for panitya (3512)\n",
      "No more results for panitya on page 1.\n",
      "No results for panitya. Moving to the next suburb.\n",
      "Scraping data for marong (3515)\n",
      "No more results for marong on page 2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% successful: 100%|██████████| 1/1 [00:01<00:00,  1.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping data for shelbourne (3515)\n",
      "No more results for shelbourne on page 1.\n",
      "No results for shelbourne. Moving to the next suburb.\n",
      "Scraping data for wilsons-hill (3515)\n",
      "No more results for wilsons-hill on page 1.\n",
      "No results for wilsons-hill. Moving to the next suburb.\n",
      "Scraping data for bridgewater (3516)\n",
      "No more results for bridgewater on page 1.\n",
      "No results for bridgewater. Moving to the next suburb.\n",
      "Scraping data for bridgewater-north (3516)\n",
      "No more results for bridgewater-north on page 1.\n",
      "No results for bridgewater-north. Moving to the next suburb.\n",
      "Scraping data for bridgewater-on-loddon (3516)\n",
      "No more results for bridgewater-on-loddon on page 1.\n",
      "No results for bridgewater-on-loddon. Moving to the next suburb.\n",
      "Scraping data for derby (3516)\n",
      "No more results for derby on page 1.\n",
      "No results for derby. Moving to the next suburb.\n",
      "Scraping data for leichardt (3516)\n",
      "No more results for leichardt on page 1.\n",
      "No results for leichardt. Moving to the next suburb.\n",
      "Scraping data for yarraberb (3516)\n",
      "No more results for yarraberb on page 1.\n",
      "No results for yarraberb. Moving to the next suburb.\n",
      "Scraping data for bears-lagoon (3517)\n",
      "No more results for bears-lagoon on page 1.\n",
      "No results for bears-lagoon. Moving to the next suburb.\n",
      "Scraping data for brenanah (3517)\n",
      "No more results for brenanah on page 1.\n",
      "No results for brenanah. Moving to the next suburb.\n",
      "Scraping data for bullabul (3517)\n",
      "Error fetching https://www.domain.com.au/rent/bullabul-vic-3517/?ssubs=0&sort=suburb-asc&page=1: HTTP Error 404: Not Found\n",
      "No results for bullabul. Moving to the next suburb.\n",
      "Scraping data for glenalbyn (3517)\n",
      "No more results for glenalbyn on page 1.\n",
      "No results for glenalbyn. Moving to the next suburb.\n",
      "Scraping data for inglewood (3517)\n",
      "No more results for inglewood on page 1.\n",
      "No results for inglewood. Moving to the next suburb.\n",
      "Scraping data for jarklin (3517)\n",
      "No more results for jarklin on page 1.\n",
      "No results for jarklin. Moving to the next suburb.\n",
      "Scraping data for kingower (3517)\n",
      "No more results for kingower on page 1.\n",
      "No results for kingower. Moving to the next suburb.\n",
      "Scraping data for kurting (3517)\n",
      "No more results for kurting on page 1.\n",
      "No results for kurting. Moving to the next suburb.\n",
      "Scraping data for powlett-plains (3517)\n",
      "No more results for powlett-plains on page 1.\n",
      "No results for powlett-plains. Moving to the next suburb.\n",
      "Scraping data for rheola (3517)\n",
      "No more results for rheola on page 1.\n",
      "No results for rheola. Moving to the next suburb.\n",
      "Scraping data for salisbury-west (3517)\n",
      "No more results for salisbury-west on page 1.\n",
      "No results for salisbury-west. Moving to the next suburb.\n",
      "Scraping data for serpentine (3517)\n",
      "No more results for serpentine on page 1.\n",
      "No results for serpentine. Moving to the next suburb.\n",
      "Scraping data for berrimal (3518)\n",
      "No more results for berrimal on page 1.\n",
      "No results for berrimal. Moving to the next suburb.\n",
      "Scraping data for borung (3518)\n",
      "No more results for borung on page 1.\n",
      "No results for borung. Moving to the next suburb.\n",
      "Scraping data for fentons-creek (3518)\n",
      "No more results for fentons-creek on page 1.\n",
      "No results for fentons-creek. Moving to the next suburb.\n",
      "Scraping data for fernihurst (3518)\n",
      "No more results for fernihurst on page 1.\n",
      "No results for fernihurst. Moving to the next suburb.\n",
      "Scraping data for fiery-flat (3518)\n",
      "No more results for fiery-flat on page 1.\n",
      "No results for fiery-flat. Moving to the next suburb.\n",
      "Scraping data for kurraca (3518)\n",
      "No more results for kurraca on page 1.\n",
      "No results for kurraca. Moving to the next suburb.\n",
      "Scraping data for kurraca-west (3518)\n",
      "No more results for kurraca-west on page 1.\n",
      "No results for kurraca-west. Moving to the next suburb.\n",
      "Scraping data for mysia (3518)\n",
      "No more results for mysia on page 1.\n",
      "No results for mysia. Moving to the next suburb.\n",
      "Scraping data for nine-mile (3518)\n",
      "No more results for nine-mile on page 1.\n",
      "No results for nine-mile. Moving to the next suburb.\n",
      "Scraping data for richmond-plains (3518)\n",
      "No more results for richmond-plains on page 1.\n",
      "No results for richmond-plains. Moving to the next suburb.\n",
      "Scraping data for skinners-flat (3518)\n",
      "No more results for skinners-flat on page 1.\n",
      "No results for skinners-flat. Moving to the next suburb.\n",
      "Scraping data for wedderburn (3518)\n",
      "No more results for wedderburn on page 1.\n",
      "No results for wedderburn. Moving to the next suburb.\n",
      "Scraping data for wedderburn-junction (3518)\n",
      "No more results for wedderburn-junction on page 1.\n",
      "No results for wedderburn-junction. Moving to the next suburb.\n",
      "Scraping data for wehla (3518)\n",
      "No more results for wehla on page 1.\n",
      "No results for wehla. Moving to the next suburb.\n",
      "Scraping data for woolshed-flat (3518)\n",
      "No more results for woolshed-flat on page 1.\n",
      "No results for woolshed-flat. Moving to the next suburb.\n",
      "Scraping data for woosang (3518)\n",
      "No more results for woosang on page 1.\n",
      "No results for woosang. Moving to the next suburb.\n",
      "Scraping data for kinypanial (3520)\n",
      "No more results for kinypanial on page 1.\n",
      "No results for kinypanial. Moving to the next suburb.\n",
      "Scraping data for korong-vale (3520)\n",
      "No more results for korong-vale on page 1.\n",
      "No results for korong-vale. Moving to the next suburb.\n",
      "Scraping data for south-kinypanial (3520)\n",
      "Error fetching https://www.domain.com.au/rent/south-kinypanial-vic-3520/?ssubs=0&sort=suburb-asc&page=1: HTTP Error 404: Not Found\n",
      "No results for south-kinypanial. Moving to the next suburb.\n",
      "Scraping data for pyalong (3521)\n",
      "No more results for pyalong on page 1.\n",
      "No results for pyalong. Moving to the next suburb.\n",
      "Scraping data for emu-flat (3522)\n",
      "Error fetching https://www.domain.com.au/rent/emu-flat-vic-3522/?ssubs=0&sort=suburb-asc&page=1: HTTP Error 404: Not Found\n",
      "No results for emu-flat. Moving to the next suburb.\n",
      "Scraping data for glenhope-east (3522)\n",
      "No more results for glenhope-east on page 1.\n",
      "No results for glenhope-east. Moving to the next suburb.\n",
      "Scraping data for tooborac (3522)\n",
      "No more results for tooborac on page 1.\n",
      "No results for tooborac. Moving to the next suburb.\n",
      "Scraping data for argyle (3523)\n",
      "No more results for argyle on page 1.\n",
      "No results for argyle. Moving to the next suburb.\n",
      "Scraping data for costerfield (3523)\n",
      "No more results for costerfield on page 1.\n",
      "No results for costerfield. Moving to the next suburb.\n",
      "Scraping data for derrinal (3523)\n",
      "No more results for derrinal on page 1.\n",
      "No results for derrinal. Moving to the next suburb.\n",
      "Scraping data for heathcote (3523)\n",
      "No more results for heathcote on page 1.\n",
      "No results for heathcote. Moving to the next suburb.\n",
      "Scraping data for heathcote-south (3523)\n",
      "No more results for heathcote-south on page 1.\n",
      "No results for heathcote-south. Moving to the next suburb.\n",
      "Scraping data for knowsley (3523)\n",
      "No more results for knowsley on page 1.\n",
      "No results for knowsley. Moving to the next suburb.\n",
      "Scraping data for ladys-pass (3523)\n",
      "No more results for ladys-pass on page 1.\n",
      "No results for ladys-pass. Moving to the next suburb.\n",
      "Scraping data for moormbool-west (3523)\n",
      "No more results for moormbool-west on page 1.\n",
      "No results for moormbool-west. Moving to the next suburb.\n",
      "Scraping data for mount-camel (3523)\n",
      "No more results for mount-camel on page 1.\n",
      "No results for mount-camel. Moving to the next suburb.\n",
      "Scraping data for redcastle (3523)\n",
      "No more results for redcastle on page 2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% successful: 100%|██████████| 1/1 [00:00<00:00,  1.09it/s]\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully written\n",
      "chunk finished\n",
      "Scraping data for argyle (3523)\n",
      "No more results for argyle on page 1.\n",
      "No results for argyle. Moving to the next suburb.\n",
      "Scraping data for costerfield (3523)\n",
      "No more results for costerfield on page 1.\n",
      "No results for costerfield. Moving to the next suburb.\n",
      "Scraping data for derrinal (3523)\n",
      "No more results for derrinal on page 1.\n",
      "No results for derrinal. Moving to the next suburb.\n",
      "Scraping data for heathcote (3523)\n",
      "No more results for heathcote on page 1.\n",
      "No results for heathcote. Moving to the next suburb.\n",
      "Scraping data for heathcote-south (3523)\n",
      "No more results for heathcote-south on page 1.\n",
      "No results for heathcote-south. Moving to the next suburb.\n",
      "Scraping data for knowsley (3523)\n",
      "No more results for knowsley on page 1.\n",
      "No results for knowsley. Moving to the next suburb.\n",
      "Scraping data for ladys-pass (3523)\n",
      "No more results for ladys-pass on page 1.\n",
      "No results for ladys-pass. Moving to the next suburb.\n",
      "Scraping data for moormbool-west (3523)\n",
      "No more results for moormbool-west on page 1.\n",
      "No results for moormbool-west. Moving to the next suburb.\n",
      "Scraping data for mount-camel (3523)\n",
      "No more results for mount-camel on page 1.\n",
      "No results for mount-camel. Moving to the next suburb.\n",
      "Scraping data for redcastle (3523)\n",
      "No more results for redcastle on page 2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% successful: 100%|██████████| 1/1 [00:00<00:00,  1.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping data for barrakee (3525)\n",
      "No more results for barrakee on page 1.\n",
      "No results for barrakee. Moving to the next suburb.\n",
      "Scraping data for buckrabanyule (3525)\n",
      "No more results for buckrabanyule on page 1.\n",
      "No results for buckrabanyule. Moving to the next suburb.\n",
      "Scraping data for charlton (3525)\n",
      "No more results for charlton on page 1.\n",
      "No results for charlton. Moving to the next suburb.\n",
      "Scraping data for chirrip (3525)\n",
      "No more results for chirrip on page 1.\n",
      "No results for chirrip. Moving to the next suburb.\n",
      "Scraping data for granite-flat (3525)\n",
      "No more results for granite-flat on page 1.\n",
      "No results for granite-flat. Moving to the next suburb.\n",
      "Scraping data for jeffcott (3525)\n",
      "Error fetching https://www.domain.com.au/rent/jeffcott-vic-3525/?ssubs=0&sort=suburb-asc&page=1: HTTP Error 404: Not Found\n",
      "No results for jeffcott. Moving to the next suburb.\n",
      "Scraping data for jeffcott-north (3525)\n",
      "Error fetching https://www.domain.com.au/rent/jeffcott-north-vic-3525/?ssubs=0&sort=suburb-asc&page=1: HTTP Error 404: Not Found\n",
      "No results for jeffcott-north. Moving to the next suburb.\n",
      "Scraping data for lake-marmal (3525)\n",
      "No more results for lake-marmal on page 1.\n",
      "No results for lake-marmal. Moving to the next suburb.\n",
      "Scraping data for nareewillock (3525)\n",
      "No more results for nareewillock on page 1.\n",
      "No results for nareewillock. Moving to the next suburb.\n",
      "Scraping data for teddywaddy (3525)\n",
      "Error fetching https://www.domain.com.au/rent/teddywaddy-vic-3525/?ssubs=0&sort=suburb-asc&page=1: HTTP Error 404: Not Found\n",
      "No results for teddywaddy. Moving to the next suburb.\n",
      "Scraping data for teddywaddy-west (3525)\n",
      "Error fetching https://www.domain.com.au/rent/teddywaddy-west-vic-3525/?ssubs=0&sort=suburb-asc&page=1: HTTP Error 404: Not Found\n",
      "No results for teddywaddy-west. Moving to the next suburb.\n",
      "Scraping data for terrappee (3525)\n",
      "No more results for terrappee on page 1.\n",
      "No results for terrappee. Moving to the next suburb.\n",
      "Scraping data for wooroonook (3525)\n",
      "No more results for wooroonook on page 1.\n",
      "No results for wooroonook. Moving to the next suburb.\n",
      "Scraping data for wychitella (3525)\n",
      "No more results for wychitella on page 1.\n",
      "No results for wychitella. Moving to the next suburb.\n",
      "Scraping data for wychitella-north (3525)\n",
      "No more results for wychitella-north on page 1.\n",
      "No results for wychitella-north. Moving to the next suburb.\n",
      "Scraping data for yeungroon (3525)\n",
      "No more results for yeungroon on page 1.\n",
      "No results for yeungroon. Moving to the next suburb.\n",
      "Scraping data for yeungroon-east (3525)\n",
      "No more results for yeungroon-east on page 1.\n",
      "No results for yeungroon-east. Moving to the next suburb.\n",
      "Scraping data for bunguluke (3527)\n",
      "No more results for bunguluke on page 1.\n",
      "No results for bunguluke. Moving to the next suburb.\n",
      "Scraping data for dumosa (3527)\n",
      "No more results for dumosa on page 1.\n",
      "No results for dumosa. Moving to the next suburb.\n",
      "Scraping data for glenloth (3527)\n",
      "No more results for glenloth on page 1.\n",
      "No results for glenloth. Moving to the next suburb.\n",
      "Scraping data for glenloth-east (3527)\n",
      "No more results for glenloth-east on page 1.\n",
      "No results for glenloth-east. Moving to the next suburb.\n",
      "Scraping data for jeruk (3527)\n",
      "No more results for jeruk on page 1.\n",
      "No results for jeruk. Moving to the next suburb.\n",
      "Scraping data for ninyeunook (3527)\n",
      "No more results for ninyeunook on page 1.\n",
      "No results for ninyeunook. Moving to the next suburb.\n",
      "Scraping data for teddywaddy (3527)\n",
      "No more results for teddywaddy on page 1.\n",
      "No results for teddywaddy. Moving to the next suburb.\n",
      "Scraping data for teddywaddy-west (3527)\n",
      "No more results for teddywaddy-west on page 1.\n",
      "No results for teddywaddy-west. Moving to the next suburb.\n",
      "Scraping data for thalia (3527)\n",
      "No more results for thalia on page 1.\n",
      "No results for thalia. Moving to the next suburb.\n",
      "Scraping data for towaninny (3527)\n",
      "No more results for towaninny on page 1.\n",
      "No results for towaninny. Moving to the next suburb.\n",
      "Scraping data for towaninny-south (3527)\n",
      "No more results for towaninny-south on page 1.\n",
      "No results for towaninny-south. Moving to the next suburb.\n",
      "Scraping data for wycheproof (3527)\n",
      "No more results for wycheproof on page 1.\n",
      "No results for wycheproof. Moving to the next suburb.\n",
      "Scraping data for wycheproof-south (3527)\n",
      "No more results for wycheproof-south on page 1.\n",
      "No results for wycheproof-south. Moving to the next suburb.\n",
      "Scraping data for kalpienung (3529)\n",
      "No more results for kalpienung on page 1.\n",
      "No results for kalpienung. Moving to the next suburb.\n",
      "Scraping data for nullawil (3529)\n",
      "No more results for nullawil on page 1.\n",
      "No results for nullawil. Moving to the next suburb.\n",
      "Scraping data for culgoa (3530)\n",
      "No more results for culgoa on page 1.\n",
      "No results for culgoa. Moving to the next suburb.\n",
      "Scraping data for sutton (3530)\n",
      "No more results for sutton on page 1.\n",
      "No results for sutton. Moving to the next suburb.\n",
      "Scraping data for wangie (3530)\n",
      "No more results for wangie on page 1.\n",
      "No results for wangie. Moving to the next suburb.\n",
      "Scraping data for warne (3530)\n",
      "No more results for warne on page 1.\n",
      "No results for warne. Moving to the next suburb.\n",
      "Scraping data for berriwillock (3531)\n",
      "No more results for berriwillock on page 1.\n",
      "No results for berriwillock. Moving to the next suburb.\n",
      "Scraping data for boigbeat (3531)\n",
      "No more results for boigbeat on page 1.\n",
      "No results for boigbeat. Moving to the next suburb.\n",
      "Scraping data for springfield (3531)\n",
      "No more results for springfield on page 1.\n",
      "No results for springfield. Moving to the next suburb.\n",
      "Scraping data for bimbourie (3533)\n",
      "No more results for bimbourie on page 1.\n",
      "No results for bimbourie. Moving to the next suburb.\n",
      "Scraping data for lake-tyrrell (3533)\n",
      "No more results for lake-tyrrell on page 1.\n",
      "No results for lake-tyrrell. Moving to the next suburb.\n",
      "Scraping data for mittyack (3533)\n",
      "No more results for mittyack on page 1.\n",
      "No results for mittyack. Moving to the next suburb.\n",
      "Scraping data for myall (3533)\n",
      "No more results for myall on page 1.\n",
      "No results for myall. Moving to the next suburb.\n",
      "Scraping data for nandaly (3533)\n",
      "No more results for nandaly on page 1.\n",
      "No results for nandaly. Moving to the next suburb.\n",
      "Scraping data for ninda (3533)\n",
      "No more results for ninda on page 1.\n",
      "No results for ninda. Moving to the next suburb.\n",
      "Scraping data for nyarrin (3533)\n",
      "No more results for nyarrin on page 1.\n",
      "No results for nyarrin. Moving to the next suburb.\n",
      "Scraping data for pier-milan (3533)\n",
      "No more results for pier-milan on page 1.\n",
      "No results for pier-milan. Moving to the next suburb.\n",
      "Scraping data for sea-lake (3533)\n",
      "No more results for sea-lake on page 1.\n",
      "No results for sea-lake. Moving to the next suburb.\n",
      "Scraping data for straten (3533)\n",
      "No more results for straten on page 1.\n",
      "No results for straten. Moving to the next suburb.\n",
      "Scraping data for tyenna (3533)\n",
      "No more results for tyenna on page 1.\n",
      "No results for tyenna. Moving to the next suburb.\n",
      "Scraping data for tyrrell (3533)\n",
      "No more results for tyrrell on page 1.\n",
      "No results for tyrrell. Moving to the next suburb.\n",
      "Scraping data for tyrrell-downs (3533)\n",
      "No more results for tyrrell-downs on page 1.\n",
      "No results for tyrrell-downs. Moving to the next suburb.\n",
      "Scraping data for barraport (3537)\n",
      "No more results for barraport on page 1.\n",
      "No results for barraport. Moving to the next suburb.\n",
      "Scraping data for barraport-west (3537)\n",
      "No more results for barraport-west on page 1.\n",
      "No results for barraport-west. Moving to the next suburb.\n",
      "Scraping data for boort (3537)\n",
      "No more results for boort on page 2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% successful: 100%|██████████| 1/1 [00:00<00:00,  1.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping data for canary-island (3537)\n",
      "No more results for canary-island on page 1.\n",
      "No results for canary-island. Moving to the next suburb.\n",
      "Scraping data for catumnal (3537)\n",
      "No more results for catumnal on page 1.\n",
      "No results for catumnal. Moving to the next suburb.\n",
      "Scraping data for gredgwin (3537)\n",
      "No more results for gredgwin on page 1.\n",
      "No results for gredgwin. Moving to the next suburb.\n",
      "Scraping data for leaghur (3537)\n",
      "No more results for leaghur on page 1.\n",
      "No results for leaghur. Moving to the next suburb.\n",
      "Scraping data for minmindie (3537)\n",
      "No more results for minmindie on page 1.\n",
      "No results for minmindie. Moving to the next suburb.\n",
      "Scraping data for yando (3537)\n",
      "No more results for yando on page 1.\n",
      "No results for yando. Moving to the next suburb.\n",
      "Scraping data for cannie (3540)\n",
      "No more results for cannie on page 1.\n",
      "No results for cannie. Moving to the next suburb.\n",
      "Scraping data for ninyeunook (3540)\n",
      "Error fetching https://www.domain.com.au/rent/ninyeunook-vic-3540/?ssubs=0&sort=suburb-asc&page=1: HTTP Error 404: Not Found\n",
      "No results for ninyeunook. Moving to the next suburb.\n",
      "Scraping data for oakvale (3540)\n",
      "No more results for oakvale on page 1.\n",
      "No results for oakvale. Moving to the next suburb.\n",
      "Scraping data for quambatook (3540)\n",
      "No more results for quambatook on page 1.\n",
      "No results for quambatook. Moving to the next suburb.\n",
      "Scraping data for cokum (3542)\n",
      "No more results for cokum on page 1.\n",
      "No results for cokum. Moving to the next suburb.\n",
      "Scraping data for lalbert (3542)\n",
      "No more results for lalbert on page 1.\n",
      "No results for lalbert. Moving to the next suburb.\n",
      "Scraping data for tittybong (3542)\n",
      "No more results for tittybong on page 1.\n",
      "No results for tittybong. Moving to the next suburb.\n",
      "Scraping data for titybong (3542)\n",
      "No more results for titybong on page 1.\n",
      "No results for titybong. Moving to the next suburb.\n",
      "Scraping data for chinangin (3544)\n",
      "No more results for chinangin on page 1.\n",
      "No results for chinangin. Moving to the next suburb.\n",
      "Scraping data for gowanford (3544)\n",
      "No more results for gowanford on page 1.\n",
      "No results for gowanford. Moving to the next suburb.\n",
      "Scraping data for murnungin (3544)\n",
      "No more results for murnungin on page 1.\n",
      "No results for murnungin. Moving to the next suburb.\n",
      "Scraping data for springfield (3544)\n",
      "No more results for springfield on page 1.\n",
      "No results for springfield. Moving to the next suburb.\n",
      "Scraping data for ultima (3544)\n",
      "No more results for ultima on page 1.\n",
      "No results for ultima. Moving to the next suburb.\n",
      "Scraping data for ultima-east (3544)\n",
      "No more results for ultima-east on page 1.\n",
      "No results for ultima-east. Moving to the next suburb.\n",
      "Scraping data for waitchie (3544)\n",
      "No more results for waitchie on page 1.\n",
      "No results for waitchie. Moving to the next suburb.\n",
      "Scraping data for bolton (3546)\n",
      "No more results for bolton on page 1.\n",
      "No results for bolton. Moving to the next suburb.\n",
      "Scraping data for chinkapook (3546)\n",
      "No more results for chinkapook on page 1.\n",
      "No results for chinkapook. Moving to the next suburb.\n",
      "Scraping data for cocamba (3546)\n",
      "No more results for cocamba on page 1.\n",
      "No results for cocamba. Moving to the next suburb.\n",
      "Scraping data for gerahmin (3546)\n",
      "No more results for gerahmin on page 1.\n",
      "No results for gerahmin. Moving to the next suburb.\n",
      "Scraping data for manangatang (3546)\n",
      "No more results for manangatang on page 2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% successful: 100%|██████████| 1/1 [00:00<00:00,  1.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping data for turoar (3546)\n",
      "No more results for turoar on page 1.\n",
      "No results for turoar. Moving to the next suburb.\n",
      "Scraping data for winnambool (3546)\n",
      "No more results for winnambool on page 1.\n",
      "No results for winnambool. Moving to the next suburb.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 6:=======================================================> (47 + 1) / 48]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully written\n",
      "chunk finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#Priscilla\n",
    "starting_chunk = 3048 + 350\n",
    "run_chunk(starting_chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rachel\n",
    "starting_chunk = 3048 + 525\n",
    "run_chunk(starting_chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping data for archerton (3723)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1008810/4257810455.py:69: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  no_results = bs_object.find(text=re.compile(\"No results found\", re.I))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No more results for archerton on page 1.\n",
      "No results for archerton. Moving to the next suburb.\n",
      "Scraping data for barjarg (3723)\n",
      "No more results for barjarg on page 1.\n",
      "No results for barjarg. Moving to the next suburb.\n",
      "Scraping data for boorolite (3723)\n",
      "No more results for boorolite on page 1.\n",
      "No results for boorolite. Moving to the next suburb.\n",
      "Scraping data for bridge-creek (3723)\n",
      "No more results for bridge-creek on page 1.\n",
      "No results for bridge-creek. Moving to the next suburb.\n",
      "Scraping data for delatite (3723)\n",
      "No more results for delatite on page 1.\n",
      "No results for delatite. Moving to the next suburb.\n",
      "Scraping data for enochs-point (3723)\n",
      "No more results for enochs-point on page 1.\n",
      "No results for enochs-point. Moving to the next suburb.\n",
      "Scraping data for gaffneys-creek (3723)\n",
      "No more results for gaffneys-creek on page 1.\n",
      "No results for gaffneys-creek. Moving to the next suburb.\n",
      "Scraping data for goughs-bay (3723)\n",
      "No more results for goughs-bay on page 1.\n",
      "No results for goughs-bay. Moving to the next suburb.\n",
      "Scraping data for howes-creek (3723)\n",
      "No more results for howes-creek on page 1.\n",
      "No results for howes-creek. Moving to the next suburb.\n",
      "Scraping data for howqua (3723)\n",
      "No more results for howqua on page 1.\n",
      "No results for howqua. Moving to the next suburb.\n",
      "Scraping data for howqua-hills (3723)\n",
      "No more results for howqua-hills on page 1.\n",
      "No results for howqua-hills. Moving to the next suburb.\n",
      "Scraping data for howqua-inlet (3723)\n",
      "No more results for howqua-inlet on page 1.\n",
      "No results for howqua-inlet. Moving to the next suburb.\n",
      "Scraping data for jamieson (3723)\n",
      "No more results for jamieson on page 1.\n",
      "No results for jamieson. Moving to the next suburb.\n",
      "Scraping data for kevington (3723)\n",
      "No more results for kevington on page 1.\n",
      "No results for kevington. Moving to the next suburb.\n",
      "Scraping data for knockwood (3723)\n",
      "No more results for knockwood on page 1.\n",
      "No results for knockwood. Moving to the next suburb.\n",
      "Scraping data for macs-cove (3723)\n",
      "No more results for macs-cove on page 1.\n",
      "No results for macs-cove. Moving to the next suburb.\n",
      "Scraping data for maindample (3723)\n",
      "No more results for maindample on page 1.\n",
      "No results for maindample. Moving to the next suburb.\n",
      "Scraping data for matlock (3723)\n",
      "No more results for matlock on page 1.\n",
      "No results for matlock. Moving to the next suburb.\n",
      "Scraping data for merrijig (3723)\n",
      "No more results for merrijig on page 2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% successful: 100%|██████████| 2/2 [00:01<00:00,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping data for mount-buller (3723)\n",
      "No more results for mount-buller on page 1.\n",
      "No results for mount-buller. Moving to the next suburb.\n",
      "Scraping data for mountain-bay (3723)\n",
      "No more results for mountain-bay on page 1.\n",
      "No results for mountain-bay. Moving to the next suburb.\n",
      "Scraping data for nillahcootie (3723)\n",
      "Error fetching https://www.domain.com.au/rent/nillahcootie-vic-3723/?ssubs=0&sort=suburb-asc&page=1: HTTP Error 404: Not Found\n",
      "No results for nillahcootie. Moving to the next suburb.\n",
      "Scraping data for piries (3723)\n",
      "No more results for piries on page 1.\n",
      "No results for piries. Moving to the next suburb.\n",
      "Scraping data for sawmill-settlement (3723)\n",
      "No more results for sawmill-settlement on page 1.\n",
      "No results for sawmill-settlement. Moving to the next suburb.\n",
      "Scraping data for tolmie (3723)\n",
      "No more results for tolmie on page 1.\n",
      "No results for tolmie. Moving to the next suburb.\n",
      "Scraping data for woods-point (3723)\n",
      "No more results for woods-point on page 1.\n",
      "No results for woods-point. Moving to the next suburb.\n",
      "Scraping data for mansfield (3724)\n",
      "Error fetching https://www.domain.com.au/rent/mansfield-vic-3724/?ssubs=0&sort=suburb-asc&page=1: HTTP Error 404: Not Found\n",
      "No results for mansfield. Moving to the next suburb.\n",
      "Scraping data for boxwood (3725)\n",
      "No more results for boxwood on page 1.\n",
      "No results for boxwood. Moving to the next suburb.\n",
      "Scraping data for chesney-vale (3725)\n",
      "No more results for chesney-vale on page 1.\n",
      "No results for chesney-vale. Moving to the next suburb.\n",
      "Scraping data for goorambat (3725)\n",
      "No more results for goorambat on page 2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% successful: 100%|██████████| 1/1 [00:00<00:00,  2.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping data for major-plains (3725)\n",
      "No more results for major-plains on page 1.\n",
      "No results for major-plains. Moving to the next suburb.\n",
      "Scraping data for stewarton (3725)\n",
      "No more results for stewarton on page 1.\n",
      "No results for stewarton. Moving to the next suburb.\n",
      "Scraping data for bungeet (3726)\n",
      "No more results for bungeet on page 1.\n",
      "No results for bungeet. Moving to the next suburb.\n",
      "Scraping data for bungeet-west (3726)\n",
      "No more results for bungeet-west on page 1.\n",
      "No results for bungeet-west. Moving to the next suburb.\n",
      "Scraping data for devenish (3726)\n",
      "No more results for devenish on page 1.\n",
      "No results for devenish. Moving to the next suburb.\n",
      "Scraping data for thoona (3726)\n",
      "No more results for thoona on page 1.\n",
      "No results for thoona. Moving to the next suburb.\n",
      "Scraping data for almonds (3727)\n",
      "No more results for almonds on page 1.\n",
      "No results for almonds. Moving to the next suburb.\n",
      "Scraping data for lake-rowan (3727)\n",
      "No more results for lake-rowan on page 1.\n",
      "No results for lake-rowan. Moving to the next suburb.\n",
      "Scraping data for pelluebla (3727)\n",
      "No more results for pelluebla on page 1.\n",
      "No results for pelluebla. Moving to the next suburb.\n",
      "Scraping data for st-james (3727)\n",
      "No more results for st-james on page 1.\n",
      "No results for st-james. Moving to the next suburb.\n",
      "Scraping data for waggarandall (3727)\n",
      "Error fetching https://www.domain.com.au/rent/waggarandall-vic-3727/?ssubs=0&sort=suburb-asc&page=1: HTTP Error 404: Not Found\n",
      "No results for waggarandall. Moving to the next suburb.\n",
      "Scraping data for yundool (3727)\n",
      "No more results for yundool on page 1.\n",
      "No results for yundool. Moving to the next suburb.\n",
      "Scraping data for boomahnoomoonah (3728)\n",
      "No more results for boomahnoomoonah on page 1.\n",
      "No results for boomahnoomoonah. Moving to the next suburb.\n",
      "Scraping data for tungamah (3728)\n",
      "No more results for tungamah on page 2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% successful: 100%|██████████| 1/1 [00:00<00:00,  1.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping data for wilby (3728)\n",
      "No more results for wilby on page 1.\n",
      "No results for wilby. Moving to the next suburb.\n",
      "Scraping data for youarang (3728)\n",
      "No more results for youarang on page 1.\n",
      "No results for youarang. Moving to the next suburb.\n",
      "Scraping data for bathumi (3730)\n",
      "No more results for bathumi on page 1.\n",
      "No results for bathumi. Moving to the next suburb.\n",
      "Scraping data for boosey (3730)\n",
      "No more results for boosey on page 1.\n",
      "No results for boosey. Moving to the next suburb.\n",
      "Scraping data for bundalong (3730)\n",
      "No more results for bundalong on page 2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% successful: 100%|██████████| 2/2 [00:01<00:00,  1.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping data for bundalong-south (3730)\n",
      "No more results for bundalong-south on page 1.\n",
      "No results for bundalong-south. Moving to the next suburb.\n",
      "Scraping data for burramine (3730)\n",
      "No more results for burramine on page 1.\n",
      "No results for burramine. Moving to the next suburb.\n",
      "Scraping data for burramine-south (3730)\n",
      "No more results for burramine-south on page 1.\n",
      "No results for burramine-south. Moving to the next suburb.\n",
      "Scraping data for esmond (3730)\n",
      "No more results for esmond on page 1.\n",
      "No results for esmond. Moving to the next suburb.\n",
      "Scraping data for telford (3730)\n",
      "No more results for telford on page 1.\n",
      "No results for telford. Moving to the next suburb.\n",
      "Scraping data for yarrawonga (3730)\n",
      "No more results for yarrawonga on page 2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% successful:  39%|███▉      | 7/18 [00:03<00:05,  1.97it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Nathan\u001b[39;00m\n\u001b[1;32m      2\u001b[0m starting_chunk \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3048\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m700\u001b[39m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mrun_chunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstarting_chunk\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[37], line 5\u001b[0m, in \u001b[0;36mrun_chunk\u001b[0;34m(starting_chunk)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# we are running chunks of 25 postcodes 7 times each\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m i \u001b[38;5;241m<\u001b[39m starting_chunk \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m175\u001b[39m:\n\u001b[0;32m----> 5\u001b[0m     \u001b[43mstart_scrape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mchunk_\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#i.split(\"_\")[1])\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     i \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m25\u001b[39m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3923\u001b[39m:\n",
      "Cell \u001b[0;32mIn[35], line 102\u001b[0m, in \u001b[0;36mstart_scrape\u001b[0;34m(chunk, file_suffix)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m property_url \u001b[38;5;129;01min\u001b[39;00m pbar:\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 102\u001b[0m         bs_object \u001b[38;5;241m=\u001b[39m BeautifulSoup(\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproperty_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mUser-Agent\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPostmanRuntime/7.6.0\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlxml\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    103\u001b[0m         total_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    105\u001b[0m         \u001b[38;5;66;03m# Get property name\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/urllib/request.py:216\u001b[0m, in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    215\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[0;32m--> 216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.10/urllib/request.py:519\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    516\u001b[0m     req \u001b[38;5;241m=\u001b[39m meth(req)\n\u001b[1;32m    518\u001b[0m sys\u001b[38;5;241m.\u001b[39maudit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124murllib.Request\u001b[39m\u001b[38;5;124m'\u001b[39m, req\u001b[38;5;241m.\u001b[39mfull_url, req\u001b[38;5;241m.\u001b[39mdata, req\u001b[38;5;241m.\u001b[39mheaders, req\u001b[38;5;241m.\u001b[39mget_method())\n\u001b[0;32m--> 519\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    521\u001b[0m \u001b[38;5;66;03m# post-process response\u001b[39;00m\n\u001b[1;32m    522\u001b[0m meth_name \u001b[38;5;241m=\u001b[39m protocol\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_response\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m/usr/lib/python3.10/urllib/request.py:536\u001b[0m, in \u001b[0;36mOpenerDirector._open\u001b[0;34m(self, req, data)\u001b[0m\n\u001b[1;32m    533\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m    535\u001b[0m protocol \u001b[38;5;241m=\u001b[39m req\u001b[38;5;241m.\u001b[39mtype\n\u001b[0;32m--> 536\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_open\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\n\u001b[1;32m    537\u001b[0m \u001b[43m                          \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_open\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result:\n\u001b[1;32m    539\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/usr/lib/python3.10/urllib/request.py:496\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[1;32m    495\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[0;32m--> 496\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    497\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    498\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/usr/lib/python3.10/urllib/request.py:1391\u001b[0m, in \u001b[0;36mHTTPSHandler.https_open\u001b[0;34m(self, req)\u001b[0m\n\u001b[1;32m   1390\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhttps_open\u001b[39m(\u001b[38;5;28mself\u001b[39m, req):\n\u001b[0;32m-> 1391\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhttp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mHTTPSConnection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1392\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_hostname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.10/urllib/request.py:1352\u001b[0m, in \u001b[0;36mAbstractHTTPHandler.do_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1350\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# timeout error\u001b[39;00m\n\u001b[1;32m   1351\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m URLError(err)\n\u001b[0;32m-> 1352\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mh\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1353\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m   1354\u001b[0m     h\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/usr/lib/python3.10/http/client.py:1375\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1373\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1374\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1375\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1376\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[1;32m   1377\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/usr/lib/python3.10/http/client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 318\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/http/client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 279\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/lib/python3.10/socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 705\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    707\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/ssl.py:1303\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1299\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1300\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1301\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1302\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1303\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1304\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1305\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m/usr/lib/python3.10/ssl.py:1159\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1157\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1159\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1160\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1161\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Nathan\n",
    "starting_chunk = 3048 + 700\n",
    "run_chunk(starting_chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3398"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3048+175 + 175"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk_3048\n",
      "chunk_3073\n",
      "chunk_3098\n",
      "chunk_3123\n",
      "chunk_3148\n",
      "chunk_3173\n",
      "chunk_3198\n",
      "chunk_3223\n",
      "chunk_3248\n",
      "chunk_3273\n",
      "chunk_3298\n",
      "chunk_3323\n",
      "chunk_3348\n",
      "chunk_3373\n",
      "chunk_3398\n",
      "chunk_3423\n",
      "chunk_3448\n",
      "chunk_3473\n",
      "chunk_3498\n",
      "chunk_3523\n",
      "chunk_3548\n",
      "chunk_3573\n",
      "chunk_3598\n",
      "chunk_3623\n",
      "chunk_3648\n",
      "chunk_3673\n",
      "chunk_3698\n",
      "chunk_3723\n",
      "chunk_3748\n",
      "chunk_3773\n",
      "chunk_3798\n",
      "chunk_3823\n",
      "chunk_3848\n",
      "chunk_3873\n",
      "chunk_3898\n",
      "chunk_3923\n",
      "chunk_3948\n",
      "chunk_3973\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
